[{"abstract":" We present an abstract formalization of G\u0026ouml;del's incompleteness theorems. We analyze sufficient conditions for the theorems' applicability to a partially specified logic. Our abstract perspective enables a comparison between alternative approaches from the literature. These include Rosser's variation of the first theorem, Jeroslow's variation of the second theorem, and the Swierczkowski\u0026ndash;Paulson semantics-based approach. This AFP entry is the main entry point to the results described in our CADE-27 paper \u003ca href=\"https://dx.doi.org/10.1007/978-3-030-29436-6_26\"\u003eA Formally Verified Abstract Account of Gödel's Incompleteness Theorems\u003c/a\u003e.  As part of our abstract formalization's validation, we instantiate our locales twice in the separate AFP entries \u003ca href=\"https://www.isa-afp.org/entries/Goedel_HFSet_Semantic.html\"\u003eGoedel_HFSet_Semantic\u003c/a\u003e and \u003ca href=\"https://www.isa-afp.org/entries/Goedel_HFSet_Semanticless.html\"\u003eGoedel_HFSet_Semanticless\u003c/a\u003e.","date":"September 16","id":0,"permalink":"/entries/goedel_incompleteness/","shortname":"Goedel_Incompleteness","title":"An Abstract Formalization of G\u0026ouml;del's Incompleteness Theorems","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" We validate an abstract formulation of G\u0026ouml;del's First and Second Incompleteness Theorems from a \u003ca href=\"https://www.isa-afp.org/entries/Goedel_Incompleteness.html\"\u003eseparate AFP entry\u003c/a\u003e by instantiating them to the case of \u003ci\u003efinite sound extensions of the Hereditarily Finite (HF) Set theory\u003c/i\u003e, i.e., FOL theories extending the HF Set theory with a finite set of axioms that are sound in the standard model. The concrete results had been previously formalised in an \u003ca href=\"https://www.isa-afp.org/entries/Incompleteness.html\"\u003eAFP entry by Larry Paulson\u003c/a\u003e; our instantiation reuses the infrastructure developed in that entry.","date":"September 16","id":1,"permalink":"/entries/goedel_hfset_semantic/","shortname":"Goedel_HFSet_Semantic","title":"From Abstract to Concrete G\u0026ouml;del's Incompleteness Theorems\u0026mdash;Part I","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" We validate an abstract formulation of G\u0026ouml;del's Second Incompleteness Theorem from a \u003ca href=\"https://www.isa-afp.org/entries/Goedel_Incompleteness.html\"\u003eseparate AFP entry\u003c/a\u003e by instantiating it to the case of \u003ci\u003efinite consistent extensions of the Hereditarily Finite (HF) Set theory\u003c/i\u003e, i.e., consistent FOL theories extending the HF Set theory with a finite set of axioms.  The instantiation draws heavily on infrastructure previously developed by Larry Paulson in his \u003ca href=\"https://www.isa-afp.org/entries/Incompleteness.html\"\u003edirect formalisation of the concrete result\u003c/a\u003e. It strengthens Paulson's formalization of G\u0026ouml;del's Second from that entry by \u003ci\u003enot\u003c/i\u003e assuming soundness, and in fact not relying on any notion of model or semantic interpretation. The strengthening was obtained by first replacing some of Paulson’s semantic arguments with proofs within his HF calculus, and then plugging in some of Paulson's (modified) lemmas to instantiate our soundness-free G\u0026ouml;del's Second locale.","date":"September 16","id":2,"permalink":"/entries/goedel_hfset_semanticless/","shortname":"Goedel_HFSet_Semanticless","title":"From Abstract to Concrete G\u0026ouml;del's Incompleteness Theorems\u0026mdash;Part II","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" We instantiate our syntax-independent logic infrastructure developed in \u003ca href=\"https://www.isa-afp.org/entries/Syntax_Independent_Logic.html\"\u003ea separate AFP entry\u003c/a\u003e to the FOL theory of Robinson arithmetic (also known as Q). The latter was formalised using Nominal Isabelle by adapting \u003ca href=\"https://www.isa-afp.org/entries/Incompleteness.html\"\u003eLarry Paulson’s formalization of the Hereditarily Finite Set theory\u003c/a\u003e.","date":"September 16","id":3,"permalink":"/entries/robinson_arithmetic/","shortname":"Robinson_Arithmetic","title":"Robinson Arithmetic","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" We formalize a notion of logic whose terms and formulas are kept abstract. In particular, logical connectives, substitution, free variables, and provability are not defined, but characterized by their general properties as locale assumptions. Based on this abstract characterization, we develop further reusable reasoning infrastructure. For example, we define parallel substitution (along with proving its characterizing theorems) from single-point substitution. Similarly, we develop a natural deduction style proof system starting from the abstract Hilbert-style one. These one-time efforts benefit different concrete logics satisfying our locales' assumptions.  We instantiate the syntax-independent logic infrastructure to Robinson arithmetic (also known as Q) in the AFP entry \u003ca href=\"https://www.isa-afp.org/entries/Robinson_Arithmetic.html\"\u003eRobinson_Arithmetic\u003c/a\u003e and to hereditarily finite set theory in the AFP entries \u003ca href=\"https://www.isa-afp.org/entries/Goedel_HFSet_Semantic.html\"\u003eGoedel_HFSet_Semantic\u003c/a\u003e and \u003ca href=\"https://www.isa-afp.org/entries/Goedel_HFSet_Semanticless.html\"\u003eGoedel_HFSet_Semanticless\u003c/a\u003e, which are part of our formalization of G\u0026ouml;del's Incompleteness Theorems described in our CADE-27 paper \u003ca href=\"https://dx.doi.org/10.1007/978-3-030-29436-6_26\"\u003eA Formally Verified Abstract Account of Gödel's Incompleteness Theorems\u003c/a\u003e.","date":"September 16","id":4,"permalink":"/entries/syntax_independent_logic/","shortname":"Syntax_Independent_Logic","title":"Syntax-Independent Logic Infrastructure","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" In this AFP entry, we provide a formalisation of extended finite state machines (EFSMs) where models are represented as finite sets of transitions between states. EFSMs execute traces to produce observable outputs. We also define various simulation and equality metrics for EFSMs in terms of traces and prove their strengths in relation to each other. Another key contribution is a framework of function definitions such that LTL properties can be phrased over EFSMs. Finally, we provide a simple example case study in the form of a drinks machine.","date":"September 7","id":5,"permalink":"/entries/extended_finite_state_machines/","shortname":"Extended_Finite_State_Machines","title":"A Formal Model of Extended Finite State Machines","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" In this AFP entry, we provide a formal implementation of a state-merging technique to infer extended finite state machines (EFSMs), complete with output and update functions, from black-box traces. In particular, we define the subsumption in context relation as a means of determining whether one transition is able to account for the behaviour of another. Building on this, we define the direct subsumption relation, which lifts the subsumption in context relation to EFSM level such that we can use it to determine whether it is safe to merge a given pair of transitions. Key proofs include the conditions necessary for subsumption to occur and that subsumption and direct subsumption are preorder relations.  We also provide a number of different heuristics which can be used to abstract away concrete values into registers so that more states and transitions can be merged and provide proofs of the various conditions which must hold for these abstractions to subsume their ungeneralised counterparts. A Code Generator setup to create executable Scala code is also defined.","date":"September 7","id":6,"permalink":"/entries/extended_finite_state_machine_inference/","shortname":"Extended_Finite_State_Machine_Inference","title":"Inference of Extended Finite State Machines","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" Generating and checking proof certificates is important to increase the trust in automated reasoning tools. In recent years formal verification using computer algebra became more important and is heavily used in automated circuit verification.  An existing proof format which covers algebraic reasoning and allows efficient proof checking is the practical algebraic calculus (PAC). In this development, we present the verified checker Pastèque that is obtained by synthesis via the Refinement Framework.  This is the formalization going with our FMCAD'20 tool presentation.","date":"August 31","id":7,"permalink":"/entries/pac_checker/","shortname":"PAC_Checker","title":"Practical Algebraic Calculus Checker","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" \u003cp\u003e This entry formalizes some classical concepts and results from inductive inference of recursive functions. In the basic setting a partial recursive function (\"strategy\") must identify (\"learn\") all functions from a set (\"class\") of recursive functions. To that end the strategy receives more and more values $f(0), f(1), f(2), \\ldots$ of some function $f$ from the given class and in turn outputs descriptions of partial recursive functions, for example, Gödel numbers. The strategy is considered successful if the sequence of outputs (\"hypotheses\") converges to a description of $f$. A class of functions learnable in this sense is called \"learnable in the limit\". The set of all these classes is denoted by LIM. \u003c/p\u003e  \u003cp\u003e Other types of inference considered are finite learning (FIN), behaviorally correct learning in the limit (BC), and some variants of LIM with restrictions on the hypotheses: total learning (TOTAL), consistent learning (CONS), and class-preserving learning (CP). The main results formalized are the proper inclusions $\\mathrm{FIN} \\subset \\mathrm{CP} \\subset \\mathrm{TOTAL} \\subset \\mathrm{CONS} \\subset \\mathrm{LIM} \\subset \\mathrm{BC} \\subset 2^{\\mathcal{R}}$, where $\\mathcal{R}$ is the set of all total recursive functions.  Further results show that for all these inference types except CONS, strategies can be assumed to be total recursive functions; that all inference types but CP are closed under the subset relation between classes; and that no inference type is closed under the union of classes. \u003c/p\u003e  \u003cp\u003e The above is based on a formalization of recursive functions heavily inspired by the \u003ca href=\"https://www.isa-afp.org/entries/Universal_Turing_Machine.html\"\u003eUniversal Turing Machine\u003c/a\u003e entry by Xu et al., but different in that it models partial functions with codomain \u003cem\u003enat option\u003c/em\u003e. The formalization contains a construction of a universal partial recursive function, without resorting to Turing machines, introduces decidability and recursive enumerability, and proves some standard results: existence of a Kleene normal form, the \u003cem\u003es-m-n\u003c/em\u003e theorem, Rice's theorem, and assorted fixed-point theorems (recursion theorems) by Kleene, Rogers, and Smullyan. \u003c/p\u003e","date":"August 31","id":8,"permalink":"/entries/inductive_inference/","shortname":"Inductive_Inference","title":"Some classical results in inductive inference of recursive functions","topicLinks":["logic/computability","computer-science/machine-learning"],"topics":["Logic/Computability","Computer science/Machine learning"]},{"abstract":" We give a simple relation-algebraic semantics of read and write operations on associative arrays. The array operations seamlessly integrate with assignments in the Hoare-logic library. Using relation algebras and Kleene algebras we verify the correctness of an array-based implementation of disjoint-set forests with a naive union operation and a find operation with path compression.","date":"August 26","id":9,"permalink":"/entries/relational_disjoint_set_forests/","shortname":"Relational_Disjoint_Set_Forests","title":"Relational Disjoint-Set Forests","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" This Isabelle/HOL formalization extends the AFP entry \u003cem\u003eSaturation_Framework\u003c/em\u003e with the following contributions:  \u003cul\u003e \u003cli\u003ean application of the framework to prove Bachmair and Ganzinger's resolution prover RP refutationally complete, which was formalized in a more ad hoc fashion by Schlichtkrull et al. in the AFP entry \u003cem\u003eOrdered_Resultion_Prover\u003c/em\u003e;\u003c/li\u003e \u003cli\u003egeneralizations of various basic concepts formalized by Schlichtkrull et al., which were needed to verify RP and could be useful to formalize other calculi, such as superposition;\u003c/li\u003e \u003cli\u003ealternative proofs of fairness (and hence saturation and ultimately refutational completeness) for the given clause procedures GC and LGC, based on invariance.\u003c/li\u003e \u003c/ul\u003e","date":"August 25","id":10,"permalink":"/entries/saturation_framework_extensions/","shortname":"Saturation_Framework_Extensions","title":"Extensions to the Comprehensive Framework for Saturation Theorem Proving","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" Richard Bird and collaborators have proposed a derivation of an intricate cyclic program that implements the Morris-Pratt string matching algorithm. Here we provide a proof of total correctness for Bird's derivation and complete it by adding Knuth's optimisation.","date":"August 25","id":11,"permalink":"/entries/birdkmp/","shortname":"BirdKMP","title":"Putting the `K' into Bird's derivation of Knuth-Morris-Pratt string matching","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" This is a formalisation of Amicable Numbers, involving some relevant material including Euler's sigma function, some relevant definitions, results and examples as well as rules such as Th\u0026#257;bit ibn Qurra's Rule, Euler's Rule, te Riele's Rule and Borho's Rule with breeders.","date":"August 4","id":12,"permalink":"/entries/amicable_numbers/","shortname":"Amicable_Numbers","title":"Amicable Numbers","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" The theory of partition relations concerns generalisations of Ramsey's theorem. For any ordinal $\\alpha$, write $\\alpha \\to (\\alpha, m)^2$ if for each function $f$ from unordered pairs of elements of $\\alpha$ into $\\{0,1\\}$, either there is a subset $X\\subseteq \\alpha$ order-isomorphic to $\\alpha$ such that $f\\{x,y\\}=0$ for all $\\{x,y\\}\\subseteq X$, or there is an $m$ element set $Y\\subseteq \\alpha$ such that $f\\{x,y\\}=1$ for all $\\{x,y\\}\\subseteq Y$. (In both cases, with $\\{x,y\\}$ we require $x\\not=y$.) In particular, the infinite Ramsey theorem can be written in this notation as $\\omega \\to (\\omega, \\omega)^2$, or if we restrict $m$ to the positive integers as above, then $\\omega \\to (\\omega, m)^2$ for all $m$.  This entry formalises Larson's proof of $\\omega^\\omega \\to (\\omega^\\omega, m)^2$ along with a similar proof of a result due to Specker: $\\omega^2 \\to (\\omega^2, m)^2$. Also proved is a necessary result by Erdős and Milner: $\\omega^{1+\\alpha\\cdot n} \\to (\\omega^{1+\\alpha}, 2^n)^2$.","date":"August 3","id":13,"permalink":"/entries/ordinal_partitions/","shortname":"Ordinal_Partitions","title":"Ordinal Partitions","topicLinks":["mathematics/combinatorics","logic/set-theory"],"topics":["Mathematics/Combinatorics","Logic/Set theory"]},{"abstract":" We provide a suitable distributed system model and implementation of the Chandy--Lamport distributed snapshot algorithm [ACM Transactions on Computer Systems, 3, 63-75, 1985]. Our main result is a formal termination and correctness proof of the Chandy--Lamport algorithm and its use in stable property detection.","date":"July 21","id":14,"permalink":"/entries/chandy_lamport/","shortname":"Chandy_Lamport","title":"A Formal Proof of The Chandy--Lamport Distributed Snapshot Algorithm","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":" Binary relations are one of the standard ways to encode, characterise and reason about graphs. Relation algebras provide equational axioms for a large fragment of the calculus of binary relations. Although relations are standard tools in many areas of mathematics and computing, researchers usually fall back to point-wise reasoning when it comes to arguments about paths in a graph. We present a purely algebraic way to specify different kinds of paths in Kleene relation algebras, which are relation algebras equipped with an operation for reflexive transitive closure. We study the relationship between paths with a designated root vertex and paths without such a vertex. Since we stay in first-order logic this development helps with mechanising proofs. To demonstrate the applicability of the algebraic framework we verify the correctness of three basic graph algorithms.","date":"July 13","id":15,"permalink":"/entries/relational_paths/","shortname":"Relational_Paths","title":"Relational Characterisations of Paths","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" The Vienna Convention on Road Traffic defines the safe distance traffic rules informally. This could make autonomous vehicle liable for safe-distance-related accidents because there is no clear definition of how large a safe distance is. We provide a formally proven prescriptive definition of a safe distance, and checkers which can decide whether an autonomous vehicle is obeying the safe distance rule. Not only does our work apply to the domain of law, but it also serves as a specification for autonomous vehicle manufacturers and for online verification of path planners.","date":"June 1","id":16,"permalink":"/entries/safe_distance/","shortname":"Safe_Distance","title":"A Formally Verified Checker of the Safe Distance Traffic Rules for Autonomous Vehicles","topicLinks":["computer-science/algorithms/mathematical","mathematics/physics"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Physics"]},{"abstract":" This work presents a formal proof in Isabelle/HOL of an algorithm to transform a matrix into its Smith normal form, a canonical matrix form, in a general setting: the algorithm is parameterized by operations to prove its existence over elementary divisor rings, while execution is guaranteed over Euclidean domains. We also provide a formal proof on some results about the generality of this algorithm as well as the uniqueness of the Smith normal form.  Since Isabelle/HOL does not feature dependent types, the development is carried out switching conveniently between two different existing libraries: the Hermite normal form (based on HOL Analysis) and the Jordan normal form AFP entries. This permits to reuse results from both developments and it is done by means of the lifting and transfer package together with the use of local type definitions.","date":"May 23","id":17,"permalink":"/entries/smith_normal_form/","shortname":"Smith_Normal_Form","title":"A verified algorithm for computing the Smith normal form of a matrix","topicLinks":["mathematics/algebra","computer-science/algorithms/mathematical"],"topics":["Mathematics/Algebra","Computer science/Algorithms/Mathematical"]},{"abstract":" In 1965, Nash-Williams discovered a generalisation of the infinite form of Ramsey's theorem. Where the latter concerns infinite sets of n-element sets for some fixed n, the Nash-Williams theorem concerns infinite sets of finite sets (or lists) subject to a “no initial segment” condition. The present formalisation follows a monograph on Ramsey Spaces by Todorčević.","date":"May 16","id":18,"permalink":"/entries/nash_williams/","shortname":"Nash_Williams","title":"The Nash-Williams Partition Theorem","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" We define a generalized version of Knuth\u0026ndash;Bendix orders, including subterm coefficient functions. For these orders we formalize several properties such as strong normalization, the subterm property, closure properties under substitutions and contexts, as well as ground totality.","date":"May 13","id":19,"permalink":"/entries/knuth_bendix_order/","shortname":"Knuth_Bendix_Order","title":"A Formalization of Knuth–Bendix Orders","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" We formalise certain irrationality criteria for infinite series of the form: \\[\\sum_{n=1}^\\infty \\frac{b_n}{\\prod_{i=1}^n a_i} \\] where $\\{b_n\\}$ is a sequence of integers and $\\{a_n\\}$ a sequence of positive integers with $a_n \u003e1$ for all large n. The results are due to P. Erdős and E. G. Straus \u003ca href=\"https://projecteuclid.org/euclid.pjm/1102911140\"\u003e[1]\u003c/a\u003e. In particular, we formalise Theorem 2.1, Corollary 2.10 and Theorem 3.1. The latter is an application of Theorem 2.1 involving the prime numbers.","date":"May 12","id":20,"permalink":"/entries/irrational_series_erdos_straus/","shortname":"Irrational_Series_Erdos_Straus","title":"Irrationality Criteria for Series by Erdős and Straus","topicLinks":["mathematics/number-theory","mathematics/analysis"],"topics":["Mathematics/Number theory","Mathematics/Analysis"]},{"abstract":" This document contains a proof of the recursion theorem. This is a mechanization of the proof of the recursion theorem from the text \u003ci\u003eIntroduction to Set Theory\u003c/i\u003e, by Karel Hrbacek and Thomas Jech. This implementation may be used as the basis for a model of Peano arithmetic in ZF. While recursion and the natural numbers are already available in Isabelle/ZF, this clean development is much easier to follow.","date":"May 11","id":21,"permalink":"/entries/recursion-addition/","shortname":"Recursion-Addition","title":"Recursion Theorem in ZF","topicLinks":["logic/set-theory"],"topics":["Logic/Set theory"]},{"abstract":" In the mid 80s, Lichtenstein, Pnueli, and Zuck proved a classical theorem stating that every formula of Past LTL (the extension of LTL with past operators) is equivalent to a formula of the form $\\bigwedge_{i=1}^n \\mathbf{G}\\mathbf{F} \\varphi_i \\vee \\mathbf{F}\\mathbf{G} \\psi_i$,  where $\\varphi_i$ and $\\psi_i$ contain only past operators. Some years later, Chang, Manna, and Pnueli built on this result to derive a similar normal form for LTL. Both normalisation procedures have a non-elementary worst-case blow-up, and follow an involved path from formulas to counter-free automata to star-free regular expressions and back to formulas. We improve on both points. We present an executable formalisation of a direct and purely syntactic normalisation procedure for LTL yielding a normal form, comparable to the one by Chang, Manna, and Pnueli, that has only a single exponential blow-up.","date":"May 8","id":22,"permalink":"/entries/ltl_normal_form/","shortname":"LTL_Normal_Form","title":"An Efficient Normalisation Procedure for Linear Temporal Logic: Isabelle/HOL Formalisation","topicLinks":["computer-science/automata-and-formal-languages","logic/general-logic/temporal-logic"],"topics":["Computer science/Automata and formal languages","Logic/General logic/Temporal logic"]},{"abstract":" We formalize the theory of forcing in the set theory framework of Isabelle/ZF. Under the assumption of the existence of a countable transitive model of ZFC, we construct a proper generic extension and show that the latter also satisfies ZFC.","date":"May 6","id":23,"permalink":"/entries/forcing/","shortname":"Forcing","title":"Formalization of Forcing in Isabelle/ZF","topicLinks":["logic/set-theory"],"topics":["Logic/Set theory"]},{"abstract":" We formalize in Isabelle/HOL a result due to S. Banach and H. Steinhaus known as the Banach-Steinhaus theorem or Uniform boundedness principle: a pointwise-bounded family of continuous linear operators from a Banach space to a normed space is uniformly bounded. Our approach is an adaptation to Isabelle/HOL of a proof due to A. Sokal.","date":"May 2","id":24,"permalink":"/entries/banach_steinhaus/","shortname":"Banach_Steinhaus","title":"Banach-Steinhaus Theorem","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" In this article, we present a proof theory for Attack Trees. Attack Trees are a well established and useful model for the construction of attacks on systems since they allow a stepwise exploration of high level attacks in application scenarios. Using the expressiveness of Higher Order Logic in Isabelle, we develop a generic theory of Attack Trees with a state-based semantics based on Kripke structures and CTL. The resulting framework allows mechanically supported logic analysis of the meta-theory of the proof calculus of Attack Trees and at the same time the developed proof theory enables application to case studies. A central correctness and completeness result proved in Isabelle establishes a connection between the notion of Attack Tree validity and CTL. The application is illustrated on the example of a healthcare IoT system and GDPR compliance verification.","date":"April 27","id":25,"permalink":"/entries/attack_trees/","shortname":"Attack_Trees","title":"Attack Trees in Isabelle for GDPR compliance of IoT healthcare systems","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003eThe Gaussian integers are the subring \u0026#8484;[i] of the complex numbers, i. e. the ring of all complex numbers with integral real and imaginary part. This article provides a definition of this ring as well as proofs of various basic properties, such as that they form a Euclidean ring and a full classification of their primes. An executable (albeit not very efficient) factorisation algorithm is also provided.\u003c/p\u003e \u003cp\u003eLastly, this Gaussian integer formalisation is used in two short applications:\u003c/p\u003e \u003col\u003e \u003cli\u003e The characterisation of all positive integers that can be written as sums of two squares\u003c/li\u003e \u003cli\u003e Euclid's formula for primitive Pythagorean triples\u003c/li\u003e \u003c/ol\u003e \u003cp\u003eWhile elementary proofs for both of these are already available in the AFP, the theory of Gaussian integers provides more concise proofs and a more high-level view.\u003c/p\u003e","date":"April 24","id":26,"permalink":"/entries/gaussian_integers/","shortname":"Gaussian_Integers","title":"Gaussian Integers","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" \u003cp\u003eThis article provides a formalisation of the symmetric multivariate polynomials known as \u003cem\u003epower sum polynomials\u003c/em\u003e. These are of the form p\u003csub\u003en\u003c/sub\u003e(\u003cem\u003eX\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e,\u0026hellip;, \u003cem\u003eX\u003c/em\u003e\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e) = \u003cem\u003eX\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e\u003csup\u003en\u003c/sup\u003e + \u0026hellip; + X\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e\u003csup\u003en\u003c/sup\u003e. A formal proof of the Girard–Newton Theorem is also given. This theorem relates the power sum polynomials to the elementary symmetric polynomials s\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e in the form of a recurrence relation (-1)\u003csup\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sup\u003e \u003cem\u003ek\u003c/em\u003e s\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e = \u0026sum;\u003csub\u003ei\u0026isinv;[0,\u003cem\u003ek\u003c/em\u003e)\u003c/sub\u003e (-1)\u003csup\u003ei\u003c/sup\u003e s\u003csub\u003ei\u003c/sub\u003e p\u003csub\u003e\u003cem\u003ek\u003c/em\u003e-\u003cem\u003ei\u003c/em\u003e\u003c/sub\u003e\u0026thinsp;.\u003c/p\u003e \u003cp\u003eAs an application, this is then used to solve a generalised form of a puzzle given as an exercise in Dummit and Foote's \u003cem\u003eAbstract Algebra\u003c/em\u003e: For \u003cem\u003ek\u003c/em\u003e complex unknowns \u003cem\u003ex\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e, \u0026hellip;, \u003cem\u003ex\u003c/em\u003e\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e, define p\u003csub\u003e\u003cem\u003ej\u003c/em\u003e\u003c/sub\u003e := \u003cem\u003ex\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e\u003csup\u003e\u003cem\u003ej\u003c/em\u003e\u003c/sup\u003e + \u0026hellip; + \u003cem\u003ex\u003c/em\u003e\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e\u003csup\u003e\u003cem\u003ej\u003c/em\u003e\u003c/sup\u003e. Then for each vector \u003cem\u003ea\u003c/em\u003e \u0026isinv; \u0026#x2102;\u003csup\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sup\u003e, show that there is exactly one solution to the system p\u003csub\u003e1\u003c/sub\u003e = a\u003csub\u003e1\u003c/sub\u003e, \u0026hellip;, p\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e = a\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e up to permutation of the \u003cem\u003ex\u003c/em\u003e\u003csub\u003e\u003cem\u003ei\u003c/em\u003e\u003c/sub\u003e and determine the value of p\u003csub\u003e\u003cem\u003ei\u003c/em\u003e\u003c/sub\u003e for i\u0026gt;k.\u003c/p\u003e","date":"April 24","id":27,"permalink":"/entries/power_sum_polynomials/","shortname":"Power_Sum_Polynomials","title":"Power Sum Polynomials","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThe Lambert \u003cem\u003eW\u003c/em\u003e function is a multi-valued function defined as the inverse function of \u003cem\u003ex\u003c/em\u003e \u0026#x21A6; \u003cem\u003ex\u003c/em\u003e e\u003csup\u003e\u003cem\u003ex\u003c/em\u003e\u003c/sup\u003e. Besides numerous applications in combinatorics, physics, and engineering, it also frequently occurs when solving equations containing both e\u003csup\u003e\u003cem\u003ex\u003c/em\u003e\u003c/sup\u003e and \u003cem\u003ex\u003c/em\u003e, or both \u003cem\u003ex\u003c/em\u003e and log \u003cem\u003ex\u003c/em\u003e.\u003c/p\u003e \u003cp\u003eThis article provides a definition of the two real-valued branches \u003cem\u003eW\u003c/em\u003e\u003csub\u003e0\u003c/sub\u003e(\u003cem\u003ex\u003c/em\u003e) and \u003cem\u003eW\u003c/em\u003e\u003csub\u003e-1\u003c/sub\u003e(\u003cem\u003ex\u003c/em\u003e) and proves various properties such as basic identities and inequalities, monotonicity, differentiability, asymptotic expansions, and the MacLaurin series of \u003cem\u003eW\u003c/em\u003e\u003csub\u003e0\u003c/sub\u003e(\u003cem\u003ex\u003c/em\u003e) at \u003cem\u003ex\u003c/em\u003e = 0.\u003c/p\u003e","date":"April 24","id":28,"permalink":"/entries/lambert_w/","shortname":"Lambert_W","title":"The Lambert W Function on the Reals","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" Our theories formalise various matrix properties that serve to establish existence, uniqueness and characterisation of the solution to affine systems of ordinary differential equations (ODEs). In particular, we formalise the operator and maximum norm of matrices. Then we use them to prove that square matrices form a Banach space, and in this setting, we show an instance of Picard-Lindelöf’s theorem for affine systems of ODEs. Finally, we use this formalisation to verify three simple hybrid programs.","date":"April 19","id":29,"permalink":"/entries/matrices_for_odes/","shortname":"Matrices_for_ODEs","title":"Matrices for ODEs","topicLinks":["mathematics/analysis","mathematics/algebra"],"topics":["Mathematics/Analysis","Mathematics/Algebra"]},{"abstract":" Authenticated data structures allow several systems to convince each other that they are referring to the same data structure, even if each of them knows only a part of the data structure. Using inclusion proofs, knowledgeable systems can selectively share their knowledge with other systems and the latter can verify the authenticity of what is being shared.  In this article, we show how to modularly define authenticated data structures, their inclusion proofs, and operations thereon as datatypes in Isabelle/HOL, using a shallow embedding. Modularity allows us to construct complicated trees from reusable building blocks, which we call Merkle functors. Merkle functors include sums, products, and function spaces and are closed under composition and least fixpoints.  As a practical application, we model the hierarchical transactions of \u003ca href=\"https://www.canton.io\"\u003eCanton\u003c/a\u003e, a practical interoperability protocol for distributed ledgers, as authenticated data structures. This is a first step towards formalizing the Canton protocol and verifying its integrity and security guarantees.","date":"April 16","id":30,"permalink":"/entries/ads_functor/","shortname":"ADS_Functor","title":"Authenticated Data Structures As Functors","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" Basin et al.'s \u003ca href=\"https://doi.org/10.1016/j.ipl.2014.09.009\"\u003esliding window algorithm (SWA)\u003c/a\u003e is an algorithm for combining the elements of subsequences of a sequence with an associative operator. It is greedy and minimizes the number of operator applications. We formalize the algorithm and verify its functional correctness. We extend the algorithm with additional operations and provide an alternative interface to the slide operation that does not require the entire input sequence.","date":"April 10","id":31,"permalink":"/entries/sliding_window_algorithm/","shortname":"Sliding_Window_Algorithm","title":"Formalization of an Algorithm for Greedily Computing Associative Aggregations on Sliding Windows","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" This Isabelle/HOL formalization is the companion of the technical report “A comprehensive framework for saturation theorem proving”, itself companion of the eponym IJCAR 2020 paper, written by Uwe Waldmann, Sophie Tourret, Simon Robillard and Jasmin Blanchette. It verifies a framework for formal refutational completeness proofs of abstract provers that implement saturation calculi, such as ordered resolution or superposition, and allows to model entire prover architectures in such a way that the static refutational completeness of a calculus immediately implies the dynamic  refutational completeness of a prover implementing the calculus using a variant of the given clause loop.  The technical report “A comprehensive framework for saturation theorem proving” is available \u003ca href=\"http://matryoshka.gforge.inria.fr/pubs/satur_report.pdf\"\u003eon the Matryoshka website\u003c/a\u003e. The names of the Isabelle lemmas and theorems corresponding to the results in the report are indicated in the margin of the report.","date":"April 9","id":32,"permalink":"/entries/saturation_framework/","shortname":"Saturation_Framework","title":"A Comprehensive Framework for Saturation Theorem Proving","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" A monitor is a runtime verification tool that solves the following problem: Given a stream of time-stamped events and a policy formulated in a specification language, decide whether the policy is satisfied at every point in the stream. We verify the correctness of an executable monitor for specifications given as formulas in metric first-order dynamic logic (MFODL), which combines the features of metric first-order temporal logic (MFOTL) and metric dynamic logic. Thus, MFODL supports real-time constraints, first-order parameters, and regular expressions. Additionally, the monitor supports aggregation operations such as count and sum. This formalization, which is described in a \u003ca href=\"http://people.inf.ethz.ch/trayteld/papers/ijcar20-verimonplus/verimonplus.pdf\"\u003e forthcoming paper at IJCAR 2020\u003c/a\u003e, significantly extends \u003ca href=\"https://www.isa-afp.org/entries/MFOTL_Monitor.html\"\u003eprevious work on a verified monitor\u003c/a\u003e for MFOTL. Apart from the addition of regular expressions and aggregations, we implemented \u003ca href=\"https://www.isa-afp.org/entries/Generic_Join.html\"\u003emulti-way joins\u003c/a\u003e and a specialized sliding window algorithm to further optimize the monitor.","date":"April 9","id":33,"permalink":"/entries/mfodl_monitor_optimized/","shortname":"MFODL_Monitor_Optimized","title":"Formalization of an Optimized Monitoring Algorithm for Metric First-Order Dynamic Logic with Aggregations","topicLinks":["computer-science/algorithms","logic/general-logic/modal-logic","computer-science/automata-and-formal-languages"],"topics":["Computer science/Algorithms","Logic/General logic/Modal logic","Computer science/Automata and formal languages"]},{"abstract":" In protocol verification we observe a wide spectrum from fully automated methods to interactive theorem proving with proof assistants like Isabelle/HOL. In this AFP entry, we present a fully-automated approach for verifying stateful security protocols, i.e., protocols with mutable state that may span several sessions. The approach supports reachability goals like secrecy and authentication. We also include a simple user-friendly transaction-based protocol specification language that is embedded into Isabelle.","date":"April 8","id":34,"permalink":"/entries/automated_stateful_protocol_verification/","shortname":"Automated_Stateful_Protocol_Verification","title":"Automated Stateful Protocol Verification","topicLinks":["computer-science/security","tools"],"topics":["Computer science/Security","Tools"]},{"abstract":" We provide in this AFP entry several relative soundness results for security protocols. In particular, we prove typing and compositionality results for stateful protocols (i.e., protocols with mutable state that may span several sessions), and that focuses on reachability properties. Such results are useful to simplify protocol verification by reducing it to a simpler problem: Typing results give conditions under which it is safe to verify a protocol in a typed model where only \"well-typed\" attacks can occur whereas compositionality results allow us to verify a composed protocol by only verifying the component protocols in isolation. The conditions on the protocols under which the results hold are furthermore syntactic in nature allowing for full automation. The foundation presented here is used in another entry to provide fully automated and formalized security proofs of stateful protocols.","date":"April 8","id":35,"permalink":"/entries/stateful_protocol_composition_and_typing/","shortname":"Stateful_Protocol_Composition_and_Typing","title":"Stateful Protocol Composition and Typing","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" This work presents a formalisation of a generating function proof for Lucas's theorem. We first outline extensions to the existing Formal Power Series (FPS) library, including an equivalence relation for coefficients modulo \u003cem\u003en\u003c/em\u003e, an alternate binomial theorem statement, and a formalised proof of the Freshman's dream (mod \u003cem\u003ep\u003c/em\u003e) lemma. The second part of the work presents the formal proof of Lucas's Theorem. Working backwards, the formalisation first proves a well known corollary of the theorem which is easier to formalise, and then applies induction to prove the original theorem statement. The proof of the corollary aims to provide a good example of a formalised generating function equivalence proof using the FPS library. The final theorem statement is intended to be integrated into the formalised proof of Hilbert's 10th Problem.","date":"April 7","id":36,"permalink":"/entries/lucas_theorem/","shortname":"Lucas_Theorem","title":"Lucas's Theorem","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" Commutative Replicated Data Types (CRDTs) are a promising new class of data structures for large-scale shared mutable content in applications that only require eventual consistency. The WithOut Operational Transforms (WOOT) framework is a CRDT for collaborative text editing introduced by Oster et al. (CSCW 2006) for which the eventual consistency property was verified only for a bounded model to date. We contribute a formal proof for WOOTs strong eventual consistency.","date":"March 25","id":37,"permalink":"/entries/woot_strong_eventual_consistency/","shortname":"WOOT_Strong_Eventual_Consistency","title":"Strong Eventual Consistency of the Collaborative Editing Framework WOOT","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":" \u003cp\u003eThis article gives a formal version of Furstenberg's topological proof of the infinitude of primes. He defines a topology on the integers based on arithmetic progressions (or, equivalently, residue classes). Using some fairly obvious properties of this topology, the infinitude of primes is then easily obtained.\u003c/p\u003e \u003cp\u003eApart from this, this topology is also fairly ‘nice’ in general: it is second countable, metrizable, and perfect. All of these (well-known) facts are formally proven, including an explicit metric for the topology given by Zulfeqarr.\u003c/p\u003e","date":"March 22","id":38,"permalink":"/entries/furstenberg_topology/","shortname":"Furstenberg_Topology","title":"Furstenberg's topology and his proof of the infinitude of primes","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" Recently, authors have proposed under-approximate logics for reasoning about programs. So far, all such logics have been confined to reasoning about individual program behaviours. Yet there exist many over-approximate relational logics for reasoning about pairs of programs and relating their behaviours. We present the first under-approximate relational logic, for the simple imperative language IMP. We prove our logic is both sound and complete. Additionally, we show how reasoning in this logic can be decomposed into non-relational reasoning in an under-approximate Hoare logic, mirroring Beringer’s result for over-approximate relational logics. We illustrate the application of our logic on some small examples in which we provably demonstrate the presence of insecurity.","date":"March 12","id":39,"permalink":"/entries/relational-incorrectness-logic/","shortname":"Relational-Incorrectness-Logic","title":"An Under-Approximate Relational Logic","topicLinks":["computer-science/programming-languages/logics","computer-science/security"],"topics":["Computer science/Programming languages/Logics","Computer science/Security"]},{"abstract":" In this article, we present a formalization of the well-known \"Hello, World!\" code, including a formal framework for reasoning about IO. Our model is inspired by the handling of IO in Haskell. We start by formalizing the 🌍 and embrace the IO monad afterwards. Then we present a sample main :: IO (), followed by its proof of correctness.","date":"March 7","id":40,"permalink":"/entries/hello_world/","shortname":"Hello_World","title":"Hello World","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" In this formalization, we develop an implementation of the Goodstein function G in plain \u0026lambda;-calculus, linked to a concise, self-contained specification. The implementation works on a Church-encoded representation of countable ordinals. The initial conversion to hereditary base 2 is not covered, but the material is sufficient to compute the particular value G(16), and easily extends to other fixed arguments.","date":"February 21","id":41,"permalink":"/entries/goodstein_lambda/","shortname":"Goodstein_Lambda","title":"Implementing the Goodstein Function in \u0026lambda;-Calculus","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" This is a generic framework for formalizing compiler transformations. It leverages Isabelle/HOL’s locales to abstract over concrete languages and transformations. It states common definitions for language semantics, program behaviours, forward and backward simulations, and compilers. We provide generic operations, such as simulation and compiler composition, and prove general (partial) correctness theorems, resulting in reusable proof components.","date":"February 10","id":42,"permalink":"/entries/vericomp/","shortname":"VeriComp","title":"A Generic Framework for Verified Compilers","topicLinks":["computer-science/programming-languages/compiling"],"topics":["Computer science/Programming languages/Compiling"]},{"abstract":" This article provides a formalization of the solution obtained by the author of the Problem “ARITHMETIC PROGRESSIONS” from the \u003ca href=\"https://www.ocf.berkeley.edu/~wwu/riddles/putnam.shtml\"\u003e Putnam exam problems of 2002\u003c/a\u003e. The statement of the problem is as follows: For which integers \u003cem\u003en\u003c/em\u003e \u003e 1 does the set of positive integers less than and relatively prime to \u003cem\u003en\u003c/em\u003e constitute an arithmetic progression?","date":"February 1","id":43,"permalink":"/entries/arith_prog_rel_primes/","shortname":"Arith_Prog_Rel_Primes","title":"Arithmetic progressions and relative primes","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" We present a collection of axiom systems for the construction of Boolean subalgebras of larger overall algebras. The subalgebras are defined as the range of a complement-like operation on a semilattice. This technique has been used, for example, with the antidomain operation, dynamic negation and Stone algebras. We present a common ground for these constructions based on a new equational axiomatisation of Boolean algebras.","date":"January 31","id":44,"permalink":"/entries/subset_boolean_algebras/","shortname":"Subset_Boolean_Algebras","title":"A Hierarchy of Algebras for Boolean Subsets","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThis article provides formal proofs of basic properties of Mersenne numbers, i. e. numbers of the form 2\u003csup\u003e\u003cem\u003en\u003c/em\u003e\u003c/sup\u003e - 1, and especially of Mersenne primes.\u003c/p\u003e \u003cp\u003eIn particular, an efficient, verified, and executable version of the Lucas\u0026ndash;Lehmer test is developed. This test decides primality for Mersenne numbers in time polynomial in \u003cem\u003en\u003c/em\u003e.\u003c/p\u003e","date":"January 17","id":45,"permalink":"/entries/mersenne_primes/","shortname":"Mersenne_Primes","title":"Mersenne primes and the Lucas–Lehmer test","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" We present the first formal verification of approximation algorithms for NP-complete optimization problems: vertex cover, independent set, load balancing, and bin packing. The proofs correct incompletenesses in existing proofs and improve the approximation ratio in one case.","date":"January 16","id":46,"permalink":"/entries/approximation_algorithms/","shortname":"Approximation_Algorithms","title":"Verified Approximation Algorithms","topicLinks":["computer-science/algorithms/approximation"],"topics":["Computer science/Algorithms/Approximation"]},{"abstract":" This entry provides two related verified divide-and-conquer algorithms solving the fundamental \u003cem\u003eClosest Pair of Points\u003c/em\u003e problem in Computational Geometry. Functional correctness and the optimal running time of \u003cem\u003eO\u003c/em\u003e(\u003cem\u003en\u003c/em\u003e log \u003cem\u003en\u003c/em\u003e) are proved. Executable code is generated which is empirically competitive with handwritten reference implementations.","date":"January 13","id":47,"permalink":"/entries/closest_pair_points/","shortname":"Closest_Pair_Points","title":"Closest Pair of Points Algorithms","topicLinks":["computer-science/algorithms/geometry"],"topics":["Computer science/Algorithms/Geometry"]},{"abstract":" \u003cp\u003e Skip lists are sorted linked lists enhanced with shortcuts and are an alternative to binary search trees. A skip lists consists of multiple levels of sorted linked lists where a list on level n is a subsequence of the list on level n − 1. In the ideal case, elements are skipped in such a way that a lookup in a skip lists takes O(log n) time. In a randomised skip list the skipped elements are choosen randomly. \u003c/p\u003e \u003cp\u003e This entry contains formalized proofs of the textbook results about the expected height and the expected length of a search path in a randomised skip list. \u003c/p\u003e","date":"January 9","id":48,"permalink":"/entries/skip_lists/","shortname":"Skip_Lists","title":"Skip Lists","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" Taking as a starting point the author's previous work on developing aspects of category theory in Isabelle/HOL, this article gives a compatible formalization of the notion of \"bicategory\" and develops a framework within which formal proofs of facts about bicategories can be given.  The framework includes a number of basic results, including the Coherence Theorem, the Strictness Theorem, pseudofunctors and biequivalence, and facts about internal equivalences and adjunctions in a bicategory.  As a driving application and demonstration of the utility of the framework, it is used to give a formal proof of a theorem, due to Carboni, Kasangian, and Street, that characterizes up to biequivalence the bicategories of spans in a category with pullbacks.  The formalization effort necessitated the filling-in of many details that were not evident from the brief presentation in the original paper, as well as identifying a few minor corrections along the way.","date":"January 6","id":49,"permalink":"/entries/bicategory/","shortname":"Bicategory","title":"Bicategories","topicLinks":["mathematics/category-theory"],"topics":["Mathematics/Category theory"]},{"abstract":" \u003cp\u003eThis article provides a formalisation of Beukers's straightforward analytic proof that ζ(3) is irrational. This was first proven by Apéry (which is why this result is also often called ‘Apéry's Theorem’) using a more algebraic approach. This formalisation follows \u003ca href=\"http://people.math.sc.edu/filaseta/gradcourses/Math785/Math785Notes4.pdf\"\u003eFilaseta's presentation\u003c/a\u003e of Beukers's proof.\u003c/p\u003e","date":"December 27","id":50,"permalink":"/entries/zeta_3_irrational/","shortname":"Zeta_3_Irrational","title":"The Irrationality of ζ(3)","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" This work is a formalization of soundness and completeness proofs for a Seligman-style tableau system for hybrid logic. The completeness result is obtained via a synthetic approach using maximally consistent sets of tableau blocks. The formalization differs from previous work in a few ways. First, to avoid the need to backtrack in the construction of a tableau, the formalized system has no unnamed initial segment, and therefore no Name rule. Second, I show that the full Bridge rule is admissible in the system. Third, I start from rules restricted to only extend the branch with new formulas, including only witnessing diamonds that are not already witnessed, and show that the unrestricted rules are admissible. Similarly, I start from simpler versions of the @-rules and show that these are sufficient. The GoTo rule is restricted using a notion of potential such that each application consumes potential and potential is earned through applications of the remaining rules. I show that if a branch can be closed then it can be closed starting from a single unit. Finally, Nom is restricted by a fixed set of allowed nominals. The resulting system should be terminating.","date":"December 20","id":51,"permalink":"/entries/hybrid_logic/","shortname":"Hybrid_Logic","title":"Formalizing a Seligman-Style Tableau System for Hybrid Logic","topicLinks":["logic/general-logic/modal-logic"],"topics":["Logic/General logic/Modal logic"]},{"abstract":" The Poincaré-Bendixson theorem is a classical result in the study of (continuous) dynamical systems. Colloquially, it restricts the possible behaviors of planar dynamical systems: such systems cannot be chaotic. In practice, it is a useful tool for proving the existence of (limiting) periodic behavior in planar systems. The theorem is an interesting and challenging benchmark for formalized mathematics because proofs in the literature rely on geometric sketches and only hint at symmetric cases. It also requires a substantial background of mathematical theories, e.g., the Jordan curve theorem, real analysis, ordinary differential equations, and limiting (long-term) behavior of dynamical systems.","date":"December 18","id":52,"permalink":"/entries/poincare_bendixson/","shortname":"Poincare_Bendixson","title":"The Poincaré-Bendixson Theorem","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" A formalization of geometry of complex numbers is presented. Fundamental objects that are investigated are the complex plane extended by a single infinite point, its objects (points, lines and circles), and groups of transformations that act on them (e.g., inversions and Möbius transformations). Most objects are defined algebraically, but correspondence with classical geometric definitions is shown.","date":"December 16","id":53,"permalink":"/entries/complex_geometry/","shortname":"Complex_Geometry","title":"Complex Geometry","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" We describe formalization of the Poincaré disc model of hyperbolic geometry within the Isabelle/HOL proof assistant. The model is defined within the extended complex plane (one dimensional complex projectives space \u0026#8450;P1), formalized in the AFP entry “Complex Geometry”. Points, lines, congruence of pairs of points, betweenness of triples of points, circles, and isometries are defined within the model. It is shown that the model satisfies all Tarski's axioms except the Euclid's axiom. It is shown that it satisfies its negation and the limiting parallels axiom (which proves it to be a model of hyperbolic geometry).","date":"December 16","id":54,"permalink":"/entries/poincare_disc/","shortname":"Poincare_Disc","title":"Poincaré Disc Model","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" \u003cp\u003eThis article provides a full formalisation of Chapter 8 of Apostol's \u003cem\u003e\u003ca href=\"https://www.springer.com/de/book/9780387901633\"\u003eIntroduction to Analytic Number Theory\u003c/a\u003e\u003c/em\u003e. Subjects that are covered are:\u003c/p\u003e \u003cul\u003e \u003cli\u003eperiodic arithmetic functions and their finite Fourier series\u003c/li\u003e \u003cli\u003e(generalised) Ramanujan sums\u003c/li\u003e \u003cli\u003eGauss sums and separable characters\u003c/li\u003e \u003cli\u003einduced moduli and primitive characters\u003c/li\u003e \u003cli\u003ethe Pólya\u0026mdash;Vinogradov inequality\u003c/li\u003e \u003c/ul\u003e","date":"December 10","id":55,"permalink":"/entries/gauss_sums/","shortname":"Gauss_Sums","title":"Gauss Sums and the Pólya–Vinogradov Inequality","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" Counting sort is a well-known algorithm that sorts objects of any kind mapped to integer keys, or else to keys in one-to-one correspondence with some subset of the integers (e.g. alphabet letters). However, it is suitable for direct use, viz. not just as a subroutine of another sorting algorithm (e.g. radix sort), only if the key range is not significantly larger than the number of the objects to be sorted. This paper describes a tail-recursive generalization of counting sort making use of a bounded number of counters, suitable for direct use in case of a large, or even infinite key range of any kind, subject to the only constraint of being a subset of an arbitrary linear order. After performing a pen-and-paper analysis of how such algorithm has to be designed to maximize its efficiency, this paper formalizes the resulting generalized counting sort (GCsort) algorithm and then formally proves its correctness properties, namely that (a) the counters' number is maximized never exceeding the fixed upper bound, (b) objects are conserved, (c) objects get sorted, and (d) the algorithm is stable.","date":"December 4","id":56,"permalink":"/entries/generalized_counting_sort/","shortname":"Generalized_Counting_Sort","title":"An Efficient Generalization of Counting Sort for Large, possibly Infinite Key Ranges","topicLinks":["computer-science/algorithms","computer-science/functional-programming"],"topics":["Computer science/Algorithms","Computer science/Functional programming"]},{"abstract":" Interval_Arithmetic implements conservative interval arithmetic computations, then uses this interval arithmetic to implement a simple programming language where all terms have 32-bit signed word values, with explicit infinities for terms outside the representable bounds. Our target use case is interpreters for languages that must have a well-understood low-level behavior.  We include a formalization of bounded-length strings which are used for the identifiers of our language. Bounded-length identifiers are useful in some applications, for example the \u003ca href=\"https://www.isa-afp.org/entries/Differential_Dynamic_Logic.html\"\u003eDifferential_Dynamic_Logic\u003c/a\u003e article, where a Euclidean space indexed by identifiers demands that identifiers are finitely many.","date":"November 27","id":57,"permalink":"/entries/interval_arithmetic_word32/","shortname":"Interval_Arithmetic_Word32","title":"Interval Arithmetic on 32-bit Words","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" \u003cp\u003eThis entry is a new formalisation of ZFC set theory in Isabelle/HOL. It is logically equivalent to Obua's HOLZF; the point is to have the closest possible integration with the rest of Isabelle/HOL, minimising the amount of new notations and exploiting type classes.\u003c/p\u003e \u003cp\u003eThere is a type \u003cem\u003eV\u003c/em\u003e of sets and a function \u003cem\u003eelts :: V =\u0026gt; V set\u003c/em\u003e mapping a set to its elements. Classes simply have type \u003cem\u003eV set\u003c/em\u003e, and a predicate identifies the small classes: those that correspond to actual sets. Type classes connected with orders and lattices are used to minimise the amount of new notation for concepts such as the subset relation, union and intersection. Basic concepts — Cartesian products, disjoint sums, natural numbers, functions, etc. — are formalised.\u003c/p\u003e \u003cp\u003eMore advanced set-theoretic concepts, such as transfinite induction, ordinals, cardinals and the transitive closure of a set, are also provided. The definition of addition and multiplication for general sets (not just ordinals) follows Kirby.\u003c/p\u003e \u003cp\u003eThe theory provides two type classes with the aim of facilitating developments that combine \u003cem\u003eV\u003c/em\u003e with other Isabelle/HOL types: \u003cem\u003eembeddable\u003c/em\u003e, the class of types that can be injected into \u003cem\u003eV\u003c/em\u003e (including \u003cem\u003eV\u003c/em\u003e itself as well as \u003cem\u003eV*V\u003c/em\u003e, etc.), and \u003cem\u003esmall\u003c/em\u003e, the class of types that correspond to some ZF set.\u003c/p\u003e extra-history = Change history: [2020-01-28]:  Generalisation of the \"small\" predicate and order types to arbitrary sets; ordinal exponentiation; introduction of the coercion ord_of_nat :: \"nat =\u003e V\"; numerous new lemmas. (revision 6081d5be8d08)","date":"October 24","id":58,"permalink":"/entries/zfc_in_hol/","shortname":"ZFC_in_HOL","title":"Zermelo Fraenkel Set Theory in Higher-Order Logic","topicLinks":["logic/set-theory"],"topics":["Logic/Set theory"]},{"abstract":" We present a framework for C code in C11 syntax deeply integrated into the Isabelle/PIDE development environment. Our framework provides an abstract interface for verification back-ends to be plugged-in independently. Thus, various techniques such as deductive program verification or white-box testing can be applied to the same source, which is part of an integrated PIDE document model. Semantic back-ends are free to choose the supported C fragment and its semantics. In particular, they can differ on the chosen memory model or the specification mechanism for framing conditions. Our framework supports semantic annotations of C sources in the form of comments. Annotations serve to locally control back-end settings, and can express the term focus to which an annotation refers. Both the logical and the syntactic context are available when semantic annotations are evaluated. As a consequence, a formula in an annotation can refer both to HOL or C variables. Our approach demonstrates the degree of maturity and expressive power the Isabelle/PIDE sub-system has achieved in recent years. Our integration technique employs Lex and Yacc style grammars to ensure efficient deterministic parsing.  This is the core-module of Isabelle/C; the AFP package for Clean and Clean_wrapper as well as AutoCorres and AutoCorres_wrapper (available via git) are applications of this front-end.","date":"October 22","id":59,"permalink":"/entries/isabelle_c/","shortname":"Isabelle_C","title":"Isabelle/C","topicLinks":["computer-science/programming-languages/language-definitions","computer-science/semantics","tools"],"topics":["Computer science/Programming languages/Language definitions","Computer science/Semantics","Tools"]},{"abstract":" VerifyThis 2019 (http://www.pm.inf.ethz.ch/research/verifythis.html) was a program verification competition associated with ETAPS 2019. It was the 8th event in the VerifyThis competition series. In this entry, we present polished and completed versions of our solutions that we created during the competition.","date":"October 16","id":60,"permalink":"/entries/verifythis2019/","shortname":"VerifyThis2019","title":"VerifyThis 2019 -- Polished Isabelle Solutions","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" We formalise with Isabelle/HOL some basic elements of Aristotle's assertoric syllogistic following the \u003ca href=\"https://plato.stanford.edu/entries/aristotle-logic/\"\u003earticle from the Stanford Encyclopedia of Philosophy by Robin Smith.\u003c/a\u003e To this end, we use a set theoretic formulation (covering both individual and general predication). In particular, we formalise the deductions in the Figures and after that we present Aristotle's metatheoretical observation that all deductions in the Figures can in fact be reduced to either Barbara or Celarent. As the formal proofs prove to be straightforward, the interest of this entry lies in illustrating the functionality of Isabelle and high efficiency of Sledgehammer for simple exercises in philosophy.","date":"October 8","id":61,"permalink":"/entries/aristotles_assertoric_syllogistic/","shortname":"Aristotles_Assertoric_Syllogistic","title":"Aristotle's Assertoric Syllogistic","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":" We use CryptHOL to formalise commitment schemes and Sigma-protocols. Both are widely used fundamental two party cryptographic primitives. Security for commitment schemes is considered using game-based definitions whereas the security of Sigma-protocols is considered using both the game-based and simulation-based security paradigms. In this work, we first define security for both primitives and then prove secure multiple case studies: the Schnorr, Chaum-Pedersen and Okamoto Sigma-protocols as well as a construction that allows for compound (AND and OR statements) Sigma-protocols and the Pedersen and Rivest commitment schemes. We also prove that commitment schemes can be constructed from Sigma-protocols. We formalise this proof at an abstract level, only assuming the existence of a Sigma-protocol; consequently, the instantiations of this result for the concrete Sigma-protocols we consider come for free.","date":"October 7","id":62,"permalink":"/entries/sigma_commit_crypto/","shortname":"Sigma_Commit_Crypto","title":"Sigma Protocols and Commitment Schemes","topicLinks":["computer-science/security/cryptography"],"topics":["Computer science/Security/Cryptography"]},{"abstract":" Clean is based on a simple, abstract execution model for an imperative target language. “Abstract” is understood in contrast to “Concrete Semantics”; alternatively, the term “shallow-style embedding” could be used. It strives for a type-safe notion of program-variables, an incremental construction of the typed state-space, support of incremental verification, and open-world extensibility of new type definitions being intertwined with the program definitions. Clean is based on a “no-frills” state-exception monad with the usual definitions of bind and unit for the compositional glue of state-based computations. Clean offers conditionals and loops supporting C-like control-flow operators such as break and return. The state-space construction is based on the extensible record package. Direct recursion of procedures is supported. Clean’s design strives for extreme simplicity. It is geared towards symbolic execution and proven correct verification tools. The underlying libraries of this package, however, deliberately restrict themselves to the most elementary infrastructure for these tasks. The package is intended to serve as demonstrator semantic backend for Isabelle/C, or for the test-generation techniques.","date":"October 4","id":63,"permalink":"/entries/clean/","shortname":"Clean","title":"Clean - An Abstract Imperative Programming Language and its Theory","topicLinks":["computer-science/programming-languages","computer-science/semantics"],"topics":["Computer science/Programming languages","Computer science/Semantics"]},{"abstract":" Worst-case optimal multiway-join algorithms are recent seminal achievement of the database community. These algorithms compute the natural join of multiple relational databases and improve in the worst case over traditional query plan optimizations of nested binary joins. In 2014, \u003ca href=\"https://doi.org/10.1145/2590989.2590991\"\u003eNgo, Ré, and Rudra\u003c/a\u003e gave a unified presentation of different multi-way join algorithms. We formalized and proved correct their \"Generic Join\" algorithm and extended it to support negative joins.","date":"September 16","id":64,"permalink":"/entries/generic_join/","shortname":"Generic_Join","title":"Formalization of Multiway-Join Algorithms","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" These components formalise a semantic framework for the deductive verification of hybrid systems. They support reasoning about continuous evolutions of hybrid programs in the style of differential dynamics logic. Vector fields or flows model these evolutions, and their verification is done with invariants for the former or orbits for the latter. Laws of modal Kleene algebra or categorical predicate transformers implement the verification condition generation. Examples show the approach at work.","date":"September 10","id":65,"permalink":"/entries/hybrid_systems_vcs/","shortname":"Hybrid_Systems_VCs","title":"Verification Components for Hybrid Systems","topicLinks":["mathematics/algebra","mathematics/analysis"],"topics":["Mathematics/Algebra","Mathematics/Analysis"]},{"abstract":" This development formalises the square integrable functions over the reals and the basics of Fourier series. It culminates with a proof that every well-behaved periodic function can be approximated by a Fourier series. The material is ported from HOL Light: https://github.com/jrh13/hol-light/blob/master/100/fourier.ml","date":"September 6","id":66,"permalink":"/entries/fourier/","shortname":"Fourier","title":"Fourier Series","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" The focus of this case study is re-use in abstract algebra.  It contains locale-based formalisations of selected parts of set, group and ring theory from Jacobson's \u003ci\u003eBasic Algebra\u003c/i\u003e leading to the respective fundamental homomorphism theorems.  The study is not intended as a library base for abstract algebra.  It rather explores an approach towards abstract algebra in Isabelle.","date":"August 30","id":67,"permalink":"/entries/jacobson_basic_algebra/","shortname":"Jacobson_Basic_Algebra","title":"A Case Study in Basic Algebra","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" This entry provides a formalisation of a refinement of an adaptive state counting algorithm, used to test for reduction between finite state machines. The algorithm has been originally presented by Hierons in the paper \u003ca href=\"https://doi.org/10.1109/TC.2004.85\"\u003eTesting from a Non-Deterministic Finite State Machine Using Adaptive State Counting\u003c/a\u003e.  Definitions for finite state machines and adaptive test cases are given and many useful theorems are derived from these. The algorithm is formalised using mutually recursive functions, for which it is proven that the generated test suite is sufficient to test for reduction against finite state machines of a certain fault domain. Additionally, the algorithm is specified in a simple WHILE-language and its correctness is shown using Hoare-logic.","date":"August 16","id":68,"permalink":"/entries/adaptive_state_counting/","shortname":"Adaptive_State_Counting","title":"Formalisation of an Adaptive State Counting Algorithm","topicLinks":["computer-science/automata-and-formal-languages","computer-science/algorithms"],"topics":["Computer science/Automata and formal languages","Computer science/Algorithms"]},{"abstract":" This entry formalizes the Laplace transform and concrete Laplace transforms for arithmetic functions, frequency shift, integration and (higher) differentiation in the time domain. It proves Lerch's lemma and uniqueness of the Laplace transform for continuous functions. In order to formalize the foundational assumptions, this entry contains a formalization of piecewise continuous functions and functions of exponential order.","date":"August 14","id":69,"permalink":"/entries/laplace_transform/","shortname":"Laplace_Transform","title":"Laplace Transform","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" Communicating Concurrent Kleene Algebra (C²KA) is a mathematical framework for capturing the communicating and concurrent behaviour of agents in distributed systems. It extends Hoare et al.'s Concurrent Kleene Algebra (CKA) with communication actions through the notions of stimuli and shared environments. C²KA has applications in studying system-level properties of distributed systems such as safety, security, and reliability. In this work, we formalize results about C²KA and its application for distributed systems specification. We first formalize the stimulus structure and behaviour structure (CKA). Next, we combine them to formalize C²KA and its properties. Then, we formalize notions and properties related to the topology of distributed systems and the potential for communication via stimuli and via shared environments of agents, all within the algebraic setting of C²KA.","date":"August 6","id":70,"permalink":"/entries/c2ka_distributedsystems/","shortname":"C2KA_DistributedSystems","title":"Communicating Concurrent Kleene Algebra for Distributed Systems Specification","topicLinks":["computer-science/automata-and-formal-languages","mathematics/algebra"],"topics":["Computer science/Automata and formal languages","Mathematics/Algebra"]},{"abstract":" We use the previous formalization of the general simplex algorithm to formulate an algorithm for solving linear programs. We encode the linear programs using only linear constraints. Solving these constraints also solves the original linear program. This algorithm is proven to be sound by applying the weak duality theorem which is also part of this formalization.","date":"August 6","id":71,"permalink":"/entries/linear_programming/","shortname":"Linear_Programming","title":"Linear Programming","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThis entry contains formalisations of the answers to three of the six problem of the International Mathematical Olympiad 2019, namely Q1, Q4, and Q5.\u003c/p\u003e \u003cp\u003eThe reason why these problems were chosen is that they are particularly amenable to formalisation: they can be solved with minimal use of libraries. The remaining three concern geometry and graph theory, which, in the author's opinion, are more difficult to formalise resp. require a more complex library.\u003c/p\u003e","date":"August 5","id":72,"permalink":"/entries/imo2019/","shortname":"IMO2019","title":"Selected Problems from the International Mathematical Olympiad 2019","topicLinks":["mathematics/misc"],"topics":["Mathematics/Misc"]},{"abstract":" We formalize the static properties of personal Byzantine quorum systems (PBQSs) and Stellar quorum systems, as described in the paper ``Stellar Consensus by Reduction'' (to appear at DISC 2019).","date":"August 1","id":73,"permalink":"/entries/stellar_quorums/","shortname":"Stellar_Quorums","title":"Stellar Quorum Systems","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":" The design of complex systems involves different formalisms for modeling their different parts or aspects. The global model of a system may therefore consist of a coordination of concurrent sub-models that use different paradigms.  We develop here a theory for a language used to specify the timed coordination of such heterogeneous subsystems by addressing the following issues: \u003cul\u003e\u003cli\u003ethe behavior of the sub-systems is observed only at a series of discrete instants,\u003c/li\u003e\u003cli\u003eevents may occur in different sub-systems at unrelated times, leading to polychronous systems, which do not necessarily have a common base clock,\u003c/li\u003e\u003cli\u003ecoordination between subsystems involves causality, so the occurrence of an event may enforce the occurrence of other events, possibly after a certain duration has elapsed or an event has occurred a given number of times,\u003c/li\u003e\u003cli\u003ethe domain of time (discrete, rational, continuous...) may be different in the subsystems, leading to polytimed systems,\u003c/li\u003e\u003cli\u003ethe time frames of different sub-systems may be related (for instance, time in a GPS satellite and in a GPS receiver on Earth are related although they are not the same).\u003c/li\u003e\u003c/ul\u003e Firstly, a denotational semantics of the language is defined. Then, in order to be able to incrementally check the behavior of systems, an operational semantics is given, with proofs of progress, soundness and completeness with regard to the denotational semantics. These proofs are made according to a setup that can scale up when new operators are added to the language. In order for specifications to be composed in a clean way, the language should be invariant by stuttering (i.e., adding observation instants at which nothing happens). The proof of this invariance is also given.","date":"July 30","id":74,"permalink":"/entries/tesl_language/","shortname":"TESL_Language","title":"A Formal Development of a Polychronous Polytimed Coordination Language","topicLinks":["computer-science/system-description-languages","computer-science/semantics","computer-science/concurrency"],"topics":["Computer science/System description languages","Computer science/Semantics","Computer science/Concurrency"]},{"abstract":" We formalize the Szpilrajn extension theorem, also known as order-extension principal: Every strict partial order can be extended to a strict linear order.","date":"July 27","id":75,"permalink":"/entries/szpilrajn/","shortname":"Szpilrajn","title":"Szpilrajn Extension Theorem","topicLinks":["mathematics/order"],"topics":["Mathematics/Order"]},{"abstract":" This work formalizes soundness and completeness of a one-sided sequent calculus for first-order logic. The completeness is shown via a translation from a complete semantic tableau calculus, the proof of which is based on the First-Order Logic According to Fitting theory. The calculi and proof techniques are taken from Ben-Ari's Mathematical Logic for Computer Science.","date":"July 18","id":76,"permalink":"/entries/fol_seq_calc1/","shortname":"FOL_Seq_Calc1","title":"A Sequent Calculus for First-Order Logic","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" This entry contains the formalization that accompanies my PhD thesis (see https://lars.hupel.info/research/codegen/). I develop a verified compilation toolchain from executable specifications in Isabelle/HOL to CakeML abstract syntax trees. This improves over the state-of-the-art in Isabelle by providing a trustworthy procedure for code generation.","date":"July 8","id":77,"permalink":"/entries/cakeml_codegen/","shortname":"CakeML_Codegen","title":"A Verified Code Generator from Isabelle/HOL to CakeML","topicLinks":["computer-science/programming-languages/compiling","logic/rewriting"],"topics":["Computer science/Programming languages/Compiling","Logic/Rewriting"]},{"abstract":" A monitor is a runtime verification tool that solves the following problem: Given a stream of time-stamped events and a policy formulated in a specification language, decide whether the policy is satisfied at every point in the stream. We verify the correctness of an executable monitor for specifications given as formulas in metric first-order temporal logic (MFOTL), an expressive extension of linear temporal logic with real-time constraints and first-order quantification. The verified monitor implements a simplified variant of the algorithm used in the efficient MonPoly monitoring tool. The formalization is presented in a \u003ca href=\"https://doi.org/10.1007/978-3-030-32079-9_18\"\u003eRV 2019 paper\u003c/a\u003e, which also compares the output of the verified monitor to that of other monitoring tools on randomly generated inputs. This case study revealed several errors in the optimized but unverified tools.","date":"July 4","id":78,"permalink":"/entries/mfotl_monitor/","shortname":"MFOTL_Monitor","title":"Formalization of a Monitoring Algorithm for Metric First-Order Temporal Logic","topicLinks":["computer-science/algorithms","logic/general-logic/temporal-logic","computer-science/automata-and-formal-languages"],"topics":["Computer science/Algorithms","Logic/General logic/Temporal logic","Computer science/Automata and formal languages"]},{"abstract":" We develop an Isabelle/HOL library of order-theoretic concepts, such as various completeness conditions and fixed-point theorems. We keep our formalization as general as possible: we reprove several well-known results about complete orders, often without any properties of ordering, thus complete non-orders. In particular, we generalize the Knaster–Tarski theorem so that we ensure the existence of a quasi-fixed point of monotone maps over complete non-orders, and show that the set of quasi-fixed points is complete under a mild condition—attractivity—which is implied by either antisymmetry or transitivity. This result generalizes and strengthens a result by Stauti and Maaden. Finally, we recover Kleene’s fixed-point theorem for omega-complete non-orders, again using attractivity to prove that Kleene’s fixed points are least quasi-fixed points.","date":"June 27","id":79,"permalink":"/entries/complete_non_orders/","shortname":"Complete_Non_Orders","title":"Complete Non-Orders and Fixed Points","topicLinks":["mathematics/order"],"topics":["Mathematics/Order"]},{"abstract":" We present a new, purely functional, simple and efficient data structure combining a search tree and a priority queue, which we call a \u003cem\u003epriority search tree\u003c/em\u003e. The salient feature of priority search trees is that they offer a decrease-key operation, something that is missing from other simple, purely functional priority queue implementations. Priority search trees can be implemented on top of any search tree. This entry does the implementation for red-black trees.  This entry formalizes the first part of our ITP-2019 proof pearl \u003cem\u003ePurely Functional, Simple and Efficient Priority Search Trees and Applications to Prim and Dijkstra\u003c/em\u003e.","date":"June 25","id":80,"permalink":"/entries/priority_search_trees/","shortname":"Priority_Search_Trees","title":"Priority Search Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We verify purely functional, simple and efficient implementations of Prim's and Dijkstra's algorithms. This constitutes the first verification of an executable and even efficient version of Prim's algorithm. This entry formalizes the second part of our ITP-2019 proof pearl \u003cem\u003ePurely Functional, Simple and Efficient Priority Search Trees and Applications to Prim and Dijkstra\u003c/em\u003e.","date":"June 25","id":81,"permalink":"/entries/prim_dijkstra_simple/","shortname":"Prim_Dijkstra_Simple","title":"Purely Functional, Simple, and Efficient Implementation of Prim and Dijkstra","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":" We formalize results about linear inqualities, mainly from Schrijver's book. The main results are the proof of the fundamental theorem on linear inequalities, Farkas' lemma, Carathéodory's theorem, the Farkas-Minkowsky-Weyl theorem, the decomposition theorem of polyhedra, and Meyer's result that the integer hull of a polyhedron is a polyhedron itself. Several theorems include bounds on the appearing numbers, and in particular we provide an a-priori bound on mixed-integer solutions of linear inequalities.","date":"June 21","id":82,"permalink":"/entries/linear_inequalities/","shortname":"Linear_Inequalities","title":"Linear Inequalities","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" This entry formalizes Hilbert's Nullstellensatz, an important theorem in algebraic geometry that can be viewed as the generalization of the Fundamental Theorem of Algebra to multivariate polynomials: If a set of (multivariate) polynomials over an algebraically closed field has no common zero, then the ideal it generates is the entire polynomial ring. The formalization proves several equivalent versions of this celebrated theorem: the weak Nullstellensatz, the strong Nullstellensatz (connecting algebraic varieties and radical ideals), and the field-theoretic Nullstellensatz. The formalization follows Chapter 4.1. of \u003ca href=\"https://link.springer.com/book/10.1007/978-0-387-35651-8\"\u003eIdeals, Varieties, and Algorithms\u003c/a\u003e by Cox, Little and O'Shea.","date":"June 16","id":83,"permalink":"/entries/nullstellensatz/","shortname":"Nullstellensatz","title":"Hilbert's Nullstellensatz","topicLinks":["mathematics/algebra","mathematics/geometry"],"topics":["Mathematics/Algebra","Mathematics/Geometry"]},{"abstract":" This entry formalizes the connection between Gröbner bases and Macaulay matrices (sometimes also referred to as `generalized Sylvester matrices'). In particular, it contains a method for computing Gröbner bases, which proceeds by first constructing some Macaulay matrix of the initial set of polynomials, then row-reducing this matrix, and finally converting the result back into a set of polynomials. The output is shown to be a Gröbner basis if the Macaulay matrix constructed in the first step is sufficiently large. In order to obtain concrete upper bounds on the size of the matrix (and hence turn the method into an effectively executable algorithm), Dubé's degree bounds on Gröbner bases are utilized; consequently, they are also part of the formalization.","date":"June 15","id":84,"permalink":"/entries/groebner_macaulay/","shortname":"Groebner_Macaulay","title":"Gröbner Bases, Macaulay Matrices and Dubé's Degree Bounds","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" In this submission array-based binary minimum heaps are formalized. The correctness of the following heap operations is proved: insert, get-min, delete-min and make-heap. These are then used to verify an in-place heapsort. The formalization is based on IMP2, an imperative program verification framework implemented in Isabelle/HOL. The verified heap functions are iterative versions of the partly recursive functions found in \"Algorithms and Data Structures – The Basic Toolbox\" by K. Mehlhorn and P. Sanders and \"Introduction to Algorithms\" by T. H. Cormen, C. E. Leiserson, R. L. Rivest and C. Stein.","date":"June 13","id":85,"permalink":"/entries/imp2_binary_heap/","shortname":"IMP2_Binary_Heap","title":"Binary Heaps for IMP2","topicLinks":["computer-science/data-structures","computer-science/algorithms"],"topics":["Computer science/Data structures","Computer science/Algorithms"]},{"abstract":" This formalization provides differential game logic (dGL), a logic for proving properties of hybrid game. In addition to the syntax and semantics, it formalizes a uniform substitution calculus for dGL. Church's uniform substitutions substitute a term or formula for a function or predicate symbol everywhere. The uniform substitutions for dGL also substitute hybrid games for a game symbol everywhere. We prove soundness of one-pass uniform substitutions and the axioms of differential game logic with respect to their denotational semantics. One-pass uniform substitutions are faster by postponing soundness-critical admissibility checks with a linear pass homomorphic application and regain soundness by a variable condition at the replacements.  The formalization is based on prior non-mechanized soundness proofs for dGL.","date":"June 3","id":86,"permalink":"/entries/differential_game_logic/","shortname":"Differential_Game_Logic","title":"Differential Game Logic","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":" This entry provides a formalization of multidimensional binary trees, also known as k-d trees. It includes a balanced build algorithm as well as the nearest neighbor algorithm and the range search algorithm. It is based on the papers \u003ca href=\"https://dl.acm.org/citation.cfm?doid=361002.361007\"\u003eMultidimensional binary search trees used for associative searching\u003c/a\u003e and \u003ca href=\"https://dl.acm.org/citation.cfm?doid=355744.355745\"\u003e An Algorithm for Finding Best Matches in Logarithmic Expected Time\u003c/a\u003e.","date":"May 30","id":87,"permalink":"/entries/kd_tree/","shortname":"KD_Tree","title":"Multidimensional Binary Search Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" Authenticated data structures are a technique for outsourcing data storage and maintenance to an untrusted server. The server is required to produce an efficiently checkable and cryptographically secure proof that it carried out precisely the requested computation. \u003ca href=\"https://doi.org/10.1145/2535838.2535851\"\u003eMiller et al.\u003c/a\u003e introduced \u0026lambda;\u0026bull; (pronounced \u003ci\u003elambda auth\u003c/i\u003e)\u0026mdash;a functional programming language with a built-in primitive authentication construct, which supports a wide range of user-specified authenticated data structures while guaranteeing certain correctness and security properties for all well-typed programs. We formalize \u0026lambda;\u0026bull; and prove its correctness and security properties. With Isabelle's help, we uncover and repair several mistakes in the informal proofs and lemma statements. Our findings are summarized in a \u003ca href=\"http://people.inf.ethz.ch/trayteld/papers/lambdaauth/lambdaauth.pdf\"\u003epaper draft\u003c/a\u003e.","date":"May 14","id":88,"permalink":"/entries/lambdaauth/","shortname":"LambdaAuth","title":"Formalization of Generic Authenticated Data Structures","topicLinks":["computer-science/security","computer-science/programming-languages/lambda-calculi"],"topics":["Computer science/Security","Computer science/Programming languages/Lambda calculi"]},{"abstract":" We use CryptHOL to consider Multi-Party Computation (MPC) protocols. MPC was first considered by Yao in 1983 and recent advances in efficiency and an increased demand mean it is now deployed in the real world. Security is considered using the real/ideal world paradigm. We first define security in the semi-honest security setting where parties are assumed not to deviate from the protocol transcript. In this setting we prove multiple Oblivious Transfer (OT) protocols secure and then show security for the gates of the GMW protocol. We then define malicious security, this is a stronger notion of security where parties are assumed to be fully corrupted by an adversary. In this setting we again consider OT, as it is a fundamental building block of almost all MPC protocols.","date":"May 9","id":89,"permalink":"/entries/multi_party_computation/","shortname":"Multi_Party_Computation","title":"Multi-Party Computation","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" This is a complete formalization of the work of Hoare and Roscoe on the denotational semantics of the Failure/Divergence Model of CSP. It follows essentially the presentation of CSP in Roscoe’s Book ”Theory and Practice of Concurrency” [8] and the semantic details in a joint Paper of Roscoe and Brooks ”An improved failures model for communicating processes\".  The present work is based on a prior formalization attempt, called HOL-CSP 1.0, done in 1997 by H. Tej and B. Wolff with the Isabelle proof technology available at that time. This work revealed minor, but omnipresent foundational errors in key concepts like the process invariant. The present version HOL-CSP profits from substantially improved libraries (notably HOLCF), improved automated proof techniques, and structured proof techniques in Isar and is substantially shorter but more complete.","date":"April 26","id":90,"permalink":"/entries/hol-csp/","shortname":"HOL-CSP","title":"HOL-CSP Version 2.0","topicLinks":["computer-science/concurrency/process-calculi","computer-science/semantics"],"topics":["Computer science/Concurrency/Process calculi","Computer science/Semantics"]},{"abstract":" We present a formalisation of the unified translation approach of linear temporal logic (LTL) into ω-automata from [1]. This approach decomposes LTL formulas into ``simple'' languages and allows a clear separation of concerns: first, we formalise the purely logical result yielding this decomposition; second, we instantiate this generic theory to obtain a construction for deterministic (state-based) Rabin automata (DRA). We extract from this particular instantiation an executable tool translating LTL to DRAs. To the best of our knowledge this is the first verified translation from LTL to DRAs that is proven to be double exponential in the worst case which asymptotically matches the known lower bound. \u003cp\u003e [1] Javier Esparza, Jan Kretínský, Salomon Sickert. One Theorem to Rule Them All: A Unified Translation of LTL into ω-Automata. LICS 2018","date":"April 16","id":91,"permalink":"/entries/ltl_master_theorem/","shortname":"LTL_Master_Theorem","title":"A Compositional and Unified Translation of LTL into ω-Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" We formalize a theory of syntax with bindings that has been developed and refined over the last decade to support several large formalization efforts. Terms are defined for an arbitrary number of constructors of varying numbers of inputs, quotiented to alpha-equivalence and sorted according to a binding signature. The theory includes many properties of the standard operators on terms: substitution, swapping and freshness. It also includes bindings-aware induction and recursion principles and support for semantic interpretation. This work has been presented in the ITP 2017 paper “A Formalized General Theory of Syntax with Bindings”.","date":"April 6","id":92,"permalink":"/entries/binding_syntax_theory/","shortname":"Binding_Syntax_Theory","title":"A General Theory of Syntax with Bindings","topicLinks":["computer-science/programming-languages/lambda-calculi","computer-science/functional-programming","logic/general-logic/mechanization-of-proofs"],"topics":["Computer science/Programming languages/Lambda calculi","Computer science/Functional programming","Logic/General logic/Mechanization of proofs"]},{"abstract":" We formalize the proofs of two transcendence criteria by J. Hančl and P. Rucki that assert the transcendence of the sums of certain infinite series built up by sequences that fulfil certain properties. Both proofs make use of Roth's celebrated theorem on diophantine approximations to algebraic numbers from 1955  which we implement as an assumption without having formalised its proof.","date":"March 27","id":93,"permalink":"/entries/transcendence_series_hancl_rucki/","shortname":"Transcendence_Series_Hancl_Rucki","title":"The Transcendence of Certain Infinite Series","topicLinks":["mathematics/analysis","mathematics/number-theory"],"topics":["Mathematics/Analysis","Mathematics/Number theory"]},{"abstract":" We formalize quantum Hoare logic as given in [1]. In particular, we specify the syntax and denotational semantics of a simple model of quantum programs. Then, we write down the rules of quantum Hoare logic for partial correctness, and show the soundness and completeness of the resulting proof system. As an application, we verify the correctness of Grover’s algorithm.","date":"March 24","id":94,"permalink":"/entries/qhlprover/","shortname":"QHLProver","title":"Quantum Hoare Logic","topicLinks":["computer-science/programming-languages/logics","computer-science/semantics"],"topics":["Computer science/Programming languages/Logics","Computer science/Semantics"]},{"abstract":" \u003cp\u003eThe theory is a formalization of the \u003ca href=\"https://www.omg.org/spec/OCL/\"\u003eOCL\u003c/a\u003e type system, its abstract syntax and expression typing rules. The theory does not define a concrete syntax and a semantics. In contrast to \u003ca href=\"https://www.isa-afp.org/entries/Featherweight_OCL.html\"\u003eFeatherweight OCL\u003c/a\u003e, it is based on a deep embedding approach. The type system is defined from scratch, it is not based on the Isabelle HOL type system.\u003c/p\u003e \u003cp\u003eThe Safe OCL distincts nullable and non-nullable types. Also the theory gives a formal definition of \u003ca href=\"http://ceur-ws.org/Vol-1512/paper07.pdf\"\u003esafe navigation operations\u003c/a\u003e. The Safe OCL typing rules are much stricter than rules given in the OCL specification. It allows one to catch more errors on a type checking phase.\u003c/p\u003e \u003cp\u003eThe type theory presented is four-layered: classes, basic types, generic types, errorable types. We introduce the following new types: non-nullable types (T[1]), nullable types (T[?]), OclSuper. OclSuper is a supertype of all other types (basic types, collections, tuples). This type allows us to define a total supremum function, so types form an upper semilattice. It allows us to define rich expression typing rules in an elegant manner.\u003c/p\u003e \u003cp\u003eThe Preliminaries Chapter of the theory defines a number of helper lemmas for transitive closures and tuples. It defines also a generic object model independent from OCL. It allows one to use the theory as a reference for formalization of analogous languages.\u003c/p\u003e","date":"March 9","id":95,"permalink":"/entries/safe_ocl/","shortname":"Safe_OCL","title":"Safe OCL","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":" \u003cp\u003eThis entry is a formalisation of Chapter 4 (and parts of Chapter 3) of Apostol's \u003ca href=\"https://www.springer.com/de/book/9780387901633\"\u003e\u003cem\u003eIntroduction to Analytic Number Theory\u003c/em\u003e\u003c/a\u003e. The main topics that are addressed are properties of the distribution of prime numbers that can be shown in an elementary way (i.\u0026thinsp;e. without the Prime Number Theorem), the various equivalent forms of the PNT (which imply each other in elementary ways), and consequences that follow from the PNT in elementary ways. The latter include, most notably, asymptotic bounds for the number of distinct prime factors of \u003cem\u003en\u003c/em\u003e, the divisor function \u003cem\u003ed(n)\u003c/em\u003e, Euler's totient function \u003cem\u003e\u0026phi;(n)\u003c/em\u003e, and lcm(1,\u0026hellip;,\u003cem\u003en\u003c/em\u003e).\u003c/p\u003e","date":"February 21","id":96,"permalink":"/entries/prime_distribution_elementary/","shortname":"Prime_Distribution_Elementary","title":"Elementary Facts About the Distribution of Primes","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" This Isabelle/HOL formalization defines a greedy algorithm for finding a minimum weight basis on a weighted matroid and proves its correctness. This algorithm is an abstract version of Kruskal's algorithm.  We interpret the abstract algorithm for the cycle matroid (i.e. forests in a graph) and refine it to imperative executable code using an efficient union-find data structure.  Our formalization can be instantiated for different graph representations. We provide instantiations for undirected graphs and symmetric directed graphs.","date":"February 14","id":97,"permalink":"/entries/kruskal/","shortname":"Kruskal","title":"Kruskal's Algorithm for Minimum Spanning Forest","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":" \u003cp\u003eThe most efficient known primality tests are \u003cem\u003eprobabilistic\u003c/em\u003e in the sense that they use randomness and may, with some probability, mistakenly classify a composite number as prime \u0026ndash; but never a prime number as composite. Examples of this are the Miller\u0026ndash;Rabin test, the Solovay\u0026ndash;Strassen test, and (in most cases) Fermat's test.\u003c/p\u003e \u003cp\u003eThis entry defines these three tests and proves their correctness. It also develops some of the number-theoretic foundations, such as Carmichael numbers and the Jacobi symbol with an efficient executable algorithm to compute it.\u003c/p\u003e","date":"February 11","id":98,"permalink":"/entries/probabilistic_prime_tests/","shortname":"Probabilistic_Prime_Tests","title":"Probabilistic Primality Testing","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" We formalise results from computability theory: recursive functions, undecidability of the halting problem, and the existence of a universal Turing machine. This formalisation is the AFP entry corresponding to the paper Mechanising Turing Machines and Computability Theory in Isabelle/HOL, ITP 2013.","date":"February 8","id":99,"permalink":"/entries/universal_turing_machine/","shortname":"Universal_Turing_Machine","title":"Universal Turing Machine","topicLinks":["logic/computability","computer-science/automata-and-formal-languages"],"topics":["Logic/Computability","Computer science/Automata and formal languages"]},{"abstract":" Isabelle/UTP is a mechanised theory engineering toolkit based on Hoare and He’s Unifying Theories of Programming (UTP). UTP enables the creation of denotational, algebraic, and operational semantics for different programming languages using an alphabetised relational calculus. We provide a semantic embedding of the alphabetised relational calculus in Isabelle/HOL, including new type definitions, relational constructors, automated proof tactics, and accompanying algebraic laws. Isabelle/UTP can be used to both capture laws of programming for different languages, and put these fundamental theorems to work in the creation of associated verification tools, using calculi like Hoare logics. This document describes the relational core of the UTP in Isabelle/HOL.","date":"February 1","id":100,"permalink":"/entries/utp/","shortname":"UTP","title":"Isabelle/UTP: Mechanised Theory Engineering for Unifying Theories of Programming","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":" \u003cp\u003eThis entry defines the set of \u003cem\u003einversions\u003c/em\u003e of a list, i.e. the pairs of indices that violate sortedness. It also proves the correctness of the well-known \u003cem\u003eO\u003c/em\u003e(\u003cem\u003en log n\u003c/em\u003e) divide-and-conquer algorithm to compute the number of inversions.\u003c/p\u003e","date":"February 1","id":101,"permalink":"/entries/list_inversions/","shortname":"List_Inversions","title":"The Inversions of a List","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" We formalize a proof of Motzkin's transposition theorem and Farkas' lemma in Isabelle/HOL. Our proof is based on the formalization of the simplex algorithm which, given a set of linear constraints, either returns a satisfying assignment to the problem or detects unsatisfiability. By reusing facts about the simplex algorithm we show that a set of linear constraints is unsatisfiable if and only if there is a linear combination of the constraints which evaluates to a trivially unsatisfiable inequality.","date":"January 17","id":102,"permalink":"/entries/farkas/","shortname":"Farkas","title":"Farkas' Lemma and Motzkin's Transposition Theorem","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" In this formalization, I introduce a higher-order term algebra, generalizing the notions of free variables, matching, and substitution. The need arose from the work on a \u003ca href=\"http://dx.doi.org/10.1007/978-3-319-89884-1_35\"\u003everified compiler from Isabelle to CakeML\u003c/a\u003e. Terms can be thought of as consisting of a generic (free variables, constants, application) and a specific part. As example applications, this entry provides instantiations for de-Bruijn terms, terms with named variables, and \u003ca href=\"https://www.isa-afp.org/entries/Lambda_Free_RPOs.html\"\u003eBlanchette’s \u0026lambda;-free higher-order terms\u003c/a\u003e. Furthermore, I implement translation functions between de-Bruijn terms and named terms and prove their correctness.","date":"January 15","id":103,"permalink":"/entries/higher_order_terms/","shortname":"Higher_Order_Terms","title":"An Algebra for Higher-Order Terms","topicLinks":["computer-science/programming-languages/lambda-calculi"],"topics":["Computer science/Programming languages/Lambda calculi"]},{"abstract":" IMP2 is a simple imperative language together with Isabelle tooling to create a program verification environment in Isabelle/HOL. The tools include a C-like syntax, a verification condition generator, and Isabelle commands for the specification of programs. The framework is modular, i.e., it allows easy reuse of already proved programs within larger programs.  This entry comes with a quickstart guide and a large collection of examples, spanning basic algorithms with simple proofs to more advanced algorithms and proof techniques like data refinement. Some highlights from the examples are: \u003cul\u003e \u003cli\u003eBisection Square Root, \u003c/li\u003e \u003cli\u003eExtended Euclid,  \u003c/li\u003e \u003cli\u003eExponentiation by Squaring,  \u003c/li\u003e \u003cli\u003eBinary Search,  \u003c/li\u003e \u003cli\u003eInsertion Sort,  \u003c/li\u003e \u003cli\u003eQuicksort,  \u003c/li\u003e \u003cli\u003eDepth First Search. \u003c/li\u003e \u003c/ul\u003e  The abstract syntax and semantics are very simple and well-documented. They are suitable to be used in a course, as extension to the IMP language which comes with the Isabelle distribution.  While this entry is limited to a simple imperative language, the ideas could be extended to more sophisticated languages.","date":"January 15","id":104,"permalink":"/entries/imp2/","shortname":"IMP2","title":"IMP2 – Simple Program Verification in Isabelle/HOL","topicLinks":["computer-science/programming-languages/logics","computer-science/algorithms"],"topics":["Computer science/Programming languages/Logics","Computer science/Algorithms"]},{"abstract":" When verifying a concurrent program, it is usual to assume that memory is sequentially consistent.  However, most modern multiprocessors depend on store buffering for efficiency, and provide native sequential consistency only at a substantial performance penalty.  To regain sequential consistency, a programmer has to follow an appropriate programming discipline. However, na\u0026iuml;ve disciplines, such as protecting all shared accesses with locks, are not flexible enough for building high-performance multiprocessor software.  We present a new discipline for concurrent programming under TSO (total store order, with store buffer forwarding). It does not depend on concurrency primitives, such as locks. Instead, threads use ghost operations to acquire and release ownership of memory addresses. A thread can write to an address only if no other thread owns it, and can read from an address only if it owns it or it is shared and the thread has flushed its store buffer since it last wrote to an address it did not own. This discipline covers both coarse-grained concurrency (where data is protected by locks) as well as fine-grained concurrency (where atomic operations race to memory).  We formalize this discipline in Isabelle/HOL, and prove that if every execution of a program in a system without store buffers follows the discipline, then every execution of the program with store buffers is sequentially consistent. Thus, we can show sequential consistency under TSO by ordinary assertional reasoning about the program, without having to consider store buffers at all.","date":"January 7","id":105,"permalink":"/entries/store_buffer_reduction/","shortname":"Store_Buffer_Reduction","title":"A Reduction Theorem for Store Buffers","topicLinks":["computer-science/concurrency"],"topics":["Computer science/Concurrency"]},{"abstract":" In this AFP entry, we formalize the core of the Document Object Model (DOM).  At its core, the DOM defines a tree-like data structure for representing documents in general and HTML documents in particular. It is the heart of any modern web browser.  Formalizing the key concepts of the DOM is a prerequisite for the formal reasoning over client-side JavaScript programs and for the analysis of security concepts in modern web browsers.  We present a formalization of the core DOM, with focus on the node-tree and the operations defined on node-trees, in Isabelle/HOL. We use the formalization to verify the functional correctness of the most important functions defined in the DOM standard. Moreover, our formalization is 1) extensible, i.e., can be extended without the need of re-proving already proven properties and 2) executable, i.e., we can generate executable code from our specification.","date":"December 26","id":106,"permalink":"/entries/core_dom/","shortname":"Core_DOM","title":"A Formal Model of the Document Object Model","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" Concurrent revisions is a concurrency control model developed by Microsoft Research. It has many interesting properties that distinguish it from other well-known models such as transactional memory. One of these properties is \u003cem\u003edeterminacy\u003c/em\u003e: programs written within the model always produce the same outcome, independent of scheduling activity. The concurrent revisions model has an operational semantics, with an informal proof of determinacy. This document contains an Isabelle/HOL formalization of this semantics and the proof of determinacy.","date":"December 25","id":107,"permalink":"/entries/concurrent_revisions/","shortname":"Concurrent_Revisions","title":"Formalization of Concurrent Revisions","topicLinks":["computer-science/concurrency"],"topics":["Computer science/Concurrency"]},{"abstract":" This entry contains the application of auto2 to verifying functional and imperative programs. Algorithms and data structures that are verified include linked lists, binary search trees, red-black trees, interval trees, priority queue, quicksort, union-find, Dijkstra's algorithm, and a sweep-line algorithm for detecting rectangle intersection. The imperative verification is based on Imperative HOL and its separation logic framework. A major goal of this work is to set up automation in order to reduce the length of proof that the user needs to provide, both for verifying functional programs and for working with separation logic.","date":"December 21","id":108,"permalink":"/entries/auto2_imperative_hol/","shortname":"Auto2_Imperative_HOL","title":"Verifying Imperative Programs using Auto2","topicLinks":["computer-science/algorithms","computer-science/data-structures"],"topics":["Computer science/Algorithms","Computer science/Data structures"]},{"abstract":" Inspired by Abstract Cryptography, we extend CryptHOL, a framework for formalizing game-based proofs, with an abstract model of Random Systems and provide proof rules about their composition and equality. This foundation facilitates the formalization of Constructive Cryptography proofs, where the security of a cryptographic scheme is realized as a special form of construction in which a complex random system is built from simpler ones. This is a first step towards a fully-featured compositional framework, similar to Universal Composability framework, that supports formalization of simulation-based proofs.","date":"December 17","id":109,"permalink":"/entries/constructive_cryptography/","shortname":"Constructive_Cryptography","title":"Constructive Cryptography in HOL","topicLinks":["computer-science/security/cryptography","mathematics/probability-theory"],"topics":["Computer science/Security/Cryptography","Mathematics/Probability theory"]},{"abstract":" These components add further fundamental order and lattice-theoretic concepts and properties to Isabelle's libraries.  They follow by and large the introductory sections of the Compendium of Continuous Lattices,  covering directed and filtered sets, down-closed and up-closed sets, ideals and filters, Galois connections, closure and co-closure operators. Some emphasis is on duality and morphisms between structures, as in the Compendium.  To this end, three ad-hoc approaches to duality are compared.","date":"December 11","id":110,"permalink":"/entries/order_lattice_props/","shortname":"Order_Lattice_Props","title":"Properties of Orderings and Lattices","topicLinks":["mathematics/order"],"topics":["Mathematics/Order"]},{"abstract":" These mathematical components formalise basic properties of quantales, together with some important models, constructions, and concepts, including quantic nuclei and conuclei.","date":"December 11","id":111,"permalink":"/entries/quantales/","shortname":"Quantales","title":"Quantales","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" These mathematical components formalise predicate transformer semantics for programs, yet currently only for partial correctness and in the absence of faults.  A first part for isotone (or monotone), Sup-preserving and Inf-preserving transformers follows Back and von Wright's approach, with additional emphasis on the quantalic structure of algebras of transformers.  The second part develops Sup-preserving and Inf-preserving predicate transformers from the powerset monad, via its Kleisli category and Eilenberg-Moore algebras, with emphasis on adjunctions and dualities, as well as isomorphisms between relations, state transformers and predicate transformers.","date":"December 11","id":112,"permalink":"/entries/transformer_semantics/","shortname":"Transformer_Semantics","title":"Transformer Semantics","topicLinks":["mathematics/algebra","computer-science/semantics"],"topics":["Mathematics/Algebra","Computer science/Semantics"]},{"abstract":" This Isabelle/HOL formalization refines the abstract ordered resolution prover  presented in Section 4.3 of Bachmair and Ganzinger's \"Resolution Theorem Proving\" chapter in the \u003ci\u003eHandbook of Automated Reasoning\u003c/i\u003e. The result is a functional implementation of a first-order prover.","date":"November 23","id":113,"permalink":"/entries/functional_ordered_resolution_prover/","shortname":"Functional_Ordered_Resolution_Prover","title":"A Verified Functional Implementation of Bachmair and Ganzinger's Ordered Resolution Prover","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" This is an Isabelle/HOL formalisation of graph saturation, closely following a \u003ca href=\"https://doi.org/10.1016/j.jlamp.2018.06.005\"\u003epaper by the author\u003c/a\u003e on graph saturation. Nine out of ten lemmas of the original paper are proven in this formalisation. The formalisation additionally includes two theorems that show the main premise of the paper: that consistency and entailment are decided through graph saturation. This formalisation does not give executable code, and it did not implement any of the optimisations suggested in the paper.","date":"November 23","id":114,"permalink":"/entries/graph_saturation/","shortname":"Graph_Saturation","title":"Graph Saturation","topicLinks":["logic/rewriting","mathematics/graph-theory"],"topics":["Logic/Rewriting","Mathematics/Graph theory"]},{"abstract":" Auto2 is a saturation-based heuristic prover for higher-order logic, implemented as a tactic in Isabelle.  This entry contains the instantiation of auto2 for Isabelle/HOL, along with two basic examples: solutions to some of the Pelletier’s problems, and elementary number theory of primes.","date":"November 20","id":115,"permalink":"/entries/auto2_hol/","shortname":"Auto2_HOL","title":"Auto2 Prover","topicLinks":["tools"],"topics":["Tools"]},{"abstract":" \u003cp\u003eThis article defines the combinatorial structures known as \u003cem\u003eIndependence Systems\u003c/em\u003e and \u003cem\u003eMatroids\u003c/em\u003e and provides basic concepts and theorems related to them. These structures play an important role in combinatorial optimisation, e. g. greedy algorithms such as Kruskal's algorithm. The development is based on Oxley's \u003ca href=\"http://www.math.lsu.edu/~oxley/survey4.pdf\"\u003e`What is a Matroid?'\u003c/a\u003e.\u003c/p\u003e","date":"November 16","id":116,"permalink":"/entries/matroids/","shortname":"Matroids","title":"Matroids","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" \u003cp\u003eWe provide a framework for automatically deriving instances for generic type classes. Our approach is inspired by Haskell's \u003ci\u003egeneric-deriving\u003c/i\u003e package and Scala's \u003ci\u003eshapeless\u003c/i\u003e library.  In addition to generating the code for type class functions, we also attempt to automatically prove type class laws for these instances. As of now, however, some manual proofs are still required for recursive datatypes.\u003c/p\u003e \u003cp\u003eNote: There are already articles in the AFP that provide automatic instantiation for a number of classes. Concretely, \u003ca href=\"https://www.isa-afp.org/entries/Deriving.html\"\u003eDeriving\u003c/a\u003e allows the automatic instantiation of comparators, linear orders, equality, and hashing. \u003ca href=\"https://www.isa-afp.org/entries/Show.html\"\u003eShow\u003c/a\u003e instantiates a Haskell-style \u003ci\u003eshow\u003c/i\u003e class.\u003c/p\u003e\u003cp\u003eOur approach works for arbitrary classes (with some Isabelle/HOL overhead for each class), but a smaller set of datatypes.\u003c/p\u003e","date":"November 6","id":117,"permalink":"/entries/generic_deriving/","shortname":"Generic_Deriving","title":"Deriving generic class instances for datatypes","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" An ambitious ethical theory ---Alan Gewirth's \"Principle of Generic Consistency\"--- is encoded and analysed in Isabelle/HOL. Gewirth's theory has stirred much attention in philosophy and ethics and has been proposed as a potential means to bound the impact of artificial general intelligence.","date":"October 30","id":118,"permalink":"/entries/gewirthpgcproof/","shortname":"GewirthPGCProof","title":"Formalisation and Evaluation of Alan Gewirth's Proof for the Principle of Generic Consistency in Isabelle/HOL","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":" This work is a formalization of epistemic logic with countably many agents. It includes proofs of soundness and completeness for the axiom system K. The completeness proof is based on the textbook \"Reasoning About Knowledge\" by Fagin, Halpern, Moses and Vardi (MIT Press 1995).","date":"October 29","id":119,"permalink":"/entries/epistemic_logic/","shortname":"Epistemic_Logic","title":"Epistemic Logic","topicLinks":["logic/general-logic/logics-of-knowledge-and-belief"],"topics":["Logic/General logic/Logics of knowledge and belief"]},{"abstract":" We formalize the definition and basic properties of smooth manifolds in Isabelle/HOL. Concepts covered include partition of unity, tangent and cotangent spaces, and the fundamental theorem of path integrals. We also examine some concrete manifolds such as spheres and projective spaces. The formalization makes extensive use of the analysis and linear algebra libraries in Isabelle/HOL, in particular its “types-to-sets” mechanism.","date":"October 22","id":120,"permalink":"/entries/smooth_manifolds/","shortname":"Smooth_Manifolds","title":"Smooth Manifolds","topicLinks":["mathematics/analysis","mathematics/topology"],"topics":["Mathematics/Analysis","Mathematics/Topology"]},{"abstract":" This Isabelle/HOL formalization defines the Embedding Path Order (EPO) for higher-order terms without lambda-abstraction and proves many useful properties about it. In contrast to the lambda-free recursive path orders, it does not fully coincide with RPO on first-order terms, but it is compatible with arbitrary higher-order contexts.","date":"October 19","id":121,"permalink":"/entries/lambda_free_epo/","shortname":"Lambda_Free_EPO","title":"Formalization of the Embedding Path Order for Lambda-Free Higher-Order Terms","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" \u003cp\u003eThis work is a formalisation of the Randomised Binary Search Trees introduced by Martínez and Roura, including definitions and correctness proofs.\u003c/p\u003e \u003cp\u003eLike randomised treaps, they are a probabilistic data structure that behaves exactly as if elements were inserted into a non-balancing BST in random order. However, unlike treaps, they only use discrete probability distributions, but their use of randomness is more complicated.\u003c/p\u003e","date":"October 19","id":122,"permalink":"/entries/randomised_bsts/","shortname":"Randomised_BSTs","title":"Randomised Binary Search Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" A completeness threshold is required to guarantee the completeness of planning as satisfiability, and bounded model checking of safety properties. One valid completeness threshold is the diameter of the underlying transition system. The diameter is the maximum element in the set of lengths of all shortest paths between pairs of states. The diameter is not calculated exactly in our setting, where the transition system is succinctly described using a (propositionally) factored representation. Rather, an upper bound on the diameter is calculated compositionally, by bounding the diameters of small abstract subsystems, and then composing those.  We port a HOL4 formalisation of a compositional algorithm for computing a relatively tight upper bound on the system diameter. This compositional algorithm exploits acyclicity in the state space to achieve compositionality, and it was introduced by Abdulaziz et. al. The formalisation that we port is described as a part of another paper by Abdulaziz et. al. As a part of this porting we developed a libray about transition systems, which shall be of use in future related mechanisation efforts.","date":"October 12","id":123,"permalink":"/entries/factored_transition_system_bounding/","shortname":"Factored_Transition_System_Bounding","title":"Upper Bounding Diameters of State Spaces of Factored Transition Systems","topicLinks":["computer-science/automata-and-formal-languages","mathematics/graph-theory"],"topics":["Computer science/Automata and formal languages","Mathematics/Graph theory"]},{"abstract":" \u003cp\u003eThis entry shows the transcendence of \u0026pi; based on the classic proof using the fundamental theorem of symmetric polynomials first given by von Lindemann in 1882, but the formalisation mostly follows the version by Niven. The proof reuses much of the machinery developed in the AFP entry on the transcendence of \u003cem\u003ee\u003c/em\u003e.\u003c/p\u003e","date":"September 28","id":124,"permalink":"/entries/pi_transcendental/","shortname":"Pi_Transcendental","title":"The Transcendence of π","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" \u003cp\u003eA symmetric polynomial is a polynomial in variables \u003cem\u003eX\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e,\u0026hellip;,\u003cem\u003eX\u003c/em\u003e\u003csub\u003en\u003c/sub\u003e that does not discriminate between its variables, i.\u0026thinsp;e. it is invariant under any permutation of them. These polynomials are important in the study of the relationship between the coefficients of a univariate polynomial and its roots in its algebraic closure.\u003c/p\u003e \u003cp\u003eThis article provides a definition of symmetric polynomials and the elementary symmetric polynomials e\u003csub\u003e1\u003c/sub\u003e,\u0026hellip;,e\u003csub\u003en\u003c/sub\u003e and proofs of their basic properties, including three notable ones:\u003c/p\u003e \u003cul\u003e \u003cli\u003e Vieta's formula, which gives an explicit expression for the \u003cem\u003ek\u003c/em\u003e-th coefficient of a univariate monic polynomial in terms of its roots \u003cem\u003ex\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e,\u0026hellip;,\u003cem\u003ex\u003c/em\u003e\u003csub\u003en\u003c/sub\u003e, namely \u003cem\u003ec\u003c/em\u003e\u003csub\u003e\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e = (-1)\u003csup\u003e\u003cem\u003en\u003c/em\u003e-\u003cem\u003ek\u003c/em\u003e\u003c/sup\u003e\u0026thinsp;e\u003csub\u003e\u003cem\u003en\u003c/em\u003e-\u003cem\u003ek\u003c/em\u003e\u003c/sub\u003e(\u003cem\u003ex\u003c/em\u003e\u003csub\u003e1\u003c/sub\u003e,\u0026hellip;,\u003cem\u003ex\u003c/em\u003e\u003csub\u003en\u003c/sub\u003e).\u003c/li\u003e \u003cli\u003eSecond, the Fundamental Theorem of Symmetric Polynomials, which states that any symmetric polynomial is itself a uniquely determined polynomial combination of the elementary symmetric polynomials.\u003c/li\u003e \u003cli\u003eThird, as a corollary of the previous two, that given a polynomial over some ring \u003cem\u003eR\u003c/em\u003e, any symmetric polynomial combination of its roots is also in \u003cem\u003eR\u003c/em\u003e even when the roots are not. \u003c/ul\u003e \u003cp\u003e Both the symmetry property itself and the witness for the Fundamental Theorem are executable. \u003c/p\u003e","date":"September 25","id":125,"permalink":"/entries/symmetric_polynomials/","shortname":"Symmetric_Polynomials","title":"Symmetric Polynomials","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThis article formalizes signature-based algorithms for computing Gr\u0026ouml;bner bases. Such algorithms are, in general, superior to other algorithms in terms of efficiency, and have not been formalized in any proof assistant so far. The present development is both generic, in the sense that most known variants of signature-based algorithms are covered by it, and effectively executable on concrete input thanks to Isabelle's code generator. Sample computations of benchmark problems show that the verified implementation of signature-based algorithms indeed outperforms the existing implementation of Buchberger's algorithm in Isabelle/HOL.\u003c/p\u003e \u003cp\u003eBesides total correctness of the algorithms, the article also proves that under certain conditions they a-priori detect and avoid all useless zero-reductions, and always return 'minimal' (in some sense) Gr\u0026ouml;bner bases if an input parameter is chosen in the right way.\u003c/p\u003e\u003cp\u003eThe formalization follows the recent survey article by Eder and Faug\u0026egrave;re.\u003c/p\u003e","date":"September 20","id":126,"permalink":"/entries/signature_groebner/","shortname":"Signature_Groebner","title":"Signature-Based Gröbner Basis Algorithms","topicLinks":["mathematics/algebra","computer-science/algorithms/mathematical"],"topics":["Mathematics/Algebra","Computer science/Algorithms/Mathematical"]},{"abstract":" \u003cp\u003eThis article provides a short proof of the Prime Number Theorem in several equivalent forms, most notably \u0026pi;(\u003cem\u003ex\u003c/em\u003e) ~ \u003cem\u003ex\u003c/em\u003e/ln \u003cem\u003ex\u003c/em\u003e where \u0026pi;(\u003cem\u003ex\u003c/em\u003e) is the number of primes no larger than \u003cem\u003ex\u003c/em\u003e. It also defines other basic number-theoretic functions related to primes like Chebyshev's functions \u0026thetasym; and \u0026psi; and the \u0026ldquo;\u003cem\u003en\u003c/em\u003e-th prime number\u0026rdquo; function p\u003csub\u003e\u003cem\u003en\u003c/em\u003e\u003c/sub\u003e. We also show various bounds and relationship between these functions are shown. Lastly, we derive Mertens' First and Second Theorem, i.\u0026thinsp;e. \u0026sum;\u003csub\u003e\u003cem\u003ep\u003c/em\u003e\u0026le;\u003cem\u003ex\u003c/em\u003e\u003c/sub\u003e ln \u003cem\u003ep\u003c/em\u003e/\u003cem\u003ep\u003c/em\u003e = ln \u003cem\u003ex\u003c/em\u003e + \u003cem\u003eO\u003c/em\u003e(1) and \u0026sum;\u003csub\u003e\u003cem\u003ep\u003c/em\u003e\u0026le;\u003cem\u003ex\u003c/em\u003e\u003c/sub\u003e 1/\u003cem\u003ep\u003c/em\u003e = ln ln \u003cem\u003ex\u003c/em\u003e + M + \u003cem\u003eO\u003c/em\u003e(1/ln \u003cem\u003ex\u003c/em\u003e). We also give explicit bounds for the remainder terms.\u003c/p\u003e \u003cp\u003eThe proof of the Prime Number Theorem builds on a library of Dirichlet series and analytic combinatorics. We essentially follow the presentation by Newman. The core part of the proof is a Tauberian theorem for Dirichlet series, which is proven using complex analysis and then used to strengthen Mertens' First Theorem to \u0026sum;\u003csub\u003e\u003cem\u003ep\u003c/em\u003e\u0026le;\u003cem\u003ex\u003c/em\u003e\u003c/sub\u003e ln \u003cem\u003ep\u003c/em\u003e/\u003cem\u003ep\u003c/em\u003e = ln \u003cem\u003ex\u003c/em\u003e + c + \u003cem\u003eo\u003c/em\u003e(1).\u003c/p\u003e \u003cp\u003eA variant of this proof has been formalised before by Harrison in HOL Light, and formalisations of Selberg's elementary proof exist both by Avigad \u003cem\u003eet al.\u003c/em\u003e in Isabelle and by Carneiro in Metamath. The advantage of the analytic proof is that, while it requires more powerful mathematical tools, it is considerably shorter and clearer. This article attempts to provide a short and clear formalisation of all components of that proof using the full range of mathematical machinery available in Isabelle, staying as close as possible to Newman's simple paper proof.\u003c/p\u003e","date":"September 19","id":127,"permalink":"/entries/prime_number_theorem/","shortname":"Prime_Number_Theorem","title":"The Prime Number Theorem","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" We develop algebras for aggregation and minimisation for weight matrices and for edge weights in graphs. We verify the correctness of Prim's and Kruskal's minimum spanning tree algorithms based on these algebras. We also show numerous instances of these algebras based on linearly ordered commutative semigroups.","date":"September 15","id":128,"permalink":"/entries/aggregation_algebras/","shortname":"Aggregation_Algebras","title":"Aggregation Algebras","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" We develop the basic theory of Octonions, including various identities and properties of the octonions and of the octonionic product, a description of 7D isometries and representations of orthogonal transformations. To this end we first develop the theory of the vector cross product in 7 dimensions. The development of the theory of Octonions is inspired by that of the theory of Quaternions by Lawrence Paulson. However, we do not work within the type class real_algebra_1 because the octonionic product is not associative.","date":"September 14","id":129,"permalink":"/entries/octonions/","shortname":"Octonions","title":"Octonions","topicLinks":["mathematics/algebra","mathematics/geometry"],"topics":["Mathematics/Algebra","Mathematics/Geometry"]},{"abstract":" This theory is inspired by the HOL Light development of quaternions, but follows its own route. Quaternions are developed coinductively, as in the existing formalisation of the complex numbers. Quaternions are quickly shown to belong to the type classes of real normed division algebras and real inner product spaces. And therefore they inherit a great body of facts involving algebraic  laws, limits, continuity, etc., which must be proved explicitly in the HOL Light version.  The development concludes with the geometric interpretation of the product of imaginary quaternions.","date":"September 5","id":130,"permalink":"/entries/quaternions/","shortname":"Quaternions","title":"Quaternions","topicLinks":["mathematics/algebra","mathematics/geometry"],"topics":["Mathematics/Algebra","Mathematics/Geometry"]},{"abstract":" This entry is mainly about counting and approximating real roots (of a polynomial) with multiplicity. We have first formalised the Budan-Fourier theorem: given a polynomial with real coefficients, we can calculate sign variations on Fourier sequences to over-approximate the number of real roots (counting multiplicity) within an interval. When all roots are known to be real, the over-approximation becomes tight: we can utilise this theorem to count real roots exactly. It is also worth noting that Descartes' rule of sign is a direct consequence of the Budan-Fourier theorem, and has been included in this entry. In addition, we have extended previous formalised Sturm's theorem to count real roots with multiplicity, while the original Sturm's theorem only counts distinct real roots. Compared to the Budan-Fourier theorem, our extended Sturm's theorem always counts roots exactly but may suffer from greater computational cost.","date":"September 2","id":131,"permalink":"/entries/budan_fourier/","shortname":"Budan_Fourier","title":"The Budan-Fourier Theorem and Counting Real Roots with Multiplicity","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We present an Isabelle/HOL formalization and total correctness proof for the incremental version of the Simplex algorithm which is used in most state-of-the-art SMT solvers. It supports extraction of satisfying assignments, extraction of minimal unsatisfiable cores, incremental assertion of constraints and backtracking. The formalization relies on stepwise program refinement, starting from a simple specification, going through a number of refinement steps, and ending up in a fully executable functional implementation. Symmetries present in the algorithm are handled with special care.","date":"August 24","id":132,"permalink":"/entries/simplex/","shortname":"Simplex","title":"An Incremental Simplex Algorithm with Unsatisfiable Core Generation","topicLinks":["computer-science/algorithms/optimization"],"topics":["Computer science/Algorithms/Optimization"]},{"abstract":" \u003cp\u003e We formalize undecidablity results for Minsky machines. To this end, we also formalize recursive inseparability. \u003c/p\u003e\u003cp\u003e We start by proving that Minsky machines can compute arbitrary primitive recursive and recursive functions. We then show that there is a deterministic Minsky machine with one argument and two final states such that the set of inputs that are accepted in one state is recursively inseparable from the set of inputs that are accepted in the other state. \u003c/p\u003e\u003cp\u003e As a corollary, the set of Minsky configurations that reach the first state but not the second recursively inseparable from the set of Minsky configurations that reach the second state but not the first. In particular both these sets are undecidable. \u003c/p\u003e\u003cp\u003e We do \u003cem\u003enot\u003c/em\u003e prove that recursive functions can simulate Minsky machines. \u003c/p\u003e","date":"August 14","id":133,"permalink":"/entries/minsky_machines/","shortname":"Minsky_Machines","title":"Minsky Machines","topicLinks":["logic/computability"],"topics":["Logic/Computability"]},{"abstract":" We have formalized the computation of fair prices for derivative products in discrete financial models. As an application, we derive a way to compute fair prices of derivative products in the Cox-Ross-Rubinstein model of a financial market, thus completing the work that was presented in this \u003ca href=\"https://hal.archives-ouvertes.fr/hal-01562944\"\u003epaper\u003c/a\u003e.","date":"July 16","id":134,"permalink":"/entries/discretepricing/","shortname":"DiscretePricing","title":"Pricing in discrete financial models","topicLinks":["mathematics/probability-theory","mathematics/games-and-economics"],"topics":["Mathematics/Probability theory","Mathematics/Games and economics"]},{"abstract":" Utility functions form an essential part of game theory and economics. In order to guarantee the existence of utility functions most of the time sufficient properties are assumed in an axiomatic manner. One famous and very common set of such assumptions is that of expected utility theory. Here, the rationality, continuity, and independence of preferences is assumed. The von-Neumann-Morgenstern Utility theorem shows that these assumptions are necessary and sufficient for an expected utility function to exists. This theorem was proven by Neumann and Morgenstern in ``Theory of Games and Economic Behavior'' which is regarded as one of the most influential works in game theory. The formalization includes formal definitions of the underlying concepts including continuity and independence of preferences.","date":"July 4","id":135,"permalink":"/entries/neumann_morgenstern_utility/","shortname":"Neumann_Morgenstern_Utility","title":"Von-Neumann-Morgenstern Utility Theorem","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" \u003cp\u003e This article gives the basic theory of Pell's equation \u003cem\u003ex\u003c/em\u003e\u003csup\u003e2\u003c/sup\u003e = 1 + \u003cem\u003eD\u003c/em\u003e\u0026thinsp;\u003cem\u003ey\u003c/em\u003e\u003csup\u003e2\u003c/sup\u003e, where \u003cem\u003eD\u003c/em\u003e\u0026thinsp;\u0026isin;\u0026thinsp;\u0026#8469; is a parameter and \u003cem\u003ex\u003c/em\u003e, \u003cem\u003ey\u003c/em\u003e are integer variables. \u003c/p\u003e \u003cp\u003e The main result that is proven is the following: If \u003cem\u003eD\u003c/em\u003e is not a perfect square, then there exists a \u003cem\u003efundamental solution\u003c/em\u003e (\u003cem\u003ex\u003c/em\u003e\u003csub\u003e0\u003c/sub\u003e, \u003cem\u003ey\u003c/em\u003e\u003csub\u003e0\u003c/sub\u003e) that is not the trivial solution (1, 0) and which generates all other solutions (\u003cem\u003ex\u003c/em\u003e, \u003cem\u003ey\u003c/em\u003e) in the sense that there exists some \u003cem\u003en\u003c/em\u003e\u0026thinsp;\u0026isin;\u0026thinsp;\u0026#8469; such that |\u003cem\u003ex\u003c/em\u003e| + |\u003cem\u003ey\u003c/em\u003e|\u0026thinsp;\u0026radic;\u003cspan style=\"text-decoration: overline\"\u003e\u003cem\u003eD\u003c/em\u003e\u003c/span\u003e = (\u003cem\u003ex\u003c/em\u003e\u003csub\u003e0\u003c/sub\u003e + \u003cem\u003ey\u003c/em\u003e\u003csub\u003e0\u003c/sub\u003e\u0026thinsp;\u0026radic;\u003cspan style=\"text-decoration: overline\"\u003e\u003cem\u003eD\u003c/em\u003e\u003c/span\u003e)\u003csup\u003e\u003cem\u003en\u003c/em\u003e\u003c/sup\u003e. This also implies that the set of solutions is infinite, and it gives us an explicit and executable characterisation of all the solutions. \u003c/p\u003e \u003cp\u003e Based on this, simple executable algorithms for computing the fundamental solution and the infinite sequence of all non-negative solutions are also provided. \u003c/p\u003e","date":"June 23","id":136,"permalink":"/entries/pell/","shortname":"Pell","title":"Pell's Equation","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" We formalize the basics of projective geometry. In particular, we give a proof of the so-called Hessenberg's theorem in projective plane geometry. We also provide a proof of the so-called Desargues's theorem based on an axiomatization of (higher) projective space geometry using the notion of rank of a matroid. This last approach allows to handle incidence relations in an homogeneous way dealing only with points and without the need of talking explicitly about lines, planes or any higher entity.","date":"June 14","id":137,"permalink":"/entries/projective_geometry/","shortname":"Projective_Geometry","title":"Projective Geometry","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" We formalize the localization of a commutative ring R with respect to a multiplicative subset (i.e. a submonoid of R seen as a multiplicative monoid). This localization is itself a commutative ring and we build the natural homomorphism of rings from R to its localization.","date":"June 14","id":138,"permalink":"/entries/localization_ring/","shortname":"Localization_Ring","title":"The Localization of a Commutative Ring","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" This entry provides a formalization of the abstract theory of ample set partial order reduction. The formalization includes transition systems with actions, trace theory, as well as basics on finite, infinite, and lazy sequences. We also provide a basic framework for static analysis on concurrent systems with respect to the ample set condition.","date":"June 5","id":139,"permalink":"/entries/partial_order_reduction/","shortname":"Partial_Order_Reduction","title":"Partial Order Reduction","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" This article formalizes recursive algorithms for the construction of optimal binary search trees given fixed access frequencies. We follow Knuth (1971), Yao (1980) and Mehlhorn (1984). The algorithms are memoized with the help of the AFP article \u003ca href=\"Monad_Memo_DP.html\"\u003eMonadification, Memoization and Dynamic Programming\u003c/a\u003e, thus yielding dynamic programming algorithms.","date":"May 27","id":140,"permalink":"/entries/optimal_bst/","shortname":"Optimal_BST","title":"Optimal Binary Search Trees","topicLinks":["computer-science/algorithms","computer-science/data-structures"],"topics":["Computer science/Algorithms","Computer science/Data structures"]},{"abstract":" This entry contains a formalization of hidden Markov models [3] based on Johannes Hölzl's formalization of discrete time Markov chains [1]. The basic definitions are provided and the correctness of two main (dynamic programming) algorithms for hidden Markov models is proved: the forward algorithm for computing the likelihood of an observed sequence, and the Viterbi algorithm for decoding the most probable hidden state sequence. The Viterbi algorithm is made executable including memoization.  Hidden markov models have various applications in natural language processing. For an introduction see Jurafsky and Martin [2].","date":"May 25","id":141,"permalink":"/entries/hidden_markov_models/","shortname":"Hidden_Markov_Models","title":"Hidden Markov Models","topicLinks":["mathematics/probability-theory","computer-science/algorithms"],"topics":["Mathematics/Probability theory","Computer science/Algorithms"]},{"abstract":" We present a formalization of probabilistic timed automata (PTA) for which we try to follow the formula MDP + TA = PTA as far as possible: our work starts from our existing formalizations of Markov decision processes (MDP) and timed automata (TA) and combines them modularly. We prove the fundamental result for probabilistic timed automata: the region construction that is known from timed automata carries over to the probabilistic setting. In particular, this allows us to prove that minimum and maximum reachability probabilities can be computed via a reduction to MDP model checking, including the case where one wants to disregard unrealizable behavior. Further information can be found in our ITP paper [2].","date":"May 24","id":142,"permalink":"/entries/probabilistic_timed_automata/","shortname":"Probabilistic_Timed_Automata","title":"Probabilistic Timed Automata","topicLinks":["mathematics/probability-theory","computer-science/automata-and-formal-languages"],"topics":["Mathematics/Probability theory","Computer science/Automata and formal languages"]},{"abstract":" This document provides a concise overview on the core results of our previous work on the exploration of axioms systems for category theory. Extending the previous studies (http://arxiv.org/abs/1609.01493) we include one further axiomatic theory in our experiments. This additional theory has been suggested by Mac Lane in 1948. We show that the axioms proposed by Mac Lane are equivalent to the ones we studied before, which includes an axioms set suggested by Scott in the 1970s and another axioms set proposed by Freyd and Scedrov in 1990, which we slightly modified to remedy a minor technical issue.","date":"May 23","id":143,"permalink":"/entries/axiomaticcategorytheory/","shortname":"AxiomaticCategoryTheory","title":"Axiom Systems for Category Theory in Free Logic","topicLinks":["mathematics/category-theory"],"topics":["Mathematics/Category theory"]},{"abstract":" We formalize with Isabelle/HOL a proof of a theorem by J. Hancl asserting the irrationality of the sum of a series consisting of rational numbers, built up by sequences that fulfill certain properties. Even though the criterion is a number theoretic result, the proof makes use only of analytical arguments. We also formalize a corollary of the theorem for a specific series fulfilling the assumptions of the theorem.","date":"May 23","id":144,"permalink":"/entries/irrationality_j_hancl/","shortname":"Irrationality_J_Hancl","title":"Irrational Rapidly Convergent Series","topicLinks":["mathematics/number-theory","mathematics/analysis"],"topics":["Mathematics/Number theory","Mathematics/Analysis"]},{"abstract":" We present a lightweight framework for the automatic verified (functional or imperative) memoization of recursive functions. Our tool can turn a pure Isabelle/HOL function definition into a monadified version in a state monad or the Imperative HOL heap monad, and prove a correspondence theorem. We provide a variety of memory implementations for the two types of monads. A number of simple techniques allow us to achieve bottom-up computation and space-efficient memoization. The framework’s utility is demonstrated on a number of representative dynamic programming problems. A detailed description of our work can be found in the accompanying paper [2].","date":"May 22","id":145,"permalink":"/entries/monad_memo_dp/","shortname":"Monad_Memo_DP","title":"Monadification, Memoization and Dynamic Programming","topicLinks":["computer-science/programming-languages/transformations","computer-science/algorithms","computer-science/functional-programming"],"topics":["Computer science/Programming languages/Transformations","Computer science/Algorithms","Computer science/Functional programming"]},{"abstract":" We introduce OpSets, an executable framework for specifying and reasoning about the semantics of replicated datatypes that provide eventual consistency in a distributed system, and for mechanically verifying algorithms that implement these datatypes. Our approach is simple but expressive, allowing us to succinctly specify a variety of abstract datatypes, including maps, sets, lists, text, graphs, trees, and registers. Our datatypes are also composable, enabling the construction of complex data structures. To demonstrate the utility of OpSets for analysing replication algorithms, we highlight an important correctness property for collaborative text editing that has traditionally been overlooked; algorithms that do not satisfy this property can exhibit awkward interleaving of text. We use OpSets to specify this correctness property and prove that although one existing replication algorithm satisfies this property, several other published algorithms do not.","date":"May 10","id":146,"permalink":"/entries/opsets/","shortname":"OpSets","title":"OpSets: Sequential Specifications for Replicated Datatypes","topicLinks":["computer-science/algorithms/distributed","computer-science/data-structures"],"topics":["Computer science/Algorithms/Distributed","Computer science/Data structures"]},{"abstract":" The \"Modular Assembly Kit for Security Properties\" (MAKS) is a framework for both the definition and verification of possibilistic information-flow security properties at the specification-level. MAKS supports the uniform representation of a wide range of possibilistic information-flow properties and provides support for the verification of such properties via unwinding results and compositionality results. We provide a formalization of this framework in Isabelle/HOL.","date":"May 7","id":147,"permalink":"/entries/modular_assembly_kit_security/","shortname":"Modular_Assembly_Kit_Security","title":"An Isabelle/HOL Formalization of the Modular Assembly Kit for Security Properties","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" This is a mechanised specification of the WebAssembly language, drawn mainly from the previously published paper formalisation of Haas et al. Also included is a full proof of soundness of the type system, together with a verified type checker and interpreter. We include only a partial procedure for the extraction of the type checker and interpreter here. For more details, please see our paper in CPP 2018.","date":"April 29","id":148,"permalink":"/entries/webassembly/","shortname":"WebAssembly","title":"WebAssembly","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":" \u003ca href=\"http://www.pm.inf.ethz.ch/research/verifythis.html\"\u003eVerifyThis 2018\u003c/a\u003e was a program verification competition associated with ETAPS 2018. It was the 7th event in the VerifyThis competition series. In this entry, we present polished and completed versions of our solutions that we created during the competition.","date":"April 27","id":149,"permalink":"/entries/verifythis2018/","shortname":"VerifyThis2018","title":"VerifyThis 2018 - Polished Isabelle Solutions","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" Bounded natural functors (BNFs) provide a modular framework for the construction of (co)datatypes in higher-order logic.  Their functorial operations, the mapper and relator, are restricted to a subset of the parameters, namely those where recursion can take place.  For certain applications, such as free theorems, data refinement, quotients, and generalised rewriting, it is desirable that these operations do not ignore the other parameters.  In this article, we formalise the generalisation BNF\u003csub\u003eCC\u003c/sub\u003e that extends the mapper and relator to covariant and contravariant parameters.  We show that \u003col\u003e \u003cli\u003e BNF\u003csub\u003eCC\u003c/sub\u003es are closed under functor composition and least and greatest fixpoints,\u003c/li\u003e \u003cli\u003e subtypes inherit the BNF\u003csub\u003eCC\u003c/sub\u003e structure under conditions that generalise those for the BNF case, and\u003c/li\u003e \u003cli\u003e BNF\u003csub\u003eCC\u003c/sub\u003es preserve quotients under mild conditions.\u003c/li\u003e \u003c/ol\u003e These proofs are carried out for abstract BNF\u003csub\u003eCC\u003c/sub\u003es similar to the AFP entry BNF Operations.  In addition, we apply the BNF\u003csub\u003eCC\u003c/sub\u003e theory to several concrete functors.","date":"April 24","id":150,"permalink":"/entries/bnf_cc/","shortname":"BNF_CC","title":"Bounded Natural Functors with Covariance and Contravariance","topicLinks":["computer-science/functional-programming","tools"],"topics":["Computer science/Functional programming","Tools"]},{"abstract":" \u003cp\u003eThis formalisation contains the proof that there is no anonymous Social Choice Function for at least three agents and alternatives that fulfils both Pareto-Efficiency and Fishburn-Strategyproofness. It was derived from a proof of \u003ca href=\"http://dss.in.tum.de/files/brandt-research/stratset.pdf\"\u003eBrandt \u003cem\u003eet al.\u003c/em\u003e\u003c/a\u003e, which relies on an unverified translation of a fixed finite instance of the original problem to SAT. This Isabelle proof contains a machine-checked version of both the statement for exactly three agents and alternatives and the lifting to the general case.\u003c/p\u003e","date":"March 22","id":151,"permalink":"/entries/fishburn_impossibility/","shortname":"Fishburn_Impossibility","title":"The Incompatibility of Fishburn-Strategyproofness and Pareto-Efficiency","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" This theory provides a verified implementation of weight-balanced trees following the work of \u003ca href=\"https://doi.org/10.1017/S0956796811000104\"\u003eHirai and Yamamoto\u003c/a\u003e who proved that all parameters in a certain range are valid, i.e. guarantee that insertion and deletion preserve weight-balance. Instead of a general theorem we provide parameterized proofs of preservation of the invariant that work for many (all?) valid parameters.","date":"March 13","id":152,"permalink":"/entries/weight_balanced_trees/","shortname":"Weight_Balanced_Trees","title":"Weight-Balanced Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" CakeML is a functional programming language with a proven-correct compiler and runtime system. This entry contains an unofficial version of the CakeML semantics that has been exported from the Lem specifications to Isabelle. Additionally, there are some hand-written theory files that adapt the exported code to Isabelle and port proofs from the HOL4 formalization, e.g. termination and equivalence proofs.","date":"March 12","id":153,"permalink":"/entries/cakeml/","shortname":"CakeML","title":"CakeML","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":" The following document formalizes and verifies several architectural design patterns. Each pattern specification is formalized in terms of a locale where the locale assumptions correspond to the assumptions which a pattern poses on an architecture. Thus, pattern specifications may build on top of each other by interpreting the corresponding locale. A pattern is verified using the framework provided by the AFP entry Dynamic Architectures. Currently, the document consists of formalizations of 4 different patterns: the singleton, the publisher subscriber, the blackboard pattern, and the blockchain pattern. Thereby, the publisher component of the publisher subscriber pattern is modeled as an instance of the singleton pattern and the blackboard pattern is modeled as an instance of the publisher subscriber pattern. In general, this entry provides the first steps towards an overall theory of architectural design patterns.","date":"March 1","id":154,"permalink":"/entries/architectural_design_patterns/","shortname":"Architectural_Design_Patterns","title":"A Theory of Architectural Design Patterns","topicLinks":["computer-science/system-description-languages"],"topics":["Computer science/System description languages"]},{"abstract":" We study three different Hoare logics for reasoning about time bounds of imperative programs and formalize them in Isabelle/HOL: a classical Hoare like logic due to Nielson, a logic with potentials due to Carbonneaux \u003ci\u003eet al.\u003c/i\u003e and a \u003ci\u003eseparation logic\u003c/i\u003e following work by Atkey, Chaguérand and Pottier. These logics are formally shown to be sound and complete. Verification condition generators are developed and are shown sound and complete too.  We also consider variants of the systems where we abstract from multiplicative constants in the running time bounds, thus supporting a big-O style of reasoning.  Finally we compare the expressive power of the three systems.","date":"February 26","id":155,"permalink":"/entries/hoare_time/","shortname":"Hoare_Time","title":"Hoare Logics for Time Bounds","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":" Short vectors in lattices and factors of integer polynomials are related. Each factor of an integer polynomial belongs to a certain lattice. When factoring polynomials, the condition that we are looking for an irreducible polynomial means that we must look for a small element in a lattice, which can be done by a basis reduction algorithm. In this development we formalize this connection and thereby one main application of the LLL basis reduction algorithm: an algorithm to factor square-free integer polynomials which runs in polynomial time. The work is based on our previous Berlekamp–Zassenhaus development, where the exponential reconstruction phase has been replaced by the polynomial-time basis reduction algorithm. Thanks to this formalization we found a serious flaw in a textbook.","date":"February 6","id":156,"permalink":"/entries/lll_factorization/","shortname":"LLL_Factorization","title":"A verified factorization algorithm for integer polynomials with polynomial complexity","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" We formalize basic results on first-order terms, including matching and a first-order unification algorithm, as well as well-foundedness of the subsumption order. This entry is part of the \u003ci\u003eIsabelle Formalization of Rewriting\u003c/i\u003e \u003ca href=\"http://cl-informatik.uibk.ac.at/isafor\"\u003eIsaFoR\u003c/a\u003e, where first-order terms are omni-present: the unification algorithm is used to certify several confluence and termination techniques, like critical-pair computation and dependency graph approximations; and the subsumption order is a crucial ingredient for completion.","date":"February 6","id":157,"permalink":"/entries/first_order_terms/","shortname":"First_Order_Terms","title":"First-Order Terms","topicLinks":["logic/rewriting","computer-science/algorithms"],"topics":["Logic/Rewriting","Computer science/Algorithms"]},{"abstract":" \u003cp\u003e This entry provides the definitions and basic properties of the complex and real error function erf and the complementary error function erfc. Additionally, it gives their full asymptotic expansions. \u003c/p\u003e","date":"February 6","id":158,"permalink":"/entries/error_function/","shortname":"Error_Function","title":"The Error Function","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" \u003cp\u003e A Treap is a binary tree whose nodes contain pairs consisting of some payload and an associated priority. It must have the search-tree property w.r.t. the payloads and the heap property w.r.t. the priorities. Treaps are an interesting data structure that is related to binary search trees (BSTs) in the following way: if one forgets all the priorities of a treap, the resulting BST is exactly the same as if one had inserted the elements into an empty BST in order of ascending priority. This means that a treap behaves like a BST where we can pretend the elements were inserted in a different order from the one in which they were actually inserted. \u003c/p\u003e \u003cp\u003e In particular, by choosing these priorities at random upon insertion of an element, we can pretend that we inserted the elements in \u003cem\u003erandom order\u003c/em\u003e, so that the shape of the resulting tree is that of a random BST no matter in what order we insert the elements. This is the main result of this formalisation.\u003c/p\u003e","date":"February 6","id":159,"permalink":"/entries/treaps/","shortname":"Treaps","title":"Treaps","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" The Lenstra-Lenstra-Lovász basis reduction algorithm, also known as LLL algorithm, is an algorithm to find a basis with short, nearly orthogonal vectors of an integer lattice. Thereby, it can also be seen as an approximation to solve the shortest vector problem (SVP), which is an NP-hard problem, where the approximation quality solely depends on the dimension of the lattice, but not the lattice itself. The algorithm also possesses many applications in diverse fields of computer science, from cryptanalysis to number theory, but it is specially well-known since it was used to implement the first polynomial-time algorithm to factor polynomials. In this work we present the first mechanized soundness proof of the LLL algorithm to compute short vectors in lattices. The formalization follows a textbook by von zur Gathen and Gerhard.","date":"February 2","id":160,"permalink":"/entries/lll_basis_reduction/","shortname":"LLL_Basis_Reduction","title":"A verified LLL algorithm","topicLinks":["computer-science/algorithms/mathematical","mathematics/algebra"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Algebra"]},{"abstract":" This Isabelle/HOL formalization covers Sections 2 to 4 of Bachmair and Ganzinger's \"Resolution Theorem Proving\" chapter in the \u003cem\u003eHandbook of Automated Reasoning\u003c/em\u003e. This includes soundness and completeness of unordered and ordered variants of ground resolution with and without literal selection, the standard redundancy criterion, a general framework for refutational theorem proving, and soundness and completeness of an abstract first-order prover.","date":"January 18","id":161,"permalink":"/entries/ordered_resolution_prover/","shortname":"Ordered_Resolution_Prover","title":"Formalization of Bachmair and Ganzinger's Ordered Resolution Prover","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" A geodesic metric space is Gromov hyperbolic if all its geodesic triangles are thin, i.e., every side is contained in a fixed thickening of the two other sides. While this definition looks innocuous, it has proved extremely important and versatile in modern geometry since its introduction by Gromov.  We formalize the basic classical properties of Gromov hyperbolic spaces, notably the Morse lemma asserting that quasigeodesics are close to geodesics, the invariance of hyperbolicity under quasi-isometries, we define and study the Gromov boundary and its associated distance, and prove that a quasi-isometry between Gromov hyperbolic spaces extends to a homeomorphism of the boundaries. We also prove a less classical theorem, by Bonk and Schramm, asserting that a Gromov hyperbolic space embeds isometrically in a geodesic Gromov-hyperbolic space. As the original proof uses a transfinite sequence of Cauchy completions, this is an interesting formalization exercise.  Along the way, we introduce basic material on isometries, quasi-isometries, Lipschitz maps, geodesic spaces, the Hausdorff distance, the Cauchy completion of a metric space, and the exponential on extended real numbers.","date":"January 16","id":162,"permalink":"/entries/gromov_hyperbolicity/","shortname":"Gromov_Hyperbolicity","title":"Gromov Hyperbolicity","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" We formalise a statement of Green’s theorem—the first formalisation to our knowledge—in Isabelle/HOL. The theorem statement that we formalise is enough for most applications, especially in physics and engineering. Our formalisation is made possible by a novel proof that avoids the ubiquitous line integral cancellation argument. This eliminates the need to formalise orientations and region boundaries explicitly with respect to the outwards-pointing normal vector. Instead we appeal to a homological argument about equivalences between paths.","date":"January 11","id":163,"permalink":"/entries/green/","shortname":"Green","title":"An Isabelle/HOL formalisation of Green's Theorem","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We present a formally verified implementation of multivariate Taylor models. Taylor models are a form of rigorous polynomial approximation, consisting of an approximation polynomial based on Taylor expansions, combined with a rigorous bound on the approximation error. Taylor models were introduced as a tool to mitigate the dependency problem of interval arithmetic. Our implementation automatically computes Taylor models for the class of elementary functions, expressed by composition of arithmetic operations and basic functions like exp, sin, or square root.","date":"January 8","id":164,"permalink":"/entries/taylor_models/","shortname":"Taylor_Models","title":"Taylor Models","topicLinks":["computer-science/algorithms/mathematical","computer-science/data-structures","mathematics/analysis","mathematics/algebra"],"topics":["Computer science/Algorithms/Mathematical","Computer science/Data structures","Mathematics/Analysis","Mathematics/Algebra"]},{"abstract":" This entry shows that the falling factorial of a sum can be computed with an expression using binomial coefficients and the falling factorial of its summands. The entry provides three different proofs: a combinatorial proof, an induction proof and an algebraic proof using the Vandermonde identity.  The three formalizations try to follow their informal presentations from a Mathematics Stack Exchange page as close as possible. The induction and algebraic formalization end up to be very close to their informal presentation, whereas the combinatorial proof first requires the introduction of list interleavings, and significant more detail than its informal presentation.","date":"December 22","id":165,"permalink":"/entries/falling_factorial_sum/","shortname":"Falling_Factorial_Sum","title":"The Falling Factorial of a Sum","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" \u003cp\u003eThis article provides a formalisation of Dirichlet characters and Dirichlet \u003cem\u003eL\u003c/em\u003e-functions including proofs of their basic properties \u0026ndash; most notably their analyticity, their areas of convergence, and their non-vanishing for \u0026Re;(s) \u0026ge; 1. All of this is built in a very high-level style using Dirichlet series. The proof of the non-vanishing follows a very short and elegant proof by Newman, which we attempt to reproduce faithfully in a similar level of abstraction in Isabelle.\u003c/p\u003e \u003cp\u003eThis also leads to a relatively short proof of Dirichlet’s Theorem, which states that, if \u003cem\u003eh\u003c/em\u003e and \u003cem\u003en\u003c/em\u003e are coprime, there are infinitely many primes \u003cem\u003ep\u003c/em\u003e with \u003cem\u003ep\u003c/em\u003e \u0026equiv; \u003cem\u003eh\u003c/em\u003e (mod \u003cem\u003en\u003c/em\u003e).\u003c/p\u003e","date":"December 21","id":166,"permalink":"/entries/dirichlet_l/","shortname":"Dirichlet_L","title":"Dirichlet L-Functions and Dirichlet's Theorem","topicLinks":["mathematics/number-theory","mathematics/algebra"],"topics":["Mathematics/Number theory","Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThis article provides a formalisation of Snyder’s simple and elegant proof of the Mason\u0026ndash;Stothers theorem, which is the polynomial analogue of the famous abc Conjecture for integers. Remarkably, Snyder found this very elegant proof when he was still a high-school student.\u003c/p\u003e \u003cp\u003eIn short, the statement of the theorem is that three non-zero coprime polynomials \u003cem\u003eA\u003c/em\u003e, \u003cem\u003eB\u003c/em\u003e, \u003cem\u003eC\u003c/em\u003e over a field which sum to 0 and do not all have vanishing derivatives fulfil max{deg(\u003cem\u003eA\u003c/em\u003e), deg(\u003cem\u003eB\u003c/em\u003e), deg(\u003cem\u003eC\u003c/em\u003e)} \u003c deg(rad(\u003cem\u003eABC\u003c/em\u003e)) where the rad(\u003cem\u003eP\u003c/em\u003e) denotes the \u003cem\u003eradical\u003c/em\u003e of \u003cem\u003eP\u003c/em\u003e, i.\u0026thinsp;e. the product of all unique irreducible factors of \u003cem\u003eP\u003c/em\u003e.\u003c/p\u003e \u003cp\u003eThis theorem also implies a kind of polynomial analogue of Fermat’s Last Theorem for polynomials: except for trivial cases, \u003cem\u003eA\u003csup\u003en\u003c/sup\u003e\u003c/em\u003e + \u003cem\u003eB\u003csup\u003en\u003c/sup\u003e\u003c/em\u003e + \u003cem\u003eC\u003csup\u003en\u003c/sup\u003e\u003c/em\u003e = 0 implies n\u0026nbsp;\u0026le;\u0026nbsp;2 for coprime polynomials \u003cem\u003eA\u003c/em\u003e, \u003cem\u003eB\u003c/em\u003e, \u003cem\u003eC\u003c/em\u003e over a field.\u003c/em\u003e\u003c/p\u003e","date":"December 21","id":167,"permalink":"/entries/mason_stothers/","shortname":"Mason_Stothers","title":"The Mason–Stothers Theorem","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThis entry provides an executable functional implementation of the Median-of-Medians algorithm for selecting the \u003cem\u003ek\u003c/em\u003e-th smallest element of an unsorted list deterministically in linear time. The size bounds for the recursive call that lead to the linear upper bound on the run-time of the algorithm are also proven. \u003c/p\u003e","date":"December 21","id":168,"permalink":"/entries/median_of_medians_selection/","shortname":"Median_Of_Medians_Selection","title":"The Median-of-Medians Selection Algorithm","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" This entry formalizes the closure property of bounded natural functors (BNFs) under seven operations. These operations and the corresponding proofs constitute the core of Isabelle's (co)datatype package. To be close to the implemented tactics, the proofs are deliberately formulated as detailed apply scripts. The (co)datatypes together with (co)induction principles and (co)recursors are byproducts of the fixpoint operations LFP and GFP. Composition of BNFs is subdivided into four simpler operations: Compose, Kill, Lift, and Permute. The N2M operation provides mutual (co)induction principles and (co)recursors for nested (co)datatypes.","date":"December 19","id":169,"permalink":"/entries/bnf_operations/","shortname":"BNF_Operations","title":"Operations on Bounded Natural Functors","topicLinks":["tools"],"topics":["Tools"]},{"abstract":" The Knuth-Morris-Pratt algorithm is often used to show that the problem of finding a string \u003ci\u003es\u003c/i\u003e in a text \u003ci\u003et\u003c/i\u003e can be solved deterministically in \u003ci\u003eO(|s| + |t|)\u003c/i\u003e time. We use the Isabelle Refinement Framework to formulate and verify the algorithm. Via refinement, we apply some optimisations and finally use the \u003cem\u003eSepref\u003c/em\u003e tool to obtain executable code in \u003cem\u003eImperative/HOL\u003c/em\u003e.","date":"December 18","id":170,"permalink":"/entries/knuth_morris_pratt/","shortname":"Knuth_Morris_Pratt","title":"The string search algorithm by Knuth, Morris and Pratt","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" Stochastic matrices are a convenient way to model discrete-time and finite state Markov chains. The Perron\u0026ndash;Frobenius theorem tells us something about the existence and uniqueness of non-negative eigenvectors of a stochastic matrix.  In this entry, we formalize stochastic matrices, link the formalization to the existing AFP-entry on Markov chains, and apply the Perron\u0026ndash;Frobenius theorem to prove that stationary distributions always exist, and they are unique if the stochastic matrix is irreducible.","date":"November 22","id":171,"permalink":"/entries/stochastic_matrices/","shortname":"Stochastic_Matrices","title":"Stochastic Matrices and the Perron-Frobenius Theorem","topicLinks":["mathematics/algebra","computer-science/automata-and-formal-languages"],"topics":["Mathematics/Algebra","Computer science/Automata and formal languages"]},{"abstract":" We provide our Isabelle/HOL formalization of a Conflict-free Replicated Datatype for Internet Message Access Protocol commands. We show that Strong Eventual Consistency (SEC) is guaranteed by proving the commutativity of concurrent operations. We base our formalization on the recently proposed \"framework for establishing Strong Eventual Consistency for Conflict-free Replicated Datatypes\" (AFP.CRDT) from Gomes et al. Hence, we provide an additional example of how the recently proposed framework can be used to design and prove CRDTs.","date":"November 9","id":172,"permalink":"/entries/imap-crdt/","shortname":"IMAP-CRDT","title":"The IMAP CmRDT","topicLinks":["computer-science/algorithms/distributed","computer-science/data-structures"],"topics":["Computer science/Algorithms/Distributed","Computer science/Data structures"]},{"abstract":" We present a semantic embedding of a spatio-temporal multi-modal logic, specifically defined to reason about motorway traffic, into Isabelle/HOL. The semantic model is an abstraction of a motorway, emphasising local spatial properties, and parameterised by the types of sensors deployed in the vehicles. We use the logic to define controller constraints to ensure safety, i.e., the absence of collisions on the motorway. After proving safety with a restrictive definition of sensors, we relax these assumptions and show how to amend the controller constraints to still guarantee safety.","date":"November 6","id":173,"permalink":"/entries/hybrid_multi_lane_spatial_logic/","shortname":"Hybrid_Multi_Lane_Spatial_Logic","title":"Hybrid Multi-Lane Spatial Logic","topicLinks":["logic/general-logic/modal-logic"],"topics":["Logic/General logic/Modal logic"]},{"abstract":" We discuss a topological curiosity discovered by Kuratowski (1922): the fact that the number of distinct operators on a topological space generated by compositions of closure and complement never exceeds 14, and is exactly 14 in the case of R. In addition, we prove a theorem due to Chagrov (1982) that classifies topological spaces according to the number of such operators they support.","date":"October 26","id":174,"permalink":"/entries/kuratowski_closure_complement/","shortname":"Kuratowski_Closure_Complement","title":"The Kuratowski Closure-Complement Theorem","topicLinks":["mathematics/topology"],"topics":["Mathematics/Topology"]},{"abstract":" This entry provides a verified implementation of rank-based Büchi Complementation. The verification is done in three steps: \u003col\u003e \u003cli\u003eDefinition of odd rankings and proof that an automaton rejects a word iff there exists an odd ranking for it.\u003c/li\u003e \u003cli\u003eDefinition of the complement automaton and proof that it accepts exactly those words for which there is an odd ranking.\u003c/li\u003e \u003cli\u003eVerified implementation of the complement automaton using the Isabelle Collections Framework.\u003c/li\u003e \u003c/ol\u003e","date":"October 19","id":175,"permalink":"/entries/buchi_complementation/","shortname":"Buchi_Complementation","title":"Büchi Complementation","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" This entry provides a very abstract theory of transition systems that can be instantiated to express various types of automata. A transition system is typically instantiated by providing a set of initial states, a predicate for enabled transitions, and a transition execution function. From this, it defines the concepts of finite and infinite paths as well as the set of reachable states, among other things. Many useful theorems, from basic path manipulation rules to coinduction and run construction rules, are proven in this abstract transition system context. The library comes with instantiations for DFAs, NFAs, and Büchi automata.","date":"October 19","id":176,"permalink":"/entries/transition_systems_and_automata/","shortname":"Transition_Systems_and_Automata","title":"Transition Systems and Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" Based on evaluating Cauchy indices through remainder sequences, this entry provides an effective procedure to count the number of complex roots (with multiplicity) of a polynomial within a rectangle box or a half-plane. Potential applications of this entry include certified complex root isolation (of a polynomial) and testing the Routh-Hurwitz stability criterion (i.e., to check whether all the roots of some characteristic polynomial have negative real parts).","date":"October 17","id":177,"permalink":"/entries/count_complex_roots/","shortname":"Count_Complex_Roots","title":"Count the Number of Complex Roots","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" In complex analysis, the winding number measures the number of times a path (counterclockwise) winds around a point, while the Cauchy index can approximate how the path winds. This entry provides a formalisation of the Cauchy index, which is then shown to be related to the winding number. In addition, this entry also offers a tactic that enables users to evaluate the winding number by calculating Cauchy indices.","date":"October 17","id":178,"permalink":"/entries/winding_number_eval/","shortname":"Winding_Number_Eval","title":"Evaluate Winding Numbers through Cauchy Indices","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We formalize the theory of homogeneous linear diophantine equations, focusing on two main results: (1) an abstract characterization of minimal complete sets of solutions, and (2) an algorithm computing them. Both, the characterization and the algorithm are based on previous work by Huet. Our starting point is a simple but inefficient variant of Huet's lexicographic algorithm incorporating improved bounds due to Clausen and Fortenbacher. We proceed by proving its soundness and completeness. Finally, we employ code equations to obtain a reasonably efficient implementation. Thus, we provide a formally verified solver for homogeneous linear diophantine equations.","date":"October 14","id":179,"permalink":"/entries/diophantine_eqns_lin_hom/","shortname":"Diophantine_Eqns_Lin_Hom","title":"Homogeneous Linear Diophantine Equations","topicLinks":["computer-science/algorithms/mathematical","mathematics/number-theory","tools"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Number theory","Tools"]},{"abstract":" This entry is a formalisation of much of Chapters 2, 3, and 11 of Apostol's \u0026ldquo;Introduction to Analytic Number Theory\u0026rdquo;. This includes: \u003cul\u003e \u003cli\u003eDefinitions and basic properties for several number-theoretic functions (Euler's \u0026phi;, M\u0026ouml;bius \u0026mu;, Liouville's \u0026lambda;, the divisor function \u0026sigma;, von Mangoldt's \u0026Lambda;)\u003c/li\u003e \u003cli\u003eExecutable code for most of these functions, the most efficient implementations using the factoring algorithm by Thiemann \u003ci\u003eet al.\u003c/i\u003e\u003c/li\u003e \u003cli\u003eDirichlet products and formal Dirichlet series\u003c/li\u003e \u003cli\u003eAnalytic results connecting convergent formal Dirichlet series to complex functions\u003c/li\u003e \u003cli\u003eEuler product expansions\u003c/li\u003e \u003cli\u003eAsymptotic estimates of number-theoretic functions including the density of squarefree integers and the average number of divisors of a natural number\u003c/li\u003e \u003c/ul\u003e These results are useful as a basis for developing more number-theoretic results, such as the Prime Number Theorem.","date":"October 12","id":180,"permalink":"/entries/dirichlet_series/","shortname":"Dirichlet_Series","title":"Dirichlet Series","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" \u003cp\u003e Linear recurrences with constant coefficients are an interesting class of recurrence equations that can be solved explicitly. The most famous example are certainly the Fibonacci numbers with the equation \u003ci\u003ef\u003c/i\u003e(\u003ci\u003en\u003c/i\u003e) = \u003ci\u003ef\u003c/i\u003e(\u003ci\u003en\u003c/i\u003e-1) + \u003ci\u003ef\u003c/i\u003e(\u003ci\u003en\u003c/i\u003e - 2) and the quite non-obvious closed form (\u003ci\u003e\u0026phi;\u003c/i\u003e\u003csup\u003e\u003ci\u003en\u003c/i\u003e\u003c/sup\u003e - (-\u003ci\u003e\u0026phi;\u003c/i\u003e)\u003csup\u003e-\u003ci\u003en\u003c/i\u003e\u003c/sup\u003e) / \u0026radic;\u003cspan style=\"text-decoration: overline\"\u003e5\u003c/span\u003e where \u0026phi; is the golden ratio. \u003c/p\u003e \u003cp\u003e In this work, I build on existing tools in Isabelle \u0026ndash; such as formal power series and polynomial factorisation algorithms \u0026ndash; to develop a theory of these recurrences and derive a fully executable solver for them that can be exported to programming languages like Haskell. \u003c/p\u003e","date":"October 12","id":181,"permalink":"/entries/linear_recurrences/","shortname":"Linear_Recurrences","title":"Linear Recurrences","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" \u003cp\u003eThis entry builds upon the results about formal and analytic Dirichlet series to define the Hurwitz \u0026zeta; function \u0026zeta;(\u003cem\u003ea\u003c/em\u003e,\u003cem\u003es\u003c/em\u003e) and, based on that, the Riemann \u0026zeta; function \u0026zeta;(\u003cem\u003es\u003c/em\u003e). This is done by first defining them for \u0026real;(\u003cem\u003ez\u003c/em\u003e) \u003e 1 and then successively extending the domain to the left using the Euler\u0026ndash;MacLaurin formula.\u003c/p\u003e \u003cp\u003eApart from the most basic facts such as analyticity, the following results are provided:\u003c/p\u003e \u003cul\u003e \u003cli\u003ethe Stieltjes constants and the Laurent expansion of \u0026zeta;(\u003cem\u003es\u003c/em\u003e) at \u003cem\u003es\u003c/em\u003e = 1\u003c/li\u003e \u003cli\u003ethe non-vanishing of \u0026zeta;(\u003cem\u003es\u003c/em\u003e) for \u0026real;(\u003cem\u003ez\u003c/em\u003e) \u0026ge; 1\u003c/li\u003e \u003cli\u003ethe relationship between \u0026zeta;(\u003cem\u003ea\u003c/em\u003e,\u003cem\u003es\u003c/em\u003e) and \u0026Gamma;\u003c/li\u003e \u003cli\u003ethe special values at negative integers and positive even integers\u003c/li\u003e \u003cli\u003eHurwitz's formula and the reflection formula for \u0026zeta;(\u003cem\u003es\u003c/em\u003e)\u003c/li\u003e \u003cli\u003ethe \u003ca href=\"https://arxiv.org/abs/math/0405478\"\u003e Hadjicostas\u0026ndash;Chapman formula\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003cp\u003eThe entry also contains Euler's analytic proof of the infinitude of primes, based on the fact that \u0026zeta;(\u003ci\u003es\u003c/i\u003e) has a pole at \u003ci\u003es\u003c/i\u003e = 1.\u003c/p\u003e","date":"October 12","id":182,"permalink":"/entries/zeta_function/","shortname":"Zeta_Function","title":"The Hurwitz and Riemann ζ Functions","topicLinks":["mathematics/number-theory","mathematics/analysis"],"topics":["Mathematics/Number theory","Mathematics/Analysis"]},{"abstract":" Computers may help us to understand --not just verify-- philosophical arguments. By utilizing modern proof assistants in an iterative interpretive process, we can reconstruct and assess an argument by fully formal means. Through the mechanization of a variant of St. Anselm's ontological argument by E. J. Lowe, which is a paradigmatic example of a natural-language argument with strong ties to metaphysics and religion, we offer an ideal showcase for our computer-assisted interpretive method.","date":"September 21","id":183,"permalink":"/entries/lowe_ontological_argument/","shortname":"Lowe_Ontological_Argument","title":"Computer-assisted Reconstruction and Assessment of E. J. Lowe's Modal Ontological Argument","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":" \u003cp\u003e We present an embedding of the second-order fragment of the Theory of Abstract Objects as described in Edward Zalta's upcoming work \u003ca href=\"https://mally.stanford.edu/principia.pdf\"\u003ePrincipia Logico-Metaphysica (PLM)\u003c/a\u003e in the automated reasoning framework Isabelle/HOL. The Theory of Abstract Objects is a metaphysical theory that reifies property patterns, as they for example occur in the abstract reasoning of mathematics, as \u003cb\u003eabstract objects\u003c/b\u003e and provides an axiomatic framework that allows to reason about these objects. It thereby serves as a fundamental metaphysical theory that can be used to axiomatize and describe a wide range of philosophical objects, such as Platonic forms or Leibniz' concepts, and has the ambition to function as a foundational theory of mathematics. The target theory of our embedding as described in chapters 7-9 of PLM employs a modal relational type theory as logical foundation for which a representation in functional type theory is \u003ca href=\"https://mally.stanford.edu/Papers/rtt.pdf\"\u003eknown to be challenging\u003c/a\u003e. \u003c/p\u003e \u003cp\u003e Nevertheless we arrive at a functioning representation of the theory in the functional logic of Isabelle/HOL based on a semantical representation of an Aczel-model of the theory. Based on this representation we construct an implementation of the deductive system of PLM which allows to automatically and interactively find and verify theorems of PLM. \u003c/p\u003e \u003cp\u003e Our work thereby supports the concept of shallow semantical embeddings of logical systems in HOL as a universal tool for logical reasoning \u003ca href=\"http://www.mi.fu-berlin.de/inf/groups/ag-ki/publications/Universal-Reasoning/1703_09620_pd.pdf\"\u003eas promoted by Christoph Benzm\u0026uuml;ller\u003c/a\u003e. \u003c/p\u003e \u003cp\u003e The most notable result of the presented work is the discovery of a previously unknown paradox in the formulation of the Theory of Abstract Objects. The embedding of the theory in Isabelle/HOL played a vital part in this discovery. Furthermore it was possible to immediately offer several options to modify the theory to guarantee its consistency. Thereby our work could provide a significant contribution to the development of a proper grounding for object theory. \u003c/p\u003e","date":"September 17","id":184,"permalink":"/entries/plm/","shortname":"PLM","title":"Representation and Partial Automation of the Principia Logico-Metaphysica in Isabelle/HOL","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":" Paul Oppenheimer and Edward Zalta's formalisation of Anselm's ontological argument for the existence of God is automated by embedding a free logic for definite descriptions within Isabelle/HOL.","date":"September 6","id":185,"permalink":"/entries/anselmgod/","shortname":"AnselmGod","title":"Anselm's God in Isabelle/HOL","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":" Economic activity has always been a fundamental part of society. Due to modern day politics, economic theory has gained even more influence on our lives. Thus we want models and theories to be as precise as possible. This can be achieved using certification with the help of formal proof technology. Hence we will use Isabelle/HOL to construct two economic models, that of the the pure exchange economy and a version of the Arrow-Debreu Model. We will prove that the \u003ci\u003eFirst Theorem of Welfare Economics\u003c/i\u003e holds within both. The theorem is the mathematical formulation of Adam Smith's famous \u003ci\u003einvisible hand\u003c/i\u003e and states that a group of self-interested and rational actors will eventually achieve an efficient allocation of goods and services.","date":"September 1","id":186,"permalink":"/entries/first_welfare_theorem/","shortname":"First_Welfare_Theorem","title":"Microeconomics and the First Welfare Theorem","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" The Orbit-Stabiliser theorem is a basic result in the algebra of groups that factors the order of a group into the sizes of its orbits and stabilisers.  We formalize the notion of a group action and the related concepts of orbits and stabilisers. This allows us to prove the orbit-stabiliser theorem.  In the second part of this work, we formalize the tetrahedral group and use the orbit-stabiliser theorem to prove that there are twelve (orientation-preserving) rotations of the tetrahedron.","date":"August 20","id":187,"permalink":"/entries/orbit_stabiliser/","shortname":"Orbit_Stabiliser","title":"Orbit-Stabiliser Theorem with Application to Rotational Symmetries","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003e Andersson introduced \u003cem\u003egeneral balanced trees\u003c/em\u003e, search trees based on the design principle of partial rebuilding: perform update operations naively until the tree becomes too unbalanced, at which point a whole subtree is rebalanced.  This article defines and analyzes a functional version of general balanced trees, which we call \u003cem\u003eroot-balanced trees\u003c/em\u003e. Using a lightweight model of execution time, amortized logarithmic complexity is verified in the theorem prover Isabelle. \u003c/p\u003e \u003cp\u003e This is the Isabelle formalization of the material decribed in the APLAS 2017 article \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/aplas17.html\"\u003eVerified Root-Balanced Trees\u003c/a\u003e by the same author, which also presents experimental results that show competitiveness of root-balanced with AVL and red-black trees. \u003c/p\u003e","date":"August 20","id":188,"permalink":"/entries/root_balanced_tree/","shortname":"Root_Balanced_Tree","title":"Root-Balanced Tree","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" The propositions-as-types correspondence is ordinarily presented as linking the metatheory of typed λ-calculi and the proof theory of intuitionistic logic. Griffin observed that this correspondence could be extended to classical logic through the use of control operators. This observation set off a flurry of further research, leading to the development of Parigots λμ-calculus. In this work, we formalise λμ- calculus in Isabelle/HOL and prove several metatheoretical properties such as type preservation and progress.","date":"August 16","id":189,"permalink":"/entries/lambdamu/","shortname":"LambdaMu","title":"The LambdaMu-calculus","topicLinks":["computer-science/programming-languages/lambda-calculi","logic/general-logic/lambda-calculus"],"topics":["Computer science/Programming languages/Lambda calculi","Logic/General logic/Lambda calculus"]},{"abstract":" This entry formalizes the two geometric theorems, Stewart's and Apollonius' theorem. Stewart's Theorem relates the length of a triangle's cevian to the lengths of the triangle's two sides. Apollonius' Theorem is a specialisation of Stewart's theorem, restricting the cevian to be the median. The proof applies the law of cosines, some basic geometric facts about triangles and then simply transforms the terms algebraically to yield the conjectured relation. The formalization in Isabelle can closely follow the informal proofs described in the Wikipedia articles of those two theorems.","date":"July 31","id":190,"permalink":"/entries/stewart_apollonius/","shortname":"Stewart_Apollonius","title":"Stewart's Theorem and Apollonius' Theorem","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" The architecture of a system describes the system's overall organization into components and connections between those components. With the emergence of mobile computing, dynamic architectures have become increasingly important. In such architectures, components may appear or disappear, and connections may change over time. In the following we mechanize a theory of dynamic architectures and verify the soundness of a corresponding calculus. Therefore, we first formalize the notion of configuration traces as a model for dynamic architectures. Then, the behavior of single components is formalized in terms of behavior traces and an operator is introduced and studied to extract the behavior of a single component out of a given configuration trace. Then, behavior trace assertions are introduced as a temporal specification technique to specify behavior of components. Reasoning about component behavior in a dynamic context is formalized in terms of a calculus for dynamic architectures. Finally, the soundness of the calculus is verified by introducing an alternative interpretation for behavior trace assertions over configuration traces and proving the rules of the calculus. Since projection may lead to finite as well as infinite behavior traces, they are formalized in terms of coinductive lists. Thus, our theory is based on Lochbihler's formalization of coinductive lists. The theory may be applied to verify properties for dynamic architectures.","date":"July 28","id":191,"permalink":"/entries/dynamicarchitectures/","shortname":"DynamicArchitectures","title":"Dynamic Architectures","topicLinks":["computer-science/system-description-languages"],"topics":["Computer science/System description languages"]},{"abstract":" We present a semantics for an applied call-by-value lambda-calculus that is compositional, extensional, and elementary. We present four different views of the semantics: 1) as a relational (big-step) semantics that is not operational but instead declarative, 2) as a denotational semantics that does not use domain theory, 3) as a non-deterministic interpreter, and 4) as a variant of the intersection type systems of the Torino group.  We prove that the semantics is correct by showing that it is sound and complete with respect to operational semantics on programs and that is sound with respect to contextual equivalence. We have not yet investigated whether it is fully abstract. We demonstrate that this approach to semantics is useful with three case studies. First, we use the semantics to prove correctness of a compiler optimization that inlines function application. Second, we adapt the semantics to the polymorphic lambda-calculus extended with general recursion and prove semantic type soundness.  Third, we adapt the semantics to the call-by-value lambda-calculus with mutable references. \u003cbr\u003e The paper that accompanies these Isabelle theories is \u003ca href=\"https://arxiv.org/abs/1707.03762\"\u003eavailable on arXiv\u003c/a\u003e.","date":"July 21","id":192,"permalink":"/entries/decl_sem_fun_pl/","shortname":"Decl_Sem_Fun_PL","title":"Declarative Semantics for Functional Languages","topicLinks":["computer-science/programming-languages"],"topics":["Computer science/Programming languages"]},{"abstract":" The Isabelle/HOLCF-Prelude is a formalization of a large part of Haskell's standard prelude in Isabelle/HOLCF. We use it to prove the correctness of the Eratosthenes' Sieve, in its self-referential implementation commonly used to showcase Haskell's laziness; prove correctness of GHC's \"fold/build\" rule and related rewrite rules; and certify a number of hints suggested by HLint.","date":"July 15","id":193,"permalink":"/entries/holcf-prelude/","shortname":"HOLCF-Prelude","title":"HOLCF-Prelude","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" \u003cp\u003eMinkowski's theorem relates a subset of \u0026#8477;\u003csup\u003en\u003c/sup\u003e, the Lebesgue measure, and the integer lattice \u0026#8484;\u003csup\u003en\u003c/sup\u003e: It states that any convex subset of \u0026#8477;\u003csup\u003en\u003c/sup\u003e with volume greater than 2\u003csup\u003en\u003c/sup\u003e contains at least one lattice point from \u0026#8484;\u003csup\u003en\u003c/sup\u003e\\{0}, i.\u0026thinsp;e. a non-zero point with integer coefficients.\u003c/p\u003e  \u003cp\u003eA related theorem which directly implies this is Blichfeldt's theorem, which states that any subset of \u0026#8477;\u003csup\u003en\u003c/sup\u003e with a volume greater than 1 contains two different points whose difference vector has integer components.\u003c/p\u003e  \u003cp\u003eThe entry contains a proof of both theorems.\u003c/p\u003e","date":"July 13","id":194,"permalink":"/entries/minkowskis_theorem/","shortname":"Minkowskis_Theorem","title":"Minkowski's Theorem","topicLinks":["mathematics/geometry","mathematics/number-theory"],"topics":["Mathematics/Geometry","Mathematics/Number theory"]},{"abstract":" I formalise a Church-style simply-typed \\(\\lambda\\)-calculus, extended with pairs, a unit value, and projection functions, and show some metatheory of the calculus, such as the subject reduction property. Particular attention is paid to the treatment of names in the calculus. A nominal style of binding is used, but I use a manual approach over Nominal Isabelle in order to extract an executable type inference algorithm. More information can be found in my \u003ca href=\"http://www.openthesis.org/documents/Verified-Metatheory-Type-Inference-Simply-603182.html\"\u003eundergraduate dissertation\u003c/a\u003e.","date":"July 9","id":195,"permalink":"/entries/name_carrying_type_inference/","shortname":"Name_Carrying_Type_Inference","title":"Verified Metatheory and Type Inference for a Name-Carrying Simply-Typed Lambda Calculus","topicLinks":["computer-science/programming-languages/type-systems"],"topics":["Computer science/Programming languages/Type systems"]},{"abstract":" In this work, we focus on the correctness of Conflict-free Replicated Data Types (CRDTs), a class of algorithm that provides strong eventual consistency guarantees for replicated data. We develop a modular and reusable framework for verifying the correctness of CRDT algorithms. We avoid correctness issues that have dogged previous mechanised proofs in this area by including a network model in our formalisation, and proving that our theorems hold in all possible network behaviours. Our axiomatic network model is a standard abstraction that accurately reflects the behaviour of real-world computer networks. Moreover, we identify an abstract convergence theorem, a property of order relations, which provides a formal definition of strong eventual consistency. We then obtain the first machine-checked correctness theorems for three concrete CRDTs: the Replicated Growable Array, the Observed-Remove Set, and an Increment-Decrement Counter.","date":"July 7","id":196,"permalink":"/entries/crdt/","shortname":"CRDT","title":"A framework for establishing Strong Eventual Consistency for Conflict-free Replicated Datatypes","topicLinks":["computer-science/algorithms/distributed","computer-science/data-structures"],"topics":["Computer science/Algorithms/Distributed","Computer science/Data structures"]},{"abstract":" We develop Stone-Kleene relation algebras, which expand Stone relation algebras with a Kleene star operation to describe reachability in weighted graphs. Many properties of the Kleene star arise as a special case of a more general theory of iteration based on Conway semirings extended by simulation axioms. This includes several theorems representing complex program transformations. We formally prove the correctness of Conway's automata-based construction of the Kleene star of a matrix. We prove numerous results useful for reasoning about weighted graphs.","date":"July 6","id":197,"permalink":"/entries/stone_kleene_relation_algebras/","shortname":"Stone_Kleene_Relation_Algebras","title":"Stone-Kleene Relation Algebras","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" We formalize a range of proof systems for classical propositional logic (sequent calculus, natural deduction, Hilbert systems, resolution) and prove the most important meta-theoretic results about semantics and proofs: compactness, soundness, completeness, translations between proof systems, cut-elimination, interpolation and model existence.","date":"June 21","id":198,"permalink":"/entries/propositional_proof_systems/","shortname":"Propositional_Proof_Systems","title":"Propositional Proof Systems","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" Partial Semigroups are relevant to the foundations of quantum mechanics and combinatorics as well as to interval and separation logics. Convolution algebras can be understood either as algebras of generalised binary modalities over ternary Kripke frames, in particular over partial semigroups, or as algebras of quantale-valued functions which are equipped with a convolution-style operation of multiplication that is parametrised by a ternary relation. Convolution algebras provide algebraic semantics for various substructural logics, including categorial, relevance and linear logics, for separation logic and for interval logics; they cover quantitative and qualitative applications. These mathematical components for partial semigroups and convolution algebras provide uniform foundations from which models of computation based on relations, program traces or pomsets, and verification components for separation or interval temporal logics can be built with little effort.","date":"June 13","id":199,"permalink":"/entries/psemigroupsconvolution/","shortname":"PSemigroupsConvolution","title":"Partial Semigroups and Convolution Algebras","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" In the 18th century, Georges-Louis Leclerc, Comte de Buffon posed and later solved the following problem, which is often called the first problem ever solved in geometric probability: Given a floor divided into vertical strips of the same width, what is the probability that a needle thrown onto the floor randomly will cross two strips?  This entry formally defines the problem in the case where the needle's position is chosen uniformly at random in a single strip around the origin (which is equivalent to larger arrangements due to symmetry). It then provides proofs of the simple solution in the case where the needle's length is no greater than the width of the strips and the more complicated solution in the opposite case.","date":"June 6","id":200,"permalink":"/entries/buffons_needle/","shortname":"Buffons_Needle","title":"Buffon's Needle Problem","topicLinks":["mathematics/probability-theory","mathematics/geometry"],"topics":["Mathematics/Probability theory","Mathematics/Geometry"]},{"abstract":" We present a formalization of flow networks and the Min-Cut-Max-Flow theorem. Our formal proof closely follows a standard textbook proof, and is accessible even without being an expert in Isabelle/HOL, the interactive theorem prover used for the formalization.","date":"June 1","id":201,"permalink":"/entries/flow_networks/","shortname":"Flow_Networks","title":"Flow Networks and the Min-Cut-Max-Flow Theorem","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" We present a formalization of push-relabel algorithms for computing the maximum flow in a network. We start with Goldberg's et al.~generic push-relabel algorithm, for which we show correctness and the time complexity bound of O(V^2E). We then derive the relabel-to-front and FIFO implementation. Using stepwise refinement techniques, we derive an efficient verified implementation.  Our formal proof of the abstract algorithms closely follows a standard textbook proof. It is accessible even without being an expert in Isabelle/HOL, the interactive theorem prover used for the formalization.","date":"June 1","id":202,"permalink":"/entries/prpu_maxflow/","shortname":"Prpu_Maxflow","title":"Formalizing Push-Relabel Algorithms","topicLinks":["computer-science/algorithms/graph","mathematics/graph-theory"],"topics":["Computer science/Algorithms/Graph","Mathematics/Graph theory"]},{"abstract":" Lenses provide an abstract interface for manipulating data types through spatially-separated views. They are defined abstractly in terms of two functions, \u003cem\u003eget\u003c/em\u003e, the return a value from the source type, and \u003cem\u003eput\u003c/em\u003e that updates the value. We mechanise the underlying theory of lenses, in terms of an algebraic hierarchy of lenses, including well-behaved and very well-behaved lenses, each lens class being characterised by a set of lens laws. We also mechanise a lens algebra in Isabelle that enables their composition and comparison, so as to allow construction of complex lenses. This is accompanied by a large library of algebraic laws. Moreover we also show how the lens classes can be applied by instantiating them with a number of Isabelle data types.","date":"May 25","id":203,"permalink":"/entries/optics/","shortname":"Optics","title":"Optics","topicLinks":["computer-science/functional-programming","mathematics/algebra"],"topics":["Computer science/Functional programming","Mathematics/Algebra"]},{"abstract":" We propose a development method for security protocols based on stepwise refinement. Our refinement strategy transforms abstract security goals into protocols that are secure when operating over an insecure channel controlled by a Dolev-Yao-style intruder. As intermediate levels of abstraction, we employ messageless guard protocols and channel protocols communicating over channels with security properties. These abstractions provide insights on why protocols are secure and foster the development of families of protocols sharing common structure and properties. We have implemented our method in Isabelle/HOL and used it to develop different entity authentication and key establishment protocols, including realistic features such as key confirmation, replay caches, and encrypted tickets. Our development highlights that guard protocols and channel protocols provide fundamental abstractions for bridging the gap between security properties and standard protocol descriptions based on cryptographic messages. It also shows that our refinement approach scales to protocols of nontrivial size and complexity.","date":"May 24","id":204,"permalink":"/entries/security_protocol_refinement/","shortname":"Security_Protocol_Refinement","title":"Developing Security Protocols by Refinement","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" Isabelle's code generator natively supports type classes. For targets that do not have language support for classes and instances, it performs the well-known dictionary translation, as described by Haftmann and Nipkow. This translation happens outside the logic, i.e., there is no guarantee that it is correct, besides the pen-and-paper proof. This work implements a certified dictionary translation that produces new class-free constants and derives equality theorems.","date":"May 24","id":205,"permalink":"/entries/dict_construction/","shortname":"Dict_Construction","title":"Dictionary Construction","topicLinks":["tools"],"topics":["Tools"]},{"abstract":" The Floyd-Warshall algorithm [Flo62, Roy59, War62] is a classic dynamic programming algorithm to compute the length of all shortest paths between any two vertices in a graph (i.e. to solve the all-pairs shortest path problem, or APSP for short). Given a representation of the graph as a matrix of weights M, it computes another matrix M' which represents a graph with the same path lengths and contains the length of the shortest path between any two vertices i and j. This is only possible if the graph does not contain any negative cycles. However, in this case the Floyd-Warshall algorithm will detect the situation by calculating a negative diagonal entry. This entry includes a formalization of the algorithm and of these key properties. The algorithm is refined to an efficient imperative version using the Imperative Refinement Framework.","date":"May 8","id":206,"permalink":"/entries/floyd_warshall/","shortname":"Floyd_Warshall","title":"The Floyd-Warshall Algorithm for Shortest Paths","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":" \u003cp\u003eCryptHOL provides a framework for formalising cryptographic arguments in Isabelle/HOL. It shallowly embeds a probabilistic functional programming language in higher order logic. The language features monadic sequencing, recursion, random sampling, failures and failure handling, and black-box access to oracles. Oracles are probabilistic functions which maintain hidden state between different invocations. All operators are defined in the new semantic domain of generative probabilistic values, a codatatype. We derive proof rules for the operators and establish a connection with the theory of relational parametricity. Thus, the resuting proofs are trustworthy and comprehensible, and the framework is extensible and widely applicable. \u003c/p\u003e\u003cp\u003e The framework is used in the accompanying AFP entry \"Game-based Cryptography in HOL\". There, we show-case our framework by formalizing different game-based proofs from the literature. This formalisation continues the work described in the author's ESOP 2016 paper.\u003c/p\u003e","date":"May 5","id":207,"permalink":"/entries/crypthol/","shortname":"CryptHOL","title":"CryptHOL","topicLinks":["computer-science/security/cryptography","computer-science/functional-programming","mathematics/probability-theory"],"topics":["Computer science/Security/Cryptography","Computer science/Functional programming","Mathematics/Probability theory"]},{"abstract":" The notion of a monad cannot be expressed within higher-order logic (HOL) due to type system restrictions. We show that if a monad is used with values of only one type, this notion can be formalised in HOL. Based on this idea, we develop a library of effect specifications and implementations of monads and monad transformers. Hence, we can abstract over the concrete monad in HOL definitions and thus use the same definition for different (combinations of) effects. We illustrate the usefulness of effect polymorphism with a monadic interpreter for a simple language.","date":"May 5","id":208,"permalink":"/entries/monomorphic_monad/","shortname":"Monomorphic_Monad","title":"Effect polymorphism in higher-order logic","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" \u003cp\u003eIn this AFP entry, we show how to specify game-based cryptographic security notions and formally prove secure several cryptographic constructions from the literature using the CryptHOL framework. Among others, we formalise the notions of a random oracle, a pseudo-random function, an unpredictable function, and of encryption schemes that are indistinguishable under chosen plaintext and/or ciphertext attacks. We prove the random-permutation/random-function switching lemma, security of the Elgamal and hashed Elgamal public-key encryption scheme and correctness and security of several constructions with pseudo-random functions. \u003c/p\u003e\u003cp\u003eOur proofs follow the game-hopping style advocated by Shoup and Bellare and Rogaway, from which most of the examples have been taken. We generalise some of their results such that they can be reused in other proofs. Thanks to CryptHOL's integration with Isabelle's parametricity infrastructure, many simple hops are easily justified using the theory of representation independence.\u003c/p\u003e","date":"May 5","id":209,"permalink":"/entries/game_based_crypto/","shortname":"Game_Based_Crypto","title":"Game-based cryptography in HOL","topicLinks":["computer-science/security/cryptography"],"topics":["Computer science/Security/Cryptography"]},{"abstract":" The usual monad laws can directly be used as rewrite rules for Isabelle’s simplifier to normalise monadic HOL terms and decide equivalences. In a commutative monad, however, the commutativity law is a higher-order permutative rewrite rule that makes the simplifier loop. This AFP entry implements a simproc that normalises monadic expressions in commutative monads using ordered rewriting. The simproc can also permute computations across control operators like if and case.","date":"May 5","id":210,"permalink":"/entries/monad_normalisation/","shortname":"Monad_Normalisation","title":"Monad normalisation","topicLinks":["tools","computer-science/functional-programming","logic/rewriting"],"topics":["Tools","Computer science/Functional programming","Logic/Rewriting"]},{"abstract":" This AFP entry defines a probabilistic while operator based on sub-probability mass functions and formalises zero-one laws and variant rules for probabilistic loop termination. As applications, we implement probabilistic algorithms for the Bernoulli, geometric and arbitrary uniform distributions that only use fair coin flips, and prove them correct and terminating with probability 1.","date":"May 5","id":211,"permalink":"/entries/probabilistic_while/","shortname":"Probabilistic_While","title":"Probabilistic while loop","topicLinks":["computer-science/functional-programming","mathematics/probability-theory","computer-science/algorithms"],"topics":["Computer science/Functional programming","Mathematics/Probability theory","Computer science/Algorithms"]},{"abstract":" Building on the formalization of basic category theory set out in the author's previous AFP article, the present article formalizes some basic aspects of the theory of monoidal categories. Among the notions defined here are monoidal category, monoidal functor, and equivalence of monoidal categories. The main theorems formalized are MacLane's coherence theorem and the constructions of the free monoidal category and free strict monoidal category generated by a given category.  The coherence theorem is proved syntactically, using a structurally recursive approach to reduction of terms that might have some novel aspects. We also give proofs of some results given by Etingof et al, which may prove useful in a formal setting. In particular, we show that the left and right unitors need not be taken as given data in the definition of monoidal category, nor does the definition of monoidal functor need to take as given a specific isomorphism expressing the preservation of the unit object. Our definitions of monoidal category and monoidal functor are stated so as to take advantage of the economy afforded by these facts.","date":"May 4","id":212,"permalink":"/entries/monoidalcategory/","shortname":"MonoidalCategory","title":"Monoidal Categories","topicLinks":["mathematics/category-theory"],"topics":["Mathematics/Category theory"]},{"abstract":" A computer-formalisation of the essential parts of Fitting's textbook \"Types, Tableaus and Gödel's God\" in Isabelle/HOL is presented. In particular, Fitting's (and Anderson's) variant of the ontological argument is verified and confirmed. This variant avoids the modal collapse, which has been criticised as an undesirable side-effect of Kurt Gödel's (and Dana Scott's) versions of the ontological argument. Fitting's work is employing an intensional higher-order modal logic, which we shallowly embed here in classical higher-order logic. We then utilize the embedded logic for the formalisation of Fitting's argument. (See also the earlier AFP entry ``Gödel's God in Isabelle/HOL''.)","date":"May 1","id":213,"permalink":"/entries/types_tableaus_and_goedels_god/","shortname":"Types_Tableaus_and_Goedels_God","title":"Types, Tableaus and Gödel’s God in Isabelle/HOL","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":" This formalisation accompanies the paper \u003ca href=\"https://arxiv.org/abs/1702.03277\"\u003eLocal Lexing\u003c/a\u003e which introduces a novel parsing concept of the same name. The paper also gives a high-level algorithm for local lexing as an extension of Earley's algorithm. This formalisation proves the algorithm to be correct with respect to its local lexing semantics. As a special case, this formalisation thus also contains a proof of the correctness of Earley's algorithm. The paper contains a short outline of how this formalisation is organised.","date":"April 28","id":214,"permalink":"/entries/locallexing/","shortname":"LocalLexing","title":"Local Lexing","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" Isabelle's code generator performs various adaptations for target languages. Among others, constructor applications have to be fully saturated. That means that for constructor calls occuring as arguments to higher-order functions, synthetic lambdas have to be inserted. This entry provides tooling to avoid this construction altogether by introducing constructor functions.","date":"April 19","id":215,"permalink":"/entries/constructor_funs/","shortname":"Constructor_Funs","title":"Constructor Functions","topicLinks":["tools"],"topics":["Tools"]},{"abstract":" Isabelle's code generator performs various adaptations for target languages. Among others, case statements are printed as match expressions. Internally, this is a sophisticated procedure, because in HOL, case statements are represented as nested calls to the case combinators as generated by the datatype package. Furthermore, the procedure relies on laziness of match expressions in the target language, i.e., that branches guarded by patterns that fail to match are not evaluated. Similarly, \u003ctt\u003eif-then-else\u003c/tt\u003e is printed to the corresponding construct in the target language. This entry provides tooling to replace these special cases in the code generator by ignoring these target language features, instead printing case expressions and \u003ctt\u003eif-then-else\u003c/tt\u003e as functions.","date":"April 18","id":216,"permalink":"/entries/lazy_case/","shortname":"Lazy_Case","title":"Lazifying case constants","topicLinks":["tools"],"topics":["Tools"]},{"abstract":" We formalize the theory of subresultants and the subresultant polynomial remainder sequence as described by Brown and Traub. As a result, we obtain efficient certified algorithms for computing the resultant and the greatest common divisor of polynomials.","date":"April 6","id":217,"permalink":"/entries/subresultants/","shortname":"Subresultants","title":"Subresultants","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eThis entry contains proofs for the textbook results about the distributions of the height and internal path length of random binary search trees (BSTs), i.\u0026thinsp;e. BSTs that are formed by taking an empty BST and inserting elements from a fixed set in random order.\u003c/p\u003e  \u003cp\u003eIn particular, we prove a logarithmic upper bound on the expected height and the \u003cem\u003eΘ(n log n)\u003c/em\u003e closed-form solution for the expected internal path length in terms of the harmonic numbers. We also show how the internal path length relates to the average-case cost of a lookup in a BST.\u003c/p\u003e","date":"April 4","id":218,"permalink":"/entries/random_bsts/","shortname":"Random_BSTs","title":"Expected Shape of Random Binary Search Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" \u003cp\u003eThis article contains a formal proof of the well-known fact that number of comparisons that a comparison-based sorting algorithm needs to perform to sort a list of length \u003cem\u003en\u003c/em\u003e is at least \u003cem\u003elog\u003csub\u003e2\u003c/sub\u003e\u0026nbsp;(n!)\u003c/em\u003e in the worst case, i.\u0026thinsp;e.\u0026nbsp;\u003cem\u003eΩ(n log n)\u003c/em\u003e.\u003c/p\u003e  \u003cp\u003eFor this purpose, a shallow embedding for comparison-based sorting algorithms is defined: a sorting algorithm is a recursive datatype containing either a HOL function or a query of a comparison oracle with a continuation containing the remaining computation. This makes it possible to force the algorithm to use only comparisons and to track the number of comparisons made.\u003c/p\u003e","date":"March 15","id":219,"permalink":"/entries/comparison_sort_lower_bound/","shortname":"Comparison_Sort_Lower_Bound","title":"Lower bound on comparison-based sorting algorithms","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" \u003cp\u003eWe give a formal proof of the well-known results about the number of comparisons performed by two variants of QuickSort: first, the expected number of comparisons of randomised QuickSort (i.\u0026thinsp;e.\u0026nbsp;QuickSort with random pivot choice) is \u003cem\u003e2\u0026thinsp;(n+1)\u0026thinsp;H\u003csub\u003en\u003c/sub\u003e - 4\u0026thinsp;n\u003c/em\u003e, which is asymptotically equivalent to \u003cem\u003e2\u0026thinsp;n ln n\u003c/em\u003e; second, the number of comparisons performed by the classic non-randomised QuickSort has the same distribution in the average case as the randomised one.\u003c/p\u003e","date":"March 15","id":220,"permalink":"/entries/quick_sort_cost/","shortname":"Quick_Sort_Cost","title":"The number of comparisons in QuickSort","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" \u003cp\u003eThe Euler-MacLaurin formula relates the value of a discrete sum to that of the corresponding integral in terms of the derivatives at the borders of the summation and a remainder term. Since the remainder term is often very small as the summation bounds grow, this can be used to compute asymptotic expansions for sums.\u003c/p\u003e  \u003cp\u003eThis entry contains a proof of this formula for functions from the reals to an arbitrary Banach space. Two variants of the formula are given: the standard textbook version and a variant outlined in \u003cem\u003eConcrete Mathematics\u003c/em\u003e that is more useful for deriving asymptotic estimates.\u003c/p\u003e  \u003cp\u003eAs example applications, we use that formula to derive the full asymptotic expansion of the harmonic numbers and the sum of inverse squares.\u003c/p\u003e","date":"March 10","id":221,"permalink":"/entries/euler_maclaurin/","shortname":"Euler_MacLaurin","title":"The Euler–MacLaurin Formula","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We prove the group law for elliptic curves in Weierstrass form over fields of characteristic greater than 2. In addition to affine coordinates, we also formalize projective coordinates, which allow for more efficient computations. By specializing the abstract formalization to prime fields, we can apply the curve operations to parameters used in standard security protocols.","date":"February 28","id":222,"permalink":"/entries/elliptic_curves_group_law/","shortname":"Elliptic_Curves_Group_Law","title":"The Group Law for Elliptic Curves","topicLinks":["computer-science/security/cryptography"],"topics":["Computer science/Security/Cryptography"]},{"abstract":" We present a formalization of Menger's Theorem for directed and undirected graphs in Isabelle/HOL.  This well-known result shows that if two non-adjacent distinct vertices u, v in a directed graph have no separator smaller than n, then there exist n internally vertex-disjoint paths from u to v.  The version for undirected graphs follows immediately because undirected graphs are a special case of directed graphs.","date":"February 26","id":223,"permalink":"/entries/menger/","shortname":"Menger","title":"Menger's Theorem","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" We formalize differential dynamic logic, a logic for proving properties of hybrid systems. The proof calculus in this formalization is based on the uniform substitution principle. We show it is sound with respect to our denotational semantics, which provides increased confidence in the correctness of the KeYmaera X theorem prover based on this calculus. As an application, we include a proof term checker embedded in Isabelle/HOL with several example proofs.  Published in: Brandon Bohrer, Vincent Rahli, Ivana Vukotic, Marcus Völp, André Platzer: Formally verified differential dynamic logic. CPP 2017.","date":"February 13","id":224,"permalink":"/entries/differential_dynamic_logic/","shortname":"Differential_Dynamic_Logic","title":"Differential Dynamic Logic","topicLinks":["logic/general-logic/modal-logic","computer-science/programming-languages/logics"],"topics":["Logic/General logic/Modal logic","Computer science/Programming languages/Logics"]},{"abstract":" A formalized coinductive account of the abstract development of Brotherston, Gorogiannis, and Petersen [APLAS 2012], in a slightly more general form since we work with arbitrary infinite proofs, which may be acyclic. This work is described in detail in an article by the authors, published in 2017 in the \u003cem\u003eJournal of Automated Reasoning\u003c/em\u003e. The abstract proof can be instantiated for various formalisms, including first-order logic with inductive predicates.","date":"February 10","id":225,"permalink":"/entries/abstract_soundness/","shortname":"Abstract_Soundness","title":"Abstract Soundness","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" We develop Stone relation algebras, which generalise relation algebras by replacing the underlying Boolean algebra structure with a Stone algebra. We show that finite matrices over extended real numbers form an instance. As a consequence, relation-algebraic concepts and methods can be used for reasoning about weighted graphs. We also develop a fixpoint calculus and apply it to compare different definitions of reflexive-transitive closures in semirings.","date":"February 7","id":226,"permalink":"/entries/stone_relation_algebras/","shortname":"Stone_Relation_Algebras","title":"Stone Relation Algebras","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" We develop a family of key agreement protocols that are correct by construction. Our work substantially extends prior work on developing security protocols by refinement. First, we strengthen the adversary by allowing him to compromise different resources of protocol participants, such as their long-term keys or their session keys. This enables the systematic development of protocols that ensure strong properties such as perfect forward secrecy. Second, we broaden the class of protocols supported to include those with non-atomic keys and equationally defined cryptographic operators. We use these extensions to develop key agreement protocols including signed Diffie-Hellman and the core of IKEv1 and SKEME.","date":"January 31","id":227,"permalink":"/entries/key_agreement_strong_adversaries/","shortname":"Key_Agreement_Strong_Adversaries","title":"Refining Authenticated Key Agreement with Strong Adversaries","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003eBernoulli numbers were first discovered in the closed-form expansion of the sum 1\u003csup\u003em\u003c/sup\u003e + 2\u003csup\u003em\u003c/sup\u003e + \u0026hellip; + n\u003csup\u003em\u003c/sup\u003e for a fixed m and appear in many other places. This entry provides three different definitions for them: a recursive one, an explicit one, and one through their exponential generating function.\u003c/p\u003e \u003cp\u003eIn addition, we prove some basic facts, e.g. their relation to sums of powers of integers and that all odd Bernoulli numbers except the first are zero, and some advanced facts like their relationship to the Riemann zeta function on positive even integers.\u003c/p\u003e \u003cp\u003eWe also prove the correctness of the Akiyama\u0026ndash;Tanigawa algorithm for computing Bernoulli numbers with reasonable efficiency, and we define the periodic Bernoulli polynomials (which appear e.g. in the Euler\u0026ndash;MacLaurin summation formula and the expansion of the log-Gamma function) and prove their basic properties.\u003c/p\u003e","date":"January 24","id":228,"permalink":"/entries/bernoulli/","shortname":"Bernoulli","title":"Bernoulli Numbers","topicLinks":["mathematics/analysis","mathematics/number-theory"],"topics":["Mathematics/Analysis","Mathematics/Number theory"]},{"abstract":" \u003cp\u003eBertrand's postulate is an early result on the distribution of prime numbers: For every positive integer n, there exists a prime number that lies strictly between n and 2n. The proof is ported from John Harrison's formalisation in HOL Light. It proceeds by first showing that the property is true for all n greater than or equal to 600 and then showing that it also holds for all n below 600 by case distinction. \u003c/p\u003e","date":"January 17","id":229,"permalink":"/entries/bertrands_postulate/","shortname":"Bertrands_Postulate","title":"Bertrand's postulate","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" \u003cp\u003eThis formalization is an extension to \u003ca href=\"https://www.isa-afp.org/entries/Formal_SSA.html\"\u003e\"Verified Construction of Static Single Assignment Form\"\u003c/a\u003e. In their work, the authors have shown that \u003ca href=\"https://doi.org/10.1007/978-3-642-37051-9_6\"\u003eBraun et al.'s static single assignment (SSA) construction algorithm\u003c/a\u003e produces minimal SSA form for input programs with a reducible control flow graph (CFG). However Braun et al. also proposed an extension to their algorithm that they claim produces minimal SSA form even for irreducible CFGs.\u003cbr\u003e In this formalization we support that claim by giving a mechanized proof. \u003c/p\u003e \u003cp\u003eAs the extension of Braun et al.'s algorithm aims for removing so-called redundant strongly connected components of phi functions, we show that this suffices to guarantee minimality according to \u003ca href=\"https://doi.org/10.1145/115372.115320\"\u003eCytron et al.\u003c/a\u003e.\u003c/p\u003e","date":"January 17","id":230,"permalink":"/entries/minimal_ssa/","shortname":"Minimal_SSA","title":"Minimal Static Single Assignment Form","topicLinks":["computer-science/programming-languages/transformations"],"topics":["Computer science/Programming languages/Transformations"]},{"abstract":" \u003cp\u003eThis work contains a proof that Euler's number e is transcendental. The proof follows the standard approach of assuming that e is algebraic and then using a specific integer polynomial to derive two inconsistent bounds, leading to a contradiction.\u003c/p\u003e \u003cp\u003eThis kind of approach can be found in many different sources; this formalisation mostly follows a \u003ca  href=\"http://planetmath.org/proofoflindemannweierstrasstheoremandthateandpiaretranscendental\"\u003ePlanetMath article\u003c/a\u003e by Roger Lipsett.\u003c/p\u003e","date":"January 12","id":231,"permalink":"/entries/e_transcendental/","shortname":"E_Transcendental","title":"The Transcendence of e","topicLinks":["mathematics/analysis","mathematics/number-theory"],"topics":["Mathematics/Analysis","Mathematics/Number theory"]},{"abstract":" We present a formal model of network protocols and their application to modeling firewall policies. The formalization is based on the Unified Policy Framework (UPF). The formalization was originally developed with for generating test cases for testing the security configuration actual firewall and router (middle-boxes) using HOL-TestGen. Our work focuses on modeling application level protocols on top of tcp/ip.","date":"January 8","id":232,"permalink":"/entries/upf_firewall/","shortname":"UPF_Firewall","title":"Formal Network Models and Their Application to Firewall Policies","topicLinks":["computer-science/security","computer-science/networks"],"topics":["Computer science/Security","Computer science/Networks"]},{"abstract":" This paper constructs a formal model of a Diffie-Hellman password-based authentication protocol between a user and a smart card, and proves its security. The protocol provides for the dispatch of the user's password to the smart card on a secure messaging channel established by means of Password Authenticated Connection Establishment (PACE), where the mapping method being used is Chip Authentication Mapping. By applying and suitably extending Paulson's Inductive Method, this paper proves that the protocol establishes trustworthy secure messaging channels, preserves the secrecy of users' passwords, and provides an effective mutual authentication service. What is more, these security properties turn out to hold independently of the secrecy of the PACE authentication key.","date":"January 3","id":233,"permalink":"/entries/password_authentication_protocol/","shortname":"Password_Authentication_Protocol","title":"Verification of a Diffie-Hellman Password-based Authentication Protocol by Extending the Inductive Method","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003eWe present a certified declarative first-order prover with equality based on John Harrison's Handbook of Practical Logic and Automated Reasoning, Cambridge University Press, 2009. ML code reflection is used such that the entire prover can be executed within Isabelle as a very simple interactive proof assistant. As examples we consider Pelletier's problems 1-46.\u003c/p\u003e \u003cp\u003eReference: Programming and Verifying a Declarative First-Order Prover in Isabelle/HOL. Alexander Birch Jensen, John Bruntse Larsen, Anders Schlichtkrull \u0026 Jørgen Villadsen. AI Communications 31:281-299 2018. \u003ca href=\"https://content.iospress.com/articles/ai-communications/aic764\"\u003e https://content.iospress.com/articles/ai-communications/aic764\u003c/a\u003e\u003c/p\u003e \u003cp\u003eSee also: Students' Proof Assistant (SPA). \u003ca href=https://github.com/logic-tools/spa\u003e https://github.com/logic-tools/spa\u003c/a\u003e\u003c/p\u003e","date":"January 1","id":234,"permalink":"/entries/fol_harrison/","shortname":"FOL_Harrison","title":"First-Order Logic According to Harrison","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" The concurrent refinement algebra developed here is designed to provide a foundation for rely/guarantee reasoning about concurrent programs. The algebra builds on a complete lattice of commands by providing sequential composition, parallel composition and a novel weak conjunction operator. The weak conjunction operator coincides with the lattice supremum providing its arguments are non-aborting, but aborts if either of its arguments do. Weak conjunction provides an abstract version of a guarantee condition as a guarantee process. We distinguish between models that distribute sequential composition over non-deterministic choice from the left (referred to as being conjunctive in the refinement calculus literature) and those that don't. Least and greatest fixed points of monotone functions are provided to allow recursion and iteration operators to be added to the language. Additional iteration laws are available for conjunctive models. The rely quotient of processes \u003ci\u003ec\u003c/i\u003e and \u003ci\u003ei\u003c/i\u003e is the process that, if executed in parallel with \u003ci\u003ei\u003c/i\u003e implements \u003ci\u003ec\u003c/i\u003e. It represents an abstract version of a rely condition generalised to a process.","date":"December 30","id":235,"permalink":"/entries/concurrent_ref_alg/","shortname":"Concurrent_Ref_Alg","title":"Concurrent Refinement Algebra and Rely Quotients","topicLinks":["computer-science/concurrency"],"topics":["Computer science/Concurrency"]},{"abstract":" This entry provides all cardinality theorems of the Twelvefold Way. The Twelvefold Way systematically classifies twelve related combinatorial problems concerning two finite sets, which include counting permutations, combinations, multisets, set partitions and number partitions. This development builds upon the existing formal developments with cardinality theorems for those structures. It provides twelve bijections from the various structures to different equivalence classes on finite functions, and hence, proves cardinality formulae for these equivalence classes on finite functions.","date":"December 29","id":236,"permalink":"/entries/twelvefold_way/","shortname":"Twelvefold_Way","title":"The Twelvefold Way","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" Isabelle includes various automatic tools for finding proofs under certain conditions. However, for each conjecture, knowing which automation to use, and how to tweak its parameters, is currently labour intensive. We have developed a language, PSL, designed to capture high level proof strategies. PSL offloads the construction of human-readable fast-to-replay proof scripts to automatic search, making use of search-time information about each conjecture. Our preliminary evaluations show that PSL reduces the labour cost of interactive theorem proving. This submission contains the implementation of PSL and an example theory file, Example.thy, showing how to write poof strategies in PSL.","date":"December 20","id":237,"permalink":"/entries/proof_strategy_language/","shortname":"Proof_Strategy_Language","title":"Proof Strategy Language","topicLinks":["tools"],"topics":["Tools"]},{"abstract":" Paraconsistency is about handling inconsistency in a coherent way. In classical and intuitionistic logic everything follows from an inconsistent theory. A paraconsistent logic avoids the explosion. Quite a few applications in computer science and engineering are discussed in the Intelligent Systems Reference Library Volume 110: Towards Paraconsistent Engineering (Springer 2016). We formalize a paraconsistent many-valued logic that we motivated and described in a special issue on logical approaches to paraconsistency (Journal of Applied Non-Classical Logics 2005). We limit ourselves to the propositional fragment of the higher-order logic. The logic is based on so-called key equalities and has a countably infinite number of truth values. We prove theorems in the logic using the definition of validity. We verify truth tables and also counterexamples for non-theorems. We prove meta-theorems about the logic and finally we investigate a case study.","date":"December 7","id":238,"permalink":"/entries/paraconsistency/","shortname":"Paraconsistency","title":"Paraconsistency","topicLinks":["logic/general-logic/paraconsistent-logics"],"topics":["Logic/General logic/Paraconsistent logics"]},{"abstract":" We propose a concurrency reasoning framework for imperative programs, based on the Owicki-Gries (OG) foundational shared-variable concurrency method. Our framework combines the approaches of Hoare-Parallel, a formalisation of OG in Isabelle/HOL for a simple while-language, and Simpl, a generic imperative language embedded in Isabelle/HOL, allowing formal reasoning on C programs. We define the Complx language, extending the syntax and semantics of Simpl with support for parallel composition and synchronisation. We additionally define an OG logic, which we prove sound w.r.t. the  semantics, and a verification condition generator, both supporting involved low-level imperative constructs such as function calls and abrupt termination. We illustrate our framework on an example that features exceptions, guards and function calls.  We aim to then target concurrent operating systems, such as the interruptible eChronos embedded operating system for which we already have a model-level OG proof using Hoare-Parallel.","date":"November 29","id":239,"permalink":"/entries/complx/","shortname":"Complx","title":"COMPLX: A Verification Framework for Concurrent Imperative Programs","topicLinks":["computer-science/programming-languages/logics","computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Logics","Computer science/Programming languages/Language definitions"]},{"abstract":" This is the Isabelle formalization of the material decribed in the eponymous \u003ca href=\"https://doi.org/10.1007/978-3-642-32347-8_9\"\u003eITP 2012 paper\u003c/a\u003e. It develops a generic abstract interpreter for a while-language, including widening and narrowing. The collecting semantics and the abstract interpreter operate on annotated commands: the program is represented as a syntax tree with the semantic information directly embedded, without auxiliary labels. The aim of the formalization is simplicity, not efficiency or precision. This is motivated by the inclusion of the material in a theorem prover based course on semantics. A similar (but more polished) development is covered in the book \u003ca href=\"https://doi.org/10.1007/978-3-319-10542-0\"\u003eConcrete Semantics\u003c/a\u003e.","date":"November 23","id":240,"permalink":"/entries/abs_int_itp2012/","shortname":"Abs_Int_ITP2012","title":"Abstract Interpretation of Annotated Commands","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":" We bring the labelled sequent calculus $LS_{PASL}$ for propositional abstract separation logic to Isabelle. The tactics given here are directly applied on an extension of the Separation Algebra in the AFP. In addition to the cancellative separation algebra, we further consider some useful properties in the heap model of separation logic, such as indivisible unit, disjointness, and cross-split. The tactics are essentially a proof search procedure for the calculus $LS_{PASL}$. We wrap the tactics in an Isabelle method called separata, and give a few examples of separation logic formulae which are provable by separata.","date":"November 16","id":241,"permalink":"/entries/separata/","shortname":"Separata","title":"Separata: Isabelle tactics for Separation Algebra","topicLinks":["computer-science/programming-languages/logics","tools"],"topics":["Computer science/Programming languages/Logics","Tools"]},{"abstract":"This Isabelle/HOL formalization defines Knuth–Bendix orders for higher-order terms without lambda-abstraction and proves many useful properties about them. The main order fully coincides with the standard transfinite KBO with subterm coefficients on first-order terms. It appears promising as the basis of a higher-order superposition calculus.","date":"November 12","id":242,"permalink":"/entries/lambda_free_kbos/","shortname":"Lambda_Free_KBOs","title":"Formalization of Knuth–Bendix Orders for Lambda-Free Higher-Order Terms","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":"This Isabelle/HOL formalization introduces a nested multiset datatype and defines Dershowitz and Manna's nested multiset order. The order is proved well founded and linear. By removing one constructor, we transform the nested multisets into hereditary multisets. These are isomorphic to the syntactic ordinals—the ordinals can be recursively expressed in Cantor normal form. Addition, subtraction, multiplication, and linear orders are provided on this type.","date":"November 12","id":243,"permalink":"/entries/nested_multisets_ordinals/","shortname":"Nested_Multisets_Ordinals","title":"Formalization of Nested Multisets, Hereditary Multisets, and Syntactic Ordinals","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" Deep learning has had a profound impact on computer science in recent years, with applications to search engines, image recognition and language processing, bioinformatics, and more. Recently, Cohen et al. provided theoretical evidence for the superiority of deep learning over shallow learning. This formalization of their work simplifies and generalizes the original proof, while working around the limitations of the Isabelle type system. To support the formalization, I developed reusable libraries of formalized mathematics, including results about the matrix rank, the Lebesgue measure, and multivariate polynomials, as well as a library for tensor analysis.","date":"November 10","id":244,"permalink":"/entries/deep_learning/","shortname":"Deep_Learning","title":"Expressiveness of Deep Learning","topicLinks":["computer-science/machine-learning","mathematics/analysis"],"topics":["Computer science/Machine learning","Mathematics/Analysis"]},{"abstract":" We formalize a uniform semantic substrate for a wide variety of process calculi where states and action labels can be from arbitrary nominal sets. A Hennessy-Milner logic for these systems is defined, and proved adequate for bisimulation equivalence. A main novelty is the construction of an infinitary nominal data type to model formulas with (finitely supported) infinite conjunctions and actions that may contain binding names. The logic is generalized to treat different bisimulation variants such as early, late and open in a systematic way.","date":"October 25","id":245,"permalink":"/entries/modal_logics_for_nts/","shortname":"Modal_Logics_for_NTS","title":"Modal Logics for Nominal Transition Systems","topicLinks":["computer-science/concurrency/process-calculi","logic/general-logic/modal-logic"],"topics":["Computer science/Concurrency/Process calculi","Logic/General logic/Modal logic"]},{"abstract":" We mechanize proofs of several results from the matching with contracts literature, which generalize those of the classical two-sided matching scenarios that go by the name of stable marriage. Our focus is on game theoretic issues. Along the way we develop executable algorithms for computing optimal stable matches.","date":"October 24","id":246,"permalink":"/entries/stable_matching/","shortname":"Stable_Matching","title":"Stable Matching","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" We present LOFT — Linux firewall OpenFlow Translator, a system that transforms the main routing table and FORWARD chain of iptables of a Linux-based firewall into a set of static OpenFlow rules. Our implementation is verified against a model of a simplified Linux-based router and we can directly show how much of the original functionality is preserved.","date":"October 21","id":247,"permalink":"/entries/loft/","shortname":"LOFT","title":"LOFT — Verified Migration of Linux Firewalls to SDN","topicLinks":["computer-science/networks"],"topics":["Computer science/Networks"]},{"abstract":" We formalise the SPARCv8 instruction set architecture (ISA) which is used in processors such as LEON3. Our formalisation can be specialised to any SPARCv8 CPU, here we use LEON3 as a running example. Our model covers the operational semantics for all the instructions in the integer unit of the SPARCv8 architecture and it supports Isabelle code export, which effectively turns the Isabelle model into a SPARCv8 CPU simulator. We prove the language-based non-interference property for the LEON3 processor.  Our model is based on deterministic monad, which is a modified version of the non-deterministic monad from NICTA/l4v.","date":"October 19","id":248,"permalink":"/entries/sparcv8/","shortname":"SPARCv8","title":"A formal model for the SPARCv8 ISA and a proof of non-interference for the LEON3 processor","topicLinks":["computer-science/security","computer-science/hardware"],"topics":["Computer science/Security","Computer science/Hardware"]},{"abstract":" This document contains a proof of the necessary condition on the code rate of a source code, namely that this code rate is bounded by the entropy of the source. This represents one half of Shannon's source coding theorem, which is itself an equivalence.","date":"October 19","id":249,"permalink":"/entries/source_coding_theorem/","shortname":"Source_Coding_Theorem","title":"Source Coding Theorem","topicLinks":["mathematics/probability-theory"],"topics":["Mathematics/Probability theory"]},{"abstract":" \u003cp\u003eWe formalize the Berlekamp-Zassenhaus algorithm for factoring square-free integer polynomials in Isabelle/HOL. We further adapt an existing formalization of Yun’s square-free factorization algorithm to integer polynomials, and thus provide an efficient and certified factorization algorithm for arbitrary univariate polynomials. \u003c/p\u003e \u003cp\u003eThe algorithm first performs a factorization in the prime field GF(p) and then performs computations in the integer ring modulo p^k, where both p and k are determined at runtime. Since a natural modeling of these structures via dependent types is not possible in Isabelle/HOL, we formalize the whole algorithm using Isabelle’s recent addition of local type definitions. \u003c/p\u003e \u003cp\u003eThrough experiments we verify that our algorithm factors polynomials of degree 100 within seconds. \u003c/p\u003e","date":"October 14","id":250,"permalink":"/entries/berlekamp_zassenhaus/","shortname":"Berlekamp_Zassenhaus","title":"The Factorization Algorithm of Berlekamp and Zassenhaus","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" This entry provides a geometric proof of the intersecting chords theorem. The theorem states that when two chords intersect each other inside a circle, the products of their segments are equal.  After a short review of existing proofs in the literature, I decided to use a proof approach that employs reasoning about lengths of line segments, the orthogonality of two lines and the Pythagoras Law. Hence, one can understand the formalized proof easily with the knowledge of a few general geometric facts that are commonly taught in high-school.  This theorem is the 55th theorem of the Top 100 Theorems list.","date":"October 11","id":251,"permalink":"/entries/chord_segments/","shortname":"Chord_Segments","title":"Intersecting Chords Theorem","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" Lp is the space of functions whose p-th power is integrable. It is one of the most fundamental Banach spaces that is used in analysis and probability. We develop a framework for function spaces, and then implement the Lp spaces in this framework using the existing integration theory in Isabelle/HOL. Our development contains most fundamental properties of Lp spaces, notably the Hölder and Minkowski inequalities, completeness of Lp, duality, stability under almost sure convergence, multiplication of functions in Lp and Lq, stability under conditional expectation.","date":"October 5","id":252,"permalink":"/entries/lp/","shortname":"Lp","title":"Lp spaces","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" \u003cp\u003eThis work defines and proves the correctness of the Fisher–Yates algorithm for shuffling – i.e. producing a random permutation – of a list. The algorithm proceeds by traversing the list and in each step swapping the current element with a random element from the remaining list.\u003c/p\u003e","date":"September 30","id":253,"permalink":"/entries/fisher_yates/","shortname":"Fisher_Yates","title":"Fisher–Yates shuffle","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" Allen’s interval calculus is a qualitative temporal representation of time events. Allen introduced 13 binary relations that describe all the possible arrangements between two events, i.e. intervals with non-zero finite length. The compositions are pertinent to reasoning about knowledge of time. In particular, a consistency problem of relation constraints is commonly solved with a guideline from these compositions. We formalize the relations together with an axiomatic system. We proof the validity of the 169 compositions of these relations. We also define nests as the sets of intervals that share a meeting point. We prove that nests give the ordering properties of points without introducing a new datatype for points. [1] J.F. Allen. Maintaining Knowledge about Temporal Intervals. In Commun. ACM, volume 26, pages 832–843, 1983. [2] J. F. Allen and P. J. Hayes. A Common-sense Theory of Time. In Proceedings of the 9th International Joint Conference on Artificial Intelligence (IJCAI’85), pages 528–531, 1985.","date":"September 29","id":254,"permalink":"/entries/allen_calculus/","shortname":"Allen_Calculus","title":"Allen's Interval Calculus","topicLinks":["logic/general-logic/temporal-logic","mathematics/order"],"topics":["Logic/General logic/Temporal logic","Mathematics/Order"]},{"abstract":"This Isabelle/HOL formalization defines recursive path orders (RPOs) for higher-order terms without lambda-abstraction and proves many useful properties about them. The main order fully coincides with the standard RPO on first-order terms also in the presence of currying, distinguishing it from previous work. An optimized variant is formalized as well. It appears promising as the basis of a higher-order superposition calculus.","date":"September 23","id":255,"permalink":"/entries/lambda_free_rpos/","shortname":"Lambda_Free_RPOs","title":"Formalization of Recursive Path Orders for Lambda-Free Higher-Order Terms","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" We present a big step semantics of the filtering behavior of the Linux/netfilter iptables firewall. We provide algorithms to simplify complex iptables rulests to a simple firewall model (c.f. AFP entry \u003ca href=\"https://www.isa-afp.org/entries/Simple_Firewall.html\"\u003eSimple_Firewall\u003c/a\u003e) and to verify spoofing protection of a ruleset. Internally, we embed our semantics into ternary logic, ultimately supporting every iptables match condition by abstracting over unknowns. Using this AFP entry and all entries it depends on, we created an easy-to-use, stand-alone haskell tool called \u003ca href=\"http://iptables.isabelle.systems\"\u003efffuu\u003c/a\u003e. The tool does not require any input \u0026mdash;except for the \u003ctt\u003eiptables-save\u003c/tt\u003e dump of the analyzed firewall\u0026mdash; and presents interesting results about the user's ruleset. Real-Word firewall errors have been uncovered, and the correctness of rulesets has been proved, with the help of our tool.","date":"September 9","id":256,"permalink":"/entries/iptables_semantics/","shortname":"Iptables_Semantics","title":"Iptables Semantics","topicLinks":["computer-science/networks"],"topics":["Computer science/Networks"]},{"abstract":" We provide a formalization of a variant of the superposition calculus, together with formal proofs of soundness and refutational completeness (w.r.t. the usual redundancy criteria based on clause ordering). This version of the calculus uses all the standard restrictions of the superposition rules, together with the following refinement, inspired by the basic superposition calculus: each clause is associated with a set of terms which are assumed to be in normal form -- thus any application of the replacement rule on these terms is blocked. The set is initially empty and terms may be added or removed at each inference step. The set of terms that are assumed to be in normal form includes any term introduced by previous unifiers as well as any term occurring in the parent clauses at a position that is smaller (according to some given ordering on positions) than a previously replaced term. The standard superposition calculus corresponds to the case where the set of irreducible terms is always empty.","date":"September 6","id":257,"permalink":"/entries/supercalc/","shortname":"SuperCalc","title":"A Variant of the Superposition Calculus","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" A range of algebras between lattices and Boolean algebras generalise the notion of a complement. We develop a hierarchy of these pseudo-complemented algebras that includes Stone algebras. Independently of this theory we study filters based on partial orders. Both theories are combined to prove Chen and Grätzer's construction theorem for Stone algebras. The latter involves extensive reasoning about algebraic structures in addition to reasoning in algebraic structures.","date":"September 6","id":258,"permalink":"/entries/stone_algebras/","shortname":"Stone_Algebras","title":"Stone Algebras","topicLinks":["mathematics/order"],"topics":["Mathematics/Order"]},{"abstract":" \u003cp\u003eThis work contains a proof of Stirling's formula both for the factorial $n! \\sim \\sqrt{2\\pi n} (n/e)^n$ on natural numbers and the real Gamma function $\\Gamma(x)\\sim \\sqrt{2\\pi/x} (x/e)^x$. The proof is based on work by \u003ca href=\"http://www.maths.lancs.ac.uk/~jameson/stirlgamma.pdf\"\u003eGraham Jameson\u003c/a\u003e.\u003c/p\u003e \u003cp\u003eThis is then extended to the full asymptotic expansion $$\\log\\Gamma(z) = \\big(z - \\tfrac{1}{2}\\big)\\log z - z + \\tfrac{1}{2}\\log(2\\pi) + \\sum_{k=1}^{n-1} \\frac{B_{k+1}}{k(k+1)} z^{-k}\\\\ {} - \\frac{1}{n} \\int_0^\\infty B_n([t])(t + z)^{-n}\\,\\text{d}t$$ uniformly for all complex $z\\neq 0$ in the cone $\\text{arg}(z)\\leq \\alpha$ for any $\\alpha\\in(0,\\pi)$, with which the above asymptotic relation for \u0026Gamma; is also extended to complex arguments.\u003c/p\u003e","date":"September 1","id":259,"permalink":"/entries/stirling_formula/","shortname":"Stirling_Formula","title":"Stirling's formula","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" This entry contains definitions for routing with routing tables/longest prefix matching.  A routing table entry is modelled as a record of a prefix match, a metric, an output port, and an optional next hop. A routing table is a list of entries, sorted by prefix length and metric. Additionally, a parser and serializer for the output of the ip-route command, a function to create a relation from output port to corresponding destination IP space, and a model of a Linux-style router are included.","date":"August 31","id":260,"permalink":"/entries/routing/","shortname":"Routing","title":"Routing","topicLinks":["computer-science/networks"],"topics":["Computer science/Networks"]},{"abstract":" We present a simple model of a firewall. The firewall can accept or drop a packet and can match on interfaces, IP addresses, protocol, and ports. It was designed to feature nice mathematical properties: The type of match expressions was carefully crafted such that the conjunction of two match expressions is only one match expression. This model is too simplistic to mirror all aspects of the real world. In the upcoming entry \"Iptables Semantics\", we will translate the Linux firewall iptables to this model.  For a fixed service (e.g. ssh, http), we provide an algorithm to compute an overview of the firewall's filtering behavior. The algorithm computes minimal service matrices, i.e. graphs which partition the complete IPv4 and IPv6 address space and visualize the allowed accesses between partitions. For a detailed description, see \u003ca href=\"http://dl.ifip.org/db/conf/networking/networking2016/1570232858.pdf\"\u003eVerified iptables Firewall Analysis\u003c/a\u003e, IFIP Networking 2016.","date":"August 24","id":261,"permalink":"/entries/simple_firewall/","shortname":"Simple_Firewall","title":"Simple Firewall","topicLinks":["computer-science/networks"],"topics":["Computer science/Networks"]},{"abstract":" TRACER is a tool for verifying safety properties of sequential C programs. TRACER attempts at building a finite symbolic execution graph which over-approximates the set of all concrete reachable states and the set of feasible paths.  We present an abstract framework for TRACER and similar CEGAR-like systems. The framework provides 1) a graph- transformation based method for reducing the feasible paths in control-flow graphs, 2) a model for symbolic execution, subsumption, predicate abstraction and invariant generation. In this framework we formally prove two key properties: correct construction of the symbolic states and preservation of feasible paths. The framework focuses on core operations, leaving to concrete prototypes to “fit in” heuristics for combining them.  The accompanying paper (published in ITP 2016) can be found at https://www.lri.fr/∼wolff/papers/conf/2016-itp-InfPathsNSE.pdf.","date":"August 18","id":262,"permalink":"/entries/infpathelimination/","shortname":"InfPathElimination","title":"Infeasible Paths Elimination by Symbolic Execution Techniques: Proof of Correctness and Preservation of Paths","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":" We present a formalization of the Ford-Fulkerson method for computing the maximum flow in a network. Our formal proof closely follows a standard textbook proof, and is accessible even without being an expert in Isabelle/HOL--- the interactive theorem prover used for the formalization. We then use stepwise refinement to obtain the Edmonds-Karp algorithm, and formally prove a bound on its complexity. Further refinement yields a verified implementation, whose execution time compares well to an unverified reference implementation in Java. This entry is based on our ITP-2016 paper with the same title.","date":"August 12","id":263,"permalink":"/entries/edmondskarp_maxflow/","shortname":"EdmondsKarp_Maxflow","title":"Formalizing the Edmonds-Karp Algorithm","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":" We present the Imperative Refinement Framework (IRF), a tool that supports a stepwise refinement based approach to imperative programs. This entry is based on the material we presented in [ITP-2015, CPP-2016].  It uses the Monadic Refinement Framework as a frontend for the specification of the abstract programs, and Imperative/HOL as a backend to generate executable imperative programs.  The IRF comes with tool support to synthesize imperative programs from more abstract, functional ones, using efficient imperative implementations for the abstract data structures.  This entry also includes the Imperative Isabelle Collection Framework (IICF), which provides a library of re-usable imperative collection data structures.  Moreover, this entry contains a quickstart guide and a reference manual, which provide an introduction to using the IRF for Isabelle/HOL experts. It also provids a collection of (partly commented) practical examples, some highlights being Dijkstra's Algorithm, Nested-DFS, and a generic worklist algorithm with subsumption.  Finally, this entry contains benchmark scripts that compare the runtime of some examples against reference implementations of the algorithms in Java and C++. [ITP-2015] Peter Lammich: Refinement to Imperative/HOL. ITP 2015: 253--269  [CPP-2016] Peter Lammich: Refinement based verification of imperative data structures. CPP 2016: 27--36","date":"August 8","id":264,"permalink":"/entries/refine_imperative_hol/","shortname":"Refine_Imperative_HOL","title":"The Imperative Refinement Framework","topicLinks":["computer-science/programming-languages/transformations","computer-science/data-structures"],"topics":["Computer science/Programming languages/Transformations","Computer science/Data structures"]},{"abstract":" This entry provides an analytic proof to Ptolemy's Theorem using polar form transformation and trigonometric identities. In this formalization, we use ideas from John Harrison's HOL Light formalization and the proof sketch on the Wikipedia entry of Ptolemy's Theorem. This theorem is the 95th theorem of the Top 100 Theorems list.","date":"August 7","id":265,"permalink":"/entries/ptolemys_theorem/","shortname":"Ptolemys_Theorem","title":"Ptolemy's Theorem","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" In 1964, Fitch showed that the paradox of the surprise hanging can be resolved by showing that the judge’s verdict is inconsistent. His formalization builds on Gödel’s coding of provability.  In this theory, we reproduce his proof in Isabelle, building on Paulson’s formalisation of Gödel’s incompleteness theorems.","date":"July 17","id":266,"permalink":"/entries/surprise_paradox/","shortname":"Surprise_Paradox","title":"Surprise Paradox","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" This library defines three different versions of pairing heaps: a functional version of the original design based on binary trees [Fredman et al. 1986], the version by Okasaki [1998] and a modified version of the latter that is free of structural invariants. \u003cp\u003e The amortized complexity of pairing heaps is analyzed in the AFP article \u003ca href=\"http://isa-afp.org/entries/Amortized_Complexity.html\"\u003eAmortized Complexity\u003c/a\u003e.","date":"July 14","id":267,"permalink":"/entries/pairing_heap/","shortname":"Pairing_Heap","title":"Pairing Heap","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" \u003cp\u003e This entry presents a framework for the modular verification of DFS-based algorithms, which is described in our [CPP-2015] paper. It provides a generic DFS algorithm framework, that can be parameterized with user-defined actions on certain events (e.g. discovery of new node).  It comes with an extensible library of invariants, which can be used to derive invariants of a specific parameterization.  Using refinement techniques, efficient implementations of the algorithms can easily be derived. Here, the framework comes with templates for a recursive and a tail-recursive implementation, and also with several templates for implementing the data structures required by the DFS algorithm.  Finally, this entry contains a set of re-usable DFS-based algorithms, which illustrate the application of the framework. \u003c/p\u003e\u003cp\u003e [CPP-2015] Peter Lammich, René Neumann: A Framework for Verifying Depth-First Search Algorithms. CPP 2015: 137-146\u003c/p\u003e","date":"July 5","id":268,"permalink":"/entries/dfs_framework/","shortname":"DFS_Framework","title":"A Framework for Verifying Depth-First Search Algorithms","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":" We provide a basic formal framework for the theory of chamber complexes and Coxeter systems, and for buildings as thick chamber complexes endowed with a system of apartments. Along the way, we develop some of the general theory of abstract simplicial complexes and of groups (relying on the \u003ci\u003egroup_add\u003c/i\u003e class for the basics), including free groups and group presentations, and their universal properties. The main results verified are that the deletion condition is both necessary and sufficient for a group with a set of generators of order two to be a Coxeter system, and that the apartments in a (thick) building are all uniformly Coxeter.","date":"July 1","id":269,"permalink":"/entries/buildings/","shortname":"Buildings","title":"Chamber Complexes, Coxeter Systems, and Buildings","topicLinks":["mathematics/algebra","mathematics/geometry"],"topics":["Mathematics/Algebra","Mathematics/Geometry"]},{"abstract":" This theory is a formalization of the resolution calculus for first-order logic. It is proven sound and complete. The soundness proof uses the substitution lemma, which shows a correspondence between substitutions and updates to an environment. The completeness proof uses semantic trees, i.e. trees whose paths are partial Herbrand interpretations. It employs Herbrand's theorem in a formulation which states that an unsatisfiable set of clauses has a finite closed semantic tree. It also uses the lifting lemma which lifts resolution derivation steps from the ground world up to the first-order world. The theory is presented in a paper in the Journal of Automated Reasoning [Sch18] which extends a paper presented at the International Conference on Interactive Theorem Proving [Sch16]. An earlier version was presented in an MSc thesis [Sch15]. The formalization mostly follows textbooks by Ben-Ari [BA12], Chang and Lee [CL73], and Leitsch [Lei97]. The theory is part of the IsaFoL project [IsaFoL]. \u003cp\u003e \u003ca name=\"Sch18\"\u003e\u003c/a\u003e[Sch18] Anders Schlichtkrull. \"Formalization of the Resolution Calculus for First-Order Logic\". Journal of Automated Reasoning, 2018.\u003cbr\u003e \u003ca name=\"Sch16\"\u003e\u003c/a\u003e[Sch16] Anders Schlichtkrull. \"Formalization of the Resolution Calculus for First-Order Logic\". In: ITP 2016. Vol. 9807. LNCS. Springer, 2016.\u003cbr\u003e \u003ca name=\"Sch15\"\u003e\u003c/a\u003e[Sch15] Anders Schlichtkrull. \u003ca href=\"https://people.compute.dtu.dk/andschl/Thesis.pdf\"\u003e \"Formalization of Resolution Calculus in Isabelle\"\u003c/a\u003e. \u003ca href=\"https://people.compute.dtu.dk/andschl/Thesis.pdf\"\u003ehttps://people.compute.dtu.dk/andschl/Thesis.pdf\u003c/a\u003e. MSc thesis. Technical University of Denmark, 2015.\u003cbr\u003e \u003ca name=\"BA12\"\u003e\u003c/a\u003e[BA12] Mordechai Ben-Ari. \u003ci\u003eMathematical Logic for Computer Science\u003c/i\u003e. 3rd. Springer, 2012.\u003cbr\u003e \u003ca name=\"CL73\"\u003e\u003c/a\u003e[CL73] Chin-Liang Chang and Richard Char-Tung Lee. \u003ci\u003eSymbolic Logic and Mechanical Theorem Proving\u003c/i\u003e. 1st. Academic Press, Inc., 1973.\u003cbr\u003e \u003ca name=\"Lei97\"\u003e\u003c/a\u003e[Lei97] Alexander Leitsch. \u003ci\u003eThe Resolution Calculus\u003c/i\u003e. Texts in theoretical computer science. Springer, 1997.\u003cbr\u003e \u003ca name=\"IsaFoL\"\u003e\u003c/a\u003e[IsaFoL] IsaFoL authors. \u003ca href=\"https://bitbucket.org/jasmin_blanchette/isafol\"\u003e IsaFoL: Isabelle Formalization of Logic\u003c/a\u003e. \u003ca href=\"https://bitbucket.org/jasmin_blanchette/isafol\"\u003ehttps://bitbucket.org/jasmin_blanchette/isafol\u003c/a\u003e.","date":"June 30","id":270,"permalink":"/entries/resolution_fol/","shortname":"Resolution_FOL","title":"The Resolution Calculus for First-Order Logic","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" We formalize the Z property introduced by Dehornoy and van Oostrom. First we show that for any abstract rewrite system, Z implies confluence. Then we give two examples of proofs using Z: confluence of lambda-calculus with respect to beta-reduction and confluence of combinatory logic.","date":"June 30","id":271,"permalink":"/entries/rewriting_z/","shortname":"Rewriting_Z","title":"The Z Property","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" The paper \"Compositional Verification and Refinement of Concurrent Value-Dependent Noninterference\" by Murray et. al. (CSF 2016) presents a compositional theory of refinement for a value-dependent noninterference property, defined in (Murray, PLAS 2015), for concurrent programs. This development formalises that refinement theory, and demonstrates its application on some small examples.","date":"June 28","id":272,"permalink":"/entries/dependent_sifum_refinement/","shortname":"Dependent_SIFUM_Refinement","title":"Compositional Security-Preserving Refinement for Concurrent Imperative Programs","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" This entry contains a definition of IP addresses and a library to work with them.  Generic IP addresses are modeled as machine words of arbitrary length. Derived from this generic definition, IPv4 addresses are 32bit machine words, IPv6 addresses are 128bit words. Additionally, IPv4 addresses can be represented in dot-decimal notation and IPv6 addresses in (compressed) colon-separated notation. We support toString functions and parsers for both notations. Sets of IP addresses can be represented with a netmask (e.g. 192.168.0.0/255.255.0.0) or in CIDR notation (e.g. 192.168.0.0/16). To provide executable code for set operations on IP address ranges, the library includes a datatype to work on arbitrary intervals of machine words.","date":"June 28","id":273,"permalink":"/entries/ip_addresses/","shortname":"IP_Addresses","title":"IP Addresses","topicLinks":["computer-science/networks"],"topics":["Computer science/Networks"]},{"abstract":" \u003cp\u003eThis entry provides three lemmas to count the number of multisets of a given size and finite carrier set. The first lemma provides a cardinality formula assuming that the multiset's elements are chosen from the given carrier set. The latter two lemmas provide formulas assuming that the multiset's elements also cover the given carrier set, i.e., each element of the carrier set occurs in the multiset at least once.\u003c/p\u003e  \u003cp\u003eThe proof of the first lemma uses the argument of the recurrence relation for counting multisets. The proof of the second lemma is straightforward, and the proof of the third lemma is easily obtained using the first cardinality lemma. A challenge for the formalization is the derivation of the required induction rule, which is a special combination of the induction rules for finite sets and natural numbers. The induction rule is derived by defining a suitable inductive predicate and transforming the predicate's induction rule.\u003c/p\u003e","date":"June 26","id":274,"permalink":"/entries/card_multisets/","shortname":"Card_Multisets","title":"Cardinality of Multisets","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" This article attempts to develop a usable framework for doing category theory in Isabelle/HOL.  Our point of view, which to some extent differs from that of the previous AFP articles on the subject, is to try to explore how category theory can be done efficaciously within HOL, rather than trying to match exactly the way things are done using a traditional approach.  To this end, we define the notion of category in an \"object-free\" style, in which a category is represented by a single partial composition operation on arrows.  This way of defining categories provides some advantages in the context of HOL, including the ability to avoid the use of records and the possibility of defining functors and natural transformations simply as certain functions on arrows, rather than as composite objects.  We define various constructions associated with the basic notions, including: dual category, product category, functor category, discrete category, free category, functor composition, and horizontal and vertical composite of natural transformations.  A \"set category\" locale is defined that axiomatizes the notion \"category of all sets at a type and all functions between them,\" and a fairly extensive set of properties of set categories is derived from the locale assumptions. The notion of a set category is used to prove the Yoneda Lemma in a general setting of a category equipped with a \"hom embedding,\" which maps arrows of the category to the \"universe\" of the set category.  We also give a treatment of adjunctions, defining adjunctions via left and right adjoint functors, natural bijections between hom-sets, and unit and counit natural transformations, and showing the equivalence of these definitions.  We also develop the theory of limits, including representations of functors, diagrams and cones, and diagonal functors.  We show that right adjoint functors preserve limits, and that limits can be constructed via products and equalizers.  We characterize the conditions under which limits exist in a set category. We also examine the case of limits in a functor category, ultimately culminating in a proof that the Yoneda embedding preserves limits.","date":"June 26","id":275,"permalink":"/entries/category3/","shortname":"Category3","title":"Category Theory with Adjunctions and Limits","topicLinks":["mathematics/category-theory"],"topics":["Mathematics/Category theory"]},{"abstract":" The paper \"Compositional Verification and Refinement of Concurrent Value-Dependent Noninterference\" by Murray et. al. (CSF 2016) presents a dependent security type system for compositionally verifying a value-dependent noninterference property, defined in (Murray, PLAS 2015), for concurrent programs. This development formalises that security definition, the type system and its soundness proof, and demonstrates its application on some small examples. It was derived from the SIFUM_Type_Systems AFP entry, by Sylvia Grewe, Heiko Mantel and Daniel Schoepe, and whose structure it inherits.","date":"June 25","id":276,"permalink":"/entries/dependent_sifum_type_systems/","shortname":"Dependent_SIFUM_Type_Systems","title":"A Dependent Security Type System for Concurrent Imperative Programs","topicLinks":["computer-science/security","computer-science/programming-languages/type-systems"],"topics":["Computer science/Security","Computer science/Programming languages/Type systems"]},{"abstract":" \u003cp\u003eIn this work, we define the Catalan numbers \u003cem\u003eC\u003csub\u003en\u003c/sub\u003e\u003c/em\u003e and prove several equivalent definitions (including some closed-form formulae). We also show one of their applications (counting the number of binary trees of size \u003cem\u003en\u003c/em\u003e), prove the asymptotic growth approximation \u003cem\u003eC\u003csub\u003en\u003c/sub\u003e \u0026sim; 4\u003csup\u003en\u003c/sup\u003e / (\u0026radic;\u003cspan style=\"text-decoration: overline\"\u003e\u0026pi;\u003c/span\u003e \u0026middot; n\u003csup\u003e1.5\u003c/sup\u003e)\u003c/em\u003e, and provide reasonably efficient executable code to compute them.\u003c/p\u003e  \u003cp\u003eThe derivation of the closed-form formulae uses algebraic manipulations of the ordinary generating function of the Catalan numbers, and the asymptotic approximation is then done using generalised binomial coefficients and the Gamma function. Thanks to these highly non-elementary mathematical tools, the proofs are very short and simple.\u003c/p\u003e","date":"June 21","id":277,"permalink":"/entries/catalan_numbers/","shortname":"Catalan_Numbers","title":"Catalan Numbers","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" Variants of Kleene algebra support program construction and verification by algebraic reasoning. This entry provides a verification component for Hoare logic based on Kleene algebra with tests, verification components for weakest preconditions and strongest postconditions based on Kleene algebra with domain and a component for step-wise refinement based on refinement Kleene algebra with tests. In addition to these components for the partial correctness of while programs, a verification component for total correctness based on divergence Kleene algebras and one for (partial correctness) of recursive programs based on domain quantales are provided. Finally we have integrated memory models for programs with pointers and a program trace semantics into the weakest precondition component.","date":"June 18","id":278,"permalink":"/entries/algebraic_vcs/","shortname":"Algebraic_VCs","title":"Program Construction and Verification Components Based on Kleene Algebra","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003eIn his outstanding work on Communicating Sequential Processes, Hoare has defined two fundamental binary operations allowing to compose the input processes into another, typically more complex, process: sequential composition and concurrent composition. Particularly, the output of the latter operation is a process in which any event not shared by both operands can occur whenever the operand that admits the event can engage in it, whereas any event shared by both operands can occur just in case both can engage in it.\u003c/p\u003e \u003cp\u003eThis paper formalizes Hoare's definition of concurrent composition and proves, in the general case of a possibly intransitive policy, that CSP noninterference security is conserved under this operation. This result, along with the previous analogous one concerning sequential composition, enables the construction of more and more complex processes enforcing noninterference security by composing, sequentially or concurrently, simpler secure processes, whose security can in turn be proven using either the definition of security, or unwinding theorems.\u003c/p\u003e","date":"June 13","id":279,"permalink":"/entries/noninterference_concurrent_composition/","shortname":"Noninterference_Concurrent_Composition","title":"Conservation of CSP Noninterference Security under Concurrent Composition","topicLinks":["computer-science/security","computer-science/concurrency/process-calculi"],"topics":["Computer science/Security","Computer science/Concurrency/Process calculi"]},{"abstract":" This entry contains an extension to the Isabelle library for fixed-width machine words. In particular, the entry adds quickcheck setup for words, printing as hexadecimals, additional operations, reasoning about alignment, signed words, enumerations of words, normalisation of word numerals, and an extensive library of properties about generic fixed-width words, as well as an instantiation of many of these to the commonly used 32 and 64-bit bases.","date":"June 9","id":280,"permalink":"/entries/word_lib/","shortname":"Word_Lib","title":"Finite Machine Word Library","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We formalize tree decompositions and tree width in Isabelle/HOL, proving that trees have treewidth 1.  We also show that every edge of a tree decomposition is a separation of the underlying graph. As an application of this theorem we prove that complete graphs of size n have treewidth n-1.","date":"May 31","id":281,"permalink":"/entries/tree_decomposition/","shortname":"Tree_Decomposition","title":"Tree Decomposition","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" This entry provides formulae for counting the number of equivalence relations and partial equivalence relations over a finite carrier set with given cardinality.  To count the number of equivalence relations, we provide bijections between equivalence relations and set partitions, and then transfer the main results of the two AFP entries, Cardinality of Set Partitions and Spivey's Generalized Recurrence for Bell Numbers, to theorems on equivalence relations. To count the number of partial equivalence relations, we observe that counting partial equivalence relations over a set A is equivalent to counting all equivalence relations over all subsets of the set A. From this observation and the results on equivalence relations, we show that the cardinality of partial equivalence relations over a finite set of cardinality n is equal to the n+1-th Bell number.","date":"May 24","id":282,"permalink":"/entries/card_equiv_relations/","shortname":"Card_Equiv_Relations","title":"Cardinality of Equivalence Relations","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" Brzozowski introduced the notion of derivatives for regular expressions. They can be used for a very simple regular expression matching algorithm. Sulzmann and Lu cleverly extended this algorithm in order to deal with POSIX matching, which is the underlying disambiguation strategy for regular expressions needed in lexers. In this entry we give our inductive definition of what a POSIX value is and show (i) that such a value is unique (for given regular expression and string being matched) and (ii) that Sulzmann and Lu's algorithm always generates such a value (provided that the regular expression matches the string). We also prove the correctness of an optimised version of the POSIX matching algorithm.","date":"May 24","id":283,"permalink":"/entries/posix-lexing/","shortname":"Posix-Lexing","title":"POSIX Lexing with Derivatives of Regular Expressions","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" \u003cp\u003eThe spectral radius of a matrix A is the maximum norm of all eigenvalues of A. In previous work we already formalized that for a complex matrix A, the values in A\u003csup\u003en\u003c/sup\u003e grow polynomially in n if and only if the spectral radius is at most one. One problem with the above characterization is the determination of all \u003cem\u003ecomplex\u003c/em\u003e eigenvalues. In case A contains only non-negative real values, a simplification is possible with the help of the Perron\u0026ndash;Frobenius theorem, which tells us that it suffices to consider only the \u003cem\u003ereal\u003c/em\u003e eigenvalues of A, i.e., applying Sturm's method can decide the polynomial growth of A\u003csup\u003en\u003c/sup\u003e. \u003c/p\u003e\u003cp\u003e We formalize the Perron\u0026ndash;Frobenius theorem based on a proof via Brouwer's fixpoint theorem, which is available in the HOL multivariate analysis (HMA) library. Since the results on the spectral radius is based on matrices in the Jordan normal form (JNF) library, we further develop a connection which allows us to easily transfer theorems between HMA and JNF. With this connection we derive the combined result: if A is a non-negative real matrix, and no real eigenvalue of A is strictly larger than one, then A\u003csup\u003en\u003c/sup\u003e is polynomially bounded in n. \u003c/p\u003e","date":"May 20","id":284,"permalink":"/entries/perron_frobenius/","shortname":"Perron_Frobenius","title":"Perron-Frobenius Theorem for Spectral Radius Analysis","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" The \u003ca href=\"http://incredible.pm\"\u003eIncredible Proof Machine\u003c/a\u003e is an interactive visual theorem prover which represents proofs as port graphs. We model this proof representation in Isabelle, and prove that it is just as powerful as natural deduction.","date":"May 20","id":285,"permalink":"/entries/incredible_proof_machine/","shortname":"Incredible_Proof_Machine","title":"The meta theory of the Incredible Proof Machine","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":" The impossibility of distributed consensus with one faulty process is a result with important consequences for real world distributed systems e.g., commits in replicated databases. Since proofs are not immune to faults and even plausible proofs with a profound formalism can conclude wrong results, we validate the fundamental result named FLP after Fischer, Lynch and Paterson. We present a formalization of distributed systems and the aforementioned consensus problem. Our proof is based on Hagen Völzer's paper \"A constructive proof for FLP\". In addition to the enhanced confidence in the validity of Völzer's proof, we contribute the missing gaps to show the correctness in Isabelle/HOL. We clarify the proof details and even prove fairness of the infinite execution that contradicts consensus. Our Isabelle formalization can also be reused for further proofs of properties of distributed systems.","date":"May 18","id":286,"permalink":"/entries/flp/","shortname":"FLP","title":"A Constructive Proof for FLP","topicLinks":["computer-science/concurrency"],"topics":["Computer science/Concurrency"]},{"abstract":" This article formalises a proof of the maximum-flow minimal-cut theorem for networks with countably many edges.  A network is a directed graph with non-negative real-valued edge labels and two dedicated vertices, the source and the sink.  A flow in a network assigns non-negative real numbers to the edges such that for all vertices except for the source and the sink, the sum of values on incoming edges equals the sum of values on outgoing edges.  A cut is a subset of the vertices which contains the source, but not the sink. Our theorem states that in every network, there is a flow and a cut such that the flow saturates all the edges going out of the cut and is zero on all the incoming edges.  The proof is based on the paper \u003cemph\u003eThe Max-Flow Min-Cut theorem for countable networks\u003c/emph\u003e by Aharoni et al.  Additionally, we prove a characterisation of the lifting operation for relations on discrete probability distributions, which leads to a concise proof of its distributivity over relation composition.","date":"May 9","id":287,"permalink":"/entries/mfmc_countable/","shortname":"MFMC_Countable","title":"A Formal Proof of the Max-Flow Min-Cut Theorem for Countable Networks","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" This work contains a formalisation of basic Randomised Social Choice, including Stochastic Dominance and Social Decision Schemes (SDSs) along with some of their most important properties (Anonymity, Neutrality, ex-post- and SD-Efficiency, SD-Strategy-Proofness) and two particular SDSs – Random Dictatorship and Random Serial Dictatorship (with proofs of the properties that they satisfy). Many important properties of these concepts are also proven – such as the two equivalent characterisations of Stochastic Dominance and the fact that SD-efficiency of a lottery only depends on the support.  The entry also provides convenient commands to define Preference Profiles, prove their well-formedness, and automatically derive restrictions that sufficiently nice SDSs need to satisfy on the defined profiles. Currently, the formalisation focuses on weak preferences and Stochastic Dominance, but it should be easy to extend it to other domains – such as strict preferences – or other lottery extensions – such as Bilinear Dominance or Pairwise Comparison.","date":"May 5","id":288,"permalink":"/entries/randomised_social_choice/","shortname":"Randomised_Social_Choice","title":"Randomised Social Choice Theory","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" This entry defines the Bell numbers as the cardinality of set partitions for a carrier set of given size, and derives Spivey's generalized recurrence relation for Bell numbers following his elegant and intuitive combinatorial proof. \u003cp\u003e As the set construction for the combinatorial proof requires construction of three intermediate structures, the main difficulty of the formalization is handling the overall combinatorial argument in a structured way. The introduced proof structure allows us to compose the combinatorial argument from its subparts, and supports to keep track how the detailed proof steps are related to the overall argument. To obtain this structure, this entry uses set monad notation for the set construction's definition, introduces suitable predicates and rules, and follows a repeating structure in its Isar proof.","date":"May 4","id":289,"permalink":"/entries/bell_numbers_spivey/","shortname":"Bell_Numbers_Spivey","title":"Spivey's Generalized Recurrence for Bell Numbers","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" This formalisation contains the proof that there is no anonymous and neutral Social Decision Scheme for at least four voters and alternatives that fulfils both SD-Efficiency and SD-Strategy- Proofness. The proof is a fully structured and quasi-human-redable one. It was derived from the (unstructured) SMT proof of the case for exactly four voters and alternatives by Brandl et al.  Their proof relies on an unverified translation of the original problem to SMT, and the proof that lifts the argument for exactly four voters and alternatives to the general case is also not machine-checked.  In this Isabelle proof, on the other hand, all of these steps are  fully proven and machine-checked. This is particularly important seeing as a previously published informal proof of a weaker statement contained a mistake in precisely this lifting step.","date":"May 4","id":290,"permalink":"/entries/sds_impossibility/","shortname":"SDS_Impossibility","title":"The Incompatibility of SD-Efficiency and SD-Strategy-Proofness","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" This formalization is concerned with the theory of Gröbner bases in (commutative) multivariate polynomial rings over fields, originally developed by Buchberger in his 1965 PhD thesis. Apart from the statement and proof of the main theorem of the theory, the formalization also implements Buchberger's algorithm for actually computing Gröbner bases as a tail-recursive function, thus allowing to effectively decide ideal membership in finitely generated polynomial ideals. Furthermore, all functions can be executed on a concrete representation of multivariate polynomials as association lists.","date":"May 2","id":291,"permalink":"/entries/groebner_bases/","shortname":"Groebner_Bases","title":"Gröbner Bases Theory","topicLinks":["mathematics/algebra","computer-science/algorithms/mathematical"],"topics":["Mathematics/Algebra","Computer science/Algorithms/Mathematical"]},{"abstract":" We provide a formal proof within First Order Relativity Theory that no observer can travel faster than the speed of light. Originally reported in Stannett \u0026 Németi (2014) \"Using Isabelle/HOL to verify first-order relativity theory\", Journal of Automated Reasoning 52(4), pp. 361-378.","date":"April 28","id":292,"permalink":"/entries/no_ftl_observers/","shortname":"No_FTL_observers","title":"No Faster-Than-Light Observers","topicLinks":["mathematics/physics"],"topics":["Mathematics/Physics"]},{"abstract":" The theory provides a formalisation of the Cocke-Younger-Kasami algorithm (CYK for short), an approach to solving the word problem for context-free languages.  CYK decides if a word is in the languages generated by a context-free grammar in Chomsky normal form. The formalized algorithm is executable.","date":"April 27","id":293,"permalink":"/entries/cyk/","shortname":"CYK","title":"A formalisation of the Cocke-Younger-Kasami algorithm","topicLinks":["computer-science/algorithms","computer-science/automata-and-formal-languages"],"topics":["Computer science/Algorithms","Computer science/Automata and formal languages"]},{"abstract":" We present a verified and executable implementation of ROBDDs in Isabelle/HOL. Our implementation relates pointer-based computation in the Heap monad to operations on an abstract definition of boolean functions. Internally, we implemented the if-then-else combinator in a recursive fashion, following the Shannon decomposition of the argument functions. The implementation mixes and adapts known techniques and is built with efficiency in mind.","date":"April 27","id":294,"permalink":"/entries/robdd/","shortname":"ROBDD","title":"Algorithms for Reduced Ordered Binary Decision Diagrams","topicLinks":["computer-science/algorithms","computer-science/data-structures"],"topics":["Computer science/Algorithms","Computer science/Data structures"]},{"abstract":" \u003cp\u003eIn his outstanding work on Communicating Sequential Processes, Hoare has defined two fundamental binary operations allowing to compose the input processes into another, typically more complex, process: sequential composition and concurrent composition. Particularly, the output of the former operation is a process that initially behaves like the first operand, and then like the second operand once the execution of the first one has terminated successfully, as long as it does.\u003c/p\u003e \u003cp\u003eThis paper formalizes Hoare's definition of sequential composition and proves, in the general case of a possibly intransitive policy, that CSP noninterference security is conserved under this operation, provided that successful termination cannot be affected by confidential events and cannot occur as an alternative to other events in the traces of the first operand. Both of these assumptions are shown, by means of counterexamples, to be necessary for the theorem to hold.\u003c/p\u003e","date":"April 26","id":295,"permalink":"/entries/noninterference_sequential_composition/","shortname":"Noninterference_Sequential_Composition","title":"Conservation of CSP Noninterference Security under Sequential Composition","topicLinks":["computer-science/security","computer-science/concurrency/process-calculi"],"topics":["Computer science/Security","Computer science/Concurrency/Process calculi"]},{"abstract":" Kleene algebras with domain are Kleene algebras endowed with an operation that maps each element of the algebra to its domain of definition (or its complement) in abstract fashion. They form a simple algebraic basis for Hoare logics, dynamic logics or predicate transformer semantics. We formalise a modular hierarchy of algebras with domain and antidomain (domain complement) operations in Isabelle/HOL that ranges from domain and antidomain semigroups to modal Kleene algebras and divergence Kleene algebras. We link these algebras with models of binary relations and program traces. We include some examples from modal logics, termination and program analysis.","date":"April 12","id":296,"permalink":"/entries/kad/","shortname":"KAD","title":"Kleene Algebras with Domain","topicLinks":["computer-science/programming-languages/logics","computer-science/automata-and-formal-languages","mathematics/algebra"],"topics":["Computer science/Programming languages/Logics","Computer science/Automata and formal languages","Mathematics/Algebra"]},{"abstract":" We provide formal proofs in Isabelle-HOL (using mostly structured Isar proofs) of the soundness and completeness of the Resolution rule in propositional logic.  The completeness proofs take into account the usual redundancy elimination rules (tautology elimination and subsumption), and several refinements of the Resolution rule are considered: ordered resolution (with selection functions), positive and negative resolution, semantic resolution and unit resolution (the latter refinement is complete only for clause sets that are Horn- renamable). We also define a concrete procedure for computing saturated sets and establish its soundness and completeness. The clause sets are not assumed to be finite, so that the results can be applied to formulas obtained by grounding sets of first-order clauses (however, a total ordering among atoms is assumed to be given). Next, we show that the unrestricted Resolution rule is deductive- complete, in the sense that it is able to generate all  (prime) implicates of any set of propositional clauses (i.e., all entailment- minimal, non-valid, clausal consequences of the considered set). The generation of prime implicates is an important problem, with many applications in artificial intelligence and verification (for abductive reasoning, knowledge compilation, diagnosis, debugging etc.). We also show that implicates can be computed in an incremental way, by fixing an ordering among all the atoms in the considered sets and resolving upon these atoms one by one in the considered order (with no backtracking). This feature is critical for the efficient computation of prime implicates. Building on these results, we provide a procedure for computing such implicates and establish its soundness and completeness.","date":"March 11","id":297,"permalink":"/entries/proprespi/","shortname":"PropResPI","title":"Propositional Resolution and Prime Implicates Generation","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":" The Cartan fixed point theorems concern the group of holomorphic automorphisms on a connected open set of C\u003csup\u003en\u003c/sup\u003e. Ciolli et al. have formalised the one-dimensional case of these theorems in HOL Light. This entry contains their proofs, ported to Isabelle/HOL.  Thus it addresses the authors' remark that \"it would be important to write a formal proof in a language that can be read by both humans and machines\".","date":"March 8","id":298,"permalink":"/entries/cartan_fp/","shortname":"Cartan_FP","title":"The Cartan Fixed Point Theorems","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" Timed automata are a widely used formalism for modeling real-time systems, which is employed  in a class of successful model checkers such as UPPAAL [LPY97], HyTech [HHWt97] or Kronos [Yov97].  This work formalizes the theory for the subclass of diagonal-free timed automata,  which is sufficient to model many interesting problems.  We first define the basic concepts and semantics of diagonal-free timed automata.  Based on this, we prove two types of decidability results for the language emptiness problem.    The first is the classic result of Alur and Dill [AD90, AD94],  which uses a finite partitioning of the state space into so-called `regions`.    Our second result focuses on an approach based on `Difference Bound Matrices (DBMs)`,  which is practically used by model checkers.  We prove the correctness of the basic forward analysis operations on DBMs.  One of these operations is the Floyd-Warshall algorithm for the all-pairs shortest paths problem. To obtain a finite search space, a widening operation has to be used for this kind of analysis.  We use Patricia Bouyer's [Bou04] approach to prove that this widening operation  is correct in the sense that DBM-based forward analysis in combination with the widening operation also decides language emptiness. The interesting property of this proof is that the first  decidability result is reused to obtain the second one.","date":"March 8","id":299,"permalink":"/entries/timed_automata/","shortname":"Timed_Automata","title":"Timed Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" This theory provides a formalisation of linear temporal logic (LTL) and unifies previous formalisations within the AFP. This entry establishes syntax and semantics for this logic and decouples it from existing entries, yielding a common environment for theories reasoning about LTL. Furthermore a parser written in SML and an executable simplifier are provided.","date":"March 1","id":300,"permalink":"/entries/ltl/","shortname":"LTL","title":"Linear Temporal Logic","topicLinks":["logic/general-logic/temporal-logic","computer-science/automata-and-formal-languages"],"topics":["Logic/General logic/Temporal logic","Computer science/Automata and formal languages"]},{"abstract":" \u003cp\u003e These theories formalize the quantitative analysis of a number of classical algorithms for the list update problem: 2-competitiveness of move-to-front, the lower bound of 2 for the competitiveness of deterministic list update algorithms and 1.6-competitiveness of the randomized COMB algorithm, the best randomized list update algorithm known to date. The material is based on the first two chapters of \u003ci\u003eOnline Computation and Competitive Analysis\u003c/i\u003e by Borodin and El-Yaniv. \u003c/p\u003e \u003cp\u003e For an informal description see the FSTTCS 2016 publication \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/fsttcs16.html\"\u003eVerified Analysis of List Update Algorithms\u003c/a\u003e by Haslbeck and Nipkow. \u003c/p\u003e","date":"February 17","id":301,"permalink":"/entries/list_update/","shortname":"List_Update","title":"Analysis of List Update Algorithms","topicLinks":["computer-science/algorithms/online"],"topics":["Computer science/Algorithms/Online"]},{"abstract":" \u003cp\u003e We define a functional variant of the static single assignment (SSA) form construction algorithm described by \u003ca href=\"https://doi.org/10.1007/978-3-642-37051-9_6\"\u003eBraun et al.\u003c/a\u003e, which combines simplicity and efficiency. The definition is based on a general, abstract control flow graph representation using Isabelle locales. \u003c/p\u003e \u003cp\u003e We prove that the algorithm's output is semantically equivalent to the input according to a small-step semantics, and that it is in minimal SSA form for the common special case of reducible inputs. We then show the satisfiability of the locale assumptions by giving instantiations for a simple While language. \u003c/p\u003e \u003cp\u003e Furthermore, we use a generic instantiation based on typedefs in order to extract OCaml code and replace the unverified SSA construction algorithm of the \u003ca href=\"https://doi.org/10.1145/2579080\"\u003eCompCertSSA project\u003c/a\u003e with it. \u003c/p\u003e \u003cp\u003e A more detailed description of the verified SSA construction can be found in the paper \u003ca href=\"https://doi.org/10.1145/2892208.2892211\"\u003eVerified Construction of Static Single Assignment Form\u003c/a\u003e, CC 2016. \u003c/p\u003e","date":"February 5","id":302,"permalink":"/entries/formal_ssa/","shortname":"Formal_SSA","title":"Verified Construction of Static Single Assignment Form","topicLinks":["computer-science/algorithms","computer-science/programming-languages/transformations"],"topics":["Computer science/Algorithms","Computer science/Programming languages/Transformations"]},{"abstract":" Based on existing libraries for polynomial interpolation and matrices, we formalized several factorization algorithms for polynomials, including Kronecker's algorithm for integer polynomials, Yun's square-free factorization algorithm for field polynomials, and Berlekamp's algorithm for polynomials over finite fields. By combining the last one with Hensel's lifting, we derive an efficient factorization algorithm for the integer polynomials, which is then lifted for rational polynomials by mechanizing Gauss' lemma. Finally, we assembled a combined factorization algorithm for rational polynomials, which combines all the mentioned algorithms and additionally uses the explicit formula for roots of quadratic polynomials and a rational root test. \u003cp\u003e As side products, we developed division algorithms for polynomials over integral domains, as well as primality-testing and prime-factorization algorithms for integers.","date":"January 29","id":303,"permalink":"/entries/polynomial_factorization/","shortname":"Polynomial_Factorization","title":"Polynomial Factorization","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" We formalized three algorithms for polynomial interpolation over arbitrary fields: Lagrange's explicit expression, the recursive algorithm of Neville and Aitken, and the Newton interpolation in combination with an efficient implementation of divided differences.  Variants of these algorithms for integer polynomials are also available, where sometimes the interpolation can fail; e.g., there is no linear integer polynomial \u003ci\u003ep\u003c/i\u003e such that \u003ci\u003ep(0) = 0\u003c/i\u003e and \u003ci\u003ep(2) = 1\u003c/i\u003e. Moreover, for the Newton interpolation for integer polynomials, we proved that all intermediate results that are computed during the algorithm must be integers.  This admits an early failure detection in the implementation.  Finally, we proved the uniqueness of polynomial interpolation. \u003cp\u003e The development also contains improved code equations to speed up the division of integers in target languages.","date":"January 29","id":304,"permalink":"/entries/polynomial_interpolation/","shortname":"Polynomial_Interpolation","title":"Polynomial Interpolation","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" This work contains a formalization of some topics in knot theory. The concepts that were formalized include definitions of tangles, links, framed links and link/tangle equivalence. The formalization is based on a formulation of links in terms of tangles. We further construct and prove the invariance of the Bracket polynomial. Bracket polynomial is an invariant of framed links closely linked to the Jones polynomial. This is perhaps the first attempt to formalize any aspect of knot theory in an interactive proof assistant.","date":"January 20","id":305,"permalink":"/entries/knot_theory/","shortname":"Knot_Theory","title":"Knot Theory","topicLinks":["mathematics/topology"],"topics":["Mathematics/Topology"]},{"abstract":" In this work, the Kronecker tensor product of matrices and the proofs of some of its properties are formalized. Properties which have been formalized include associativity of the tensor product and the mixed-product property.","date":"January 18","id":306,"permalink":"/entries/matrix_tensor/","shortname":"Matrix_Tensor","title":"Tensor Product of Matrices","topicLinks":["computer-science/data-structures","mathematics/algebra"],"topics":["Computer science/Data structures","Mathematics/Algebra"]},{"abstract":" This entry provides a basic library for number partitions, defines the two-argument partition function through its recurrence relation and relates this partition function to the cardinality of number partitions. The main proof shows that the recursively-defined partition function with arguments n and k equals the cardinality of number partitions of n with exactly k parts. The combinatorial proof follows the proof sketch of Theorem 2.4.1 in Mazur's textbook `Combinatorics: A Guided Tour`. This entry can serve as starting point for various more intrinsic properties about number partitions, the partition function and related recurrence relations.","date":"January 14","id":307,"permalink":"/entries/card_number_partitions/","shortname":"Card_Number_Partitions","title":"Cardinality of Number Partitions","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" \u003cp\u003e This entry contains a definition of angles between vectors and between three points. Building on this, we prove basic geometric properties of triangles, such as the Isosceles Triangle Theorem, the Law of Sines and the Law of Cosines, that the sum of the angles of a triangle is π, and the congruence theorems for triangles. \u003c/p\u003e\u003cp\u003e The definitions and proofs were developed following those by John Harrison in HOL Light. However, due to Isabelle's type class system, all definitions and theorems in the Isabelle formalisation hold for all real inner product spaces. \u003c/p\u003e","date":"December 28","id":308,"permalink":"/entries/triangle/","shortname":"Triangle","title":"Basic Geometric Properties of Triangles","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":" \u003cp\u003e Descartes' Rule of Signs relates the number of positive real roots of a polynomial with the number of sign changes in its coefficient sequence. \u003c/p\u003e\u003cp\u003e Our proof follows the simple inductive proof given by Rob Arthan, which was also used by John Harrison in his HOL Light formalisation. We proved most of the lemmas for arbitrary linearly-ordered integrity domains (e.g. integers, rationals, reals); the main result, however, requires the intermediate value theorem and was therefore only proven for real polynomials. \u003c/p\u003e","date":"December 28","id":309,"permalink":"/entries/descartes_sign_rule/","shortname":"Descartes_Sign_Rule","title":"Descartes' Rule of Signs","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" \u003cp\u003e Liouville numbers are a class of transcendental numbers that can be approximated particularly well with rational numbers. Historically, they were the first numbers whose transcendence was proven. \u003c/p\u003e\u003cp\u003e In this entry, we define the concept of Liouville numbers as well as the standard construction to obtain Liouville numbers (including Liouville's constant) and we prove their most important properties: irrationality and transcendence. \u003c/p\u003e\u003cp\u003e The proof is very elementary and requires only standard arithmetic, the Mean Value Theorem for polynomials, and the boundedness of polynomials on compact intervals. \u003c/p\u003e","date":"December 28","id":310,"permalink":"/entries/liouville_numbers/","shortname":"Liouville_Numbers","title":"Liouville numbers","topicLinks":["mathematics/analysis","mathematics/number-theory"],"topics":["Mathematics/Analysis","Mathematics/Number theory"]},{"abstract":" \u003cp\u003e In this work, we prove the lower bound \u003cspan class=\"nobr\"\u003eln(H_n) - ln(5/3)\u003c/span\u003e for the partial sum of the Prime Harmonic series and, based on this, the divergence of the Prime Harmonic Series \u003cspan class=\"nobr\"\u003e∑[p\u0026thinsp;prime]\u0026thinsp;·\u0026thinsp;1/p.\u003c/span\u003e \u003c/p\u003e\u003cp\u003e The proof relies on the unique squarefree decomposition of natural numbers. This is similar to Euler's original proof (which was highly informal and morally questionable). Its advantage over proofs by contradiction, like the famous one by Paul Erdős, is that it provides a relatively good lower bound for the partial sums. \u003c/p\u003e","date":"December 28","id":311,"permalink":"/entries/prime_harmonic_series/","shortname":"Prime_Harmonic_Series","title":"The Divergence of the Prime Harmonic Series","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":"Based on existing libraries for matrices, factorization of rational polynomials, and Sturm's theorem, we formalized algebraic numbers in Isabelle/HOL. Our development serves as an implementation for real and complex numbers, and it admits to compute roots and completely factorize real and complex polynomials, provided that all coefficients are rational numbers. Moreover, we provide two implementations to display algebraic numbers, an injective and expensive one, or a faster but approximative version. \u003c/p\u003e\u003cp\u003e To this end, we mechanized several results on resultants, which also required us to prove that polynomials over a unique factorization domain form again a unique factorization domain. \u003c/p\u003e","date":"December 22","id":312,"permalink":"/entries/algebraic_numbers/","shortname":"Algebraic_Numbers","title":"Algebraic Numbers in Isabelle/HOL","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"Applicative functors augment computations with effects by lifting function application to types which model the effects.  As the structure of the computation cannot depend on the effects, applicative expressions can be analysed statically.  This allows us to lift universally quantified equations to the effectful types, as observed by Hinze. Thus, equational reasoning over effectful computations can be reduced to pure types. \u003c/p\u003e\u003cp\u003e This entry provides a package for registering applicative functors and two proof methods for lifting of equations over applicative functors. The first method normalises applicative expressions according to the laws of applicative functors. This way, equations whose two sides contain the same list of variables can be lifted to every applicative functor. \u003c/p\u003e\u003cp\u003e To lift larger classes of equations, the second method exploits a number of additional properties (e.g., commutativity of effects) provided the properties have been declared for the concrete applicative functor at hand upon registration. \u003c/p\u003e\u003cp\u003e We declare several types from the Isabelle library as applicative functors and illustrate the use of the methods with two examples: the lifting of the arithmetic type class hierarchy to streams and the verification of a relabelling function on binary trees. We also formalise and verify the normalisation algorithm used by the first proof method. \u003c/p\u003e","date":"December 22","id":313,"permalink":"/entries/applicative_lifting/","shortname":"Applicative_Lifting","title":"Applicative Lifting","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"The Stern-Brocot tree contains all rational numbers exactly once and in their lowest terms.  We formalise the Stern-Brocot tree as a coinductive tree using recursive and iterative specifications, which we have proven equivalent, and show that it indeed contains all the numbers as stated.  Following Hinze, we prove that the Stern-Brocot tree can be linearised looplessly into Stern's diatonic sequence (also known as Dijkstra's fusc function) and that it is a permutation of the Bird tree. \u003c/p\u003e\u003cp\u003e The reasoning stays at an abstract level by appealing to the uniqueness of solutions of guarded recursive equations and lifting algebraic laws point-wise to trees and streams using applicative functors. \u003c/p\u003e","date":"December 22","id":314,"permalink":"/entries/stern_brocot/","shortname":"Stern_Brocot","title":"The Stern-Brocot Tree","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":" The theory's main theorem states that the cardinality of set partitions of size k on a carrier set of size n is expressed by Stirling numbers of the second kind. In Isabelle, Stirling numbers of the second kind are defined in the AFP entry `Discrete Summation` through their well-known recurrence relation. The main theorem relates them to the alternative definition as cardinality of set partitions. The proof follows the simple and short explanation in Richard P. Stanley's `Enumerative Combinatorics: Volume 1` and Wikipedia, and unravels the full details and implicit reasoning steps of these explanations.","date":"December 12","id":315,"permalink":"/entries/card_partitions/","shortname":"Card_Partitions","title":"Cardinality of Set Partitions","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" A Latin Square is a n x n table filled with integers from 1 to n where each number appears exactly once in each row and each column. A Latin Rectangle is a partially filled n x n table with r filled rows and n-r empty rows, such that each number appears at most once in each row and each column. The main result of this theory is that any Latin Rectangle can be completed to a Latin Square.","date":"December 2","id":316,"permalink":"/entries/latin_square/","shortname":"Latin_Square","title":"Latin Square","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":"Ergodic theory is the branch of mathematics that studies the behaviour of measure preserving transformations, in finite or infinite measure. It interacts both with probability theory (mainly through measure theory) and with geometry as a lot of interesting examples are from geometric origin. We implement the first definitions and theorems of ergodic theory, including notably Poicaré recurrence theorem for finite measure preserving systems (together with the notion of conservativity in general), induced maps, Kac's theorem, Birkhoff theorem (arguably the most important theorem in ergodic theory), and variations around it such as conservativity of the corresponding skew product, or Atkinson lemma.","date":"December 1","id":317,"permalink":"/entries/ergodic_theory/","shortname":"Ergodic_Theory","title":"Ergodic Theory","topicLinks":["mathematics/probability-theory"],"topics":["Mathematics/Probability theory"]},{"abstract":" Euler's Partition Theorem states that the number of partitions with only distinct parts is equal to the number of partitions with only odd parts. The combinatorial proof follows John Harrison's HOL Light formalization. This theorem is the 45th theorem of the Top 100 Theorems list.","date":"November 19","id":318,"permalink":"/entries/euler_partition/","shortname":"Euler_Partition","title":"Euler's Partition Theorem","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":"We formalize the Tortoise and Hare cycle-finding algorithm ascribed to Floyd by Knuth, and an improved version due to Brent.","date":"November 18","id":319,"permalink":"/entries/tortoisehare/","shortname":"TortoiseHare","title":"The Tortoise and Hare Algorithm","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" This development provides a formalization of planarity based on combinatorial maps and proves that Kuratowski's theorem implies combinatorial planarity. Moreover, it contains verified implementations of programs checking certificates for planarity (i.e., a combinatorial map) or non-planarity (i.e., a Kuratowski subgraph).","date":"November 11","id":320,"permalink":"/entries/planarity_certificates/","shortname":"Planarity_Certificates","title":"Planarity Certificates","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" We present a formalization of parity games (a two-player game on directed graphs) and a proof of their positional determinacy in Isabelle/HOL.  This proof works for both finite and infinite games.","date":"November 2","id":321,"permalink":"/entries/parity_game/","shortname":"Parity_Game","title":"Positional Determinacy of Parity Games","topicLinks":["mathematics/games-and-economics","mathematics/graph-theory"],"topics":["Mathematics/Games and economics","Mathematics/Graph theory"]},{"abstract":" We represent a theory \u003ci\u003eof\u003c/i\u003e (a fragment of) Isabelle/HOL \u003ci\u003ein\u003c/i\u003e Isabelle/HOL. The purpose of this exercise is to write packages for domain-specific specifications such as class models, B-machines, ..., and generally speaking, any domain-specific languages whose abstract syntax can be defined by a HOL \"datatype\". On this basis, the Isabelle code-generator can then be used to generate code for global context transformations as well as tactic code. \u003cp\u003e Consequently the package is geared towards parsing, printing and code-generation to the Isabelle API. It is at the moment not sufficiently rich for doing meta theory on Isabelle itself. Extensions in this direction are possible though. \u003cp\u003e Moreover, the chosen fragment is fairly rudimentary. However it should be easily adapted to one's needs if a package is written on top of it. The supported API contains types, terms, transformation of global context like definitions and data-type declarations as well as infrastructure for Isar-setups. \u003cp\u003e This theory is drawn from the \u003ca href=\"http://isa-afp.org/entries/Featherweight_OCL.html\"\u003eFeatherweight OCL\u003c/a\u003e project where it is used to construct a package for object-oriented data-type theories generated from UML class diagrams. The Featherweight OCL, for example, allows for both the direct execution of compiled tactic code by the Isabelle API as well as the generation of \".thy\"-files for debugging purposes. \u003cp\u003e Gained experience from this project shows that the compiled code is sufficiently efficient for practical purposes while being based on a formal \u003ci\u003emodel\u003c/i\u003e on which properties of the package can be proven such as termination of certain transformations, correctness, etc.","date":"September 16","id":322,"permalink":"/entries/isabelle_meta_model/","shortname":"Isabelle_Meta_Model","title":"A Meta-Model for the Isabelle API","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"Recently, Javier Esparza and Jan Kretinsky proposed a new method directly translating linear temporal logic (LTL) formulas to deterministic (generalized) Rabin automata. Compared to the existing approaches of constructing a non-deterministic Buechi-automaton in the first step and then applying a determinization procedure (e.g. some variant of Safra's construction) in a second step, this new approach preservers a relation between the formula and the states of the resulting automaton. While the old approach produced a monolithic structure, the new method is compositional. Furthermore, in some cases the resulting automata are much smaller than the automata generated by existing approaches. In order to ensure the correctness of the construction, this entry contains a complete formalisation and verification of the translation. Furthermore from this basis executable code is generated.","date":"September 4","id":323,"permalink":"/entries/ltl_to_dra/","shortname":"LTL_to_DRA","title":"Converting Linear Temporal Logic to Deterministic (Generalized) Rabin Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" \u003cp\u003e Matrix interpretations are useful as measure functions in termination proving. In order to use these interpretations also for complexity analysis, the growth rate of matrix powers has to examined. Here, we formalized a central result of spectral radius theory, namely that the growth rate is polynomially bounded if and only if the spectral radius of a matrix is at most one. \u003c/p\u003e\u003cp\u003e To formally prove this result we first studied the growth rates of matrices in Jordan normal form, and prove the result that every complex matrix has a Jordan normal form using a constructive prove via Schur decomposition. \u003c/p\u003e\u003cp\u003e The whole development is based on a new abstract type for matrices, which is also executable by a suitable setup of the code generator. It completely subsumes our former AFP-entry on executable matrices, and its main advantage is its close connection to the HMA-representation which allowed us to easily adapt existing proofs on determinants. \u003c/p\u003e\u003cp\u003e All the results have been applied to improve CeTA, our certifier to validate termination and complexity proof certificates. \u003c/p\u003e","date":"August 21","id":324,"permalink":"/entries/jordan_normal_form/","shortname":"Jordan_Normal_Form","title":"Matrices, Jordan Normal Forms, and Spectral Radius Theory","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"This theory formalizes the commutation version of decreasing diagrams for Church-Rosser modulo. The proof follows Felgenhauer and van Oostrom (RTA 2013). The theory also provides important specializations, in particular van Oostrom’s conversion version (TCS 2008) of decreasing diagrams.","date":"August 20","id":325,"permalink":"/entries/decreasing-diagrams-ii/","shortname":"Decreasing-Diagrams-II","title":"Decreasing Diagrams II","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":" \u003cp\u003e The necessary and sufficient condition for CSP noninterference security stated by the Ipurge Unwinding Theorem is expressed in terms of a pair of event lists varying over the set of process traces. This does not render it suitable for the subsequent application of rule induction in the case of a process defined inductively, since rule induction may rather be applied to a single variable ranging over an inductively defined set. \u003c/p\u003e\u003cp\u003e Starting from the Ipurge Unwinding Theorem, this paper derives a necessary and sufficient condition for CSP noninterference security that involves a single event list varying over the set of process traces, and is thus suitable for rule induction; hence its name, Inductive Unwinding Theorem. Similarly to the Ipurge Unwinding Theorem, the new theorem only requires to consider individual accepted and refused events for each process trace, and applies to the general case of a possibly intransitive noninterference policy. Specific variants of this theorem are additionally proven for deterministic processes and trace set processes. \u003c/p\u003e","date":"August 18","id":326,"permalink":"/entries/noninterference_inductive_unwinding/","shortname":"Noninterference_Inductive_Unwinding","title":"The Inductive Unwinding Theorem for CSP Noninterference Security","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"We provide a formal framework for the theory of representations of finite groups, as modules over the group ring. Along the way, we develop the general theory of groups (relying on the group_add class for the basics), modules, and vector spaces, to the extent required for theory of group representations. We then provide formal proofs of several important introductory theorems in the subject, including Maschke's theorem, Schur's lemma, and Frobenius reciprocity. We also prove that every irreducible representation is isomorphic to a submodule of the group ring, leading to the fact that for a finite group there are only finitely many isomorphism classes of irreducible representations. In all of this, no restriction is made on the characteristic of the ring or field of scalars until the definition of a group representation, and then the only restriction made is that the characteristic must not divide the order of the group.","date":"August 12","id":327,"permalink":"/entries/rep_fin_groups/","shortname":"Rep_Fin_Groups","title":"Representations of Finite Groups","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"Encodings or the proof of their absence are the main way to compare process calculi. To analyse the quality of encodings and to rule out trivial or meaningless encodings, they are augmented with quality criteria. There exists a bunch of different criteria and different variants of criteria in order to reason in different settings. This leads to incomparable results. Moreover it is not always clear whether the criteria used to obtain a result in a particular setting do indeed fit to this setting. We show how to formally reason about and compare encodability criteria by mapping them on requirements on a relation between source and target terms that is induced by the encoding function. In particular we analyse the common criteria full abstraction, operational correspondence, divergence reflection, success sensitiveness, and respect of barbs; e.g. we analyse the exact nature of the simulation relation (coupled simulation versus bisimulation) that is induced by different variants of operational correspondence. This way we reduce the problem of analysing or comparing encodability criteria to the better understood problem of comparing relations on processes.","date":"August 10","id":328,"permalink":"/entries/encodability_process_calculi/","shortname":"Encodability_Process_Calculi","title":"Analysing and Comparing Encodability Criteria for Process Calculi","topicLinks":["computer-science/concurrency/process-calculi"],"topics":["Computer science/Concurrency/Process calculi"]},{"abstract":" Isabelle/Isar provides named cases to structure proofs. This article contains an implementation of a proof method \u003ctt\u003ecasify\u003c/tt\u003e, which can be used to easily extend proof tools with support for named cases. Such a proof tool must produce labeled subgoals, which are then interpreted by \u003ctt\u003ecasify\u003c/tt\u003e. \u003cp\u003e As examples, this work contains verification condition generators producing named cases for three languages: The Hoare language from \u003ctt\u003eHOL/Library\u003c/tt\u003e, a monadic language for computations with failure (inspired by the AutoCorres tool), and a language of conditional expressions. These VCGs are demonstrated by a number of example programs.","date":"July 21","id":329,"permalink":"/entries/case_labeling/","shortname":"Case_Labeling","title":"Generating Cases from Labeled Subgoals","topicLinks":["tools","computer-science/programming-languages/misc"],"topics":["Tools","Computer science/Programming languages/Misc"]},{"abstract":"This entry provides Landau symbols to describe and reason about the asymptotic growth of functions for sufficiently large inputs. A number of simplification procedures are provided for additional convenience: cancelling of dominated terms in sums under a Landau symbol, cancelling of common factors in products, and a decision procedure for Landau expressions containing products of powers of functions like x, ln(x), ln(ln(x)) etc.","date":"July 14","id":330,"permalink":"/entries/landau_symbols/","shortname":"Landau_Symbols","title":"Landau Symbols","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"This article contains a formalisation of the Akra-Bazzi method based on a proof by Leighton. It is a generalisation of the well-known Master Theorem for analysing the complexity of Divide \u0026 Conquer algorithms. We also include a generalised version of the Master theorem based on the Akra-Bazzi theorem, which is easier to apply than the Akra-Bazzi theorem itself. \u003cp\u003e Some proof methods that facilitate applying the Master theorem are also included. For a more detailed explanation of the formalisation and the proof methods, see the accompanying paper (publication forthcoming).","date":"July 14","id":331,"permalink":"/entries/akra_bazzi/","shortname":"Akra_Bazzi","title":"The Akra-Bazzi theorem and the Master theorem","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"Hermite Normal Form is a canonical matrix analogue of Reduced Echelon Form, but involving matrices over more general rings. In this work we formalise an algorithm to compute the Hermite Normal Form of a matrix by means of elementary row operations, taking advantage of the Echelon Form AFP entry. We have proven the correctness of such an algorithm and refined it to immutable arrays. Furthermore, we have also formalised the uniqueness of the Hermite Normal Form of a matrix. Code can be exported and some examples of execution involving integer matrices and polynomial matrices are presented as well.","date":"July 7","id":332,"permalink":"/entries/hermite/","shortname":"Hermite","title":"Hermite Normal Form","topicLinks":["computer-science/algorithms/mathematical","mathematics/algebra"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Algebra"]},{"abstract":" The Derangements Formula describes the number of fixpoint-free permutations as a closed formula. This theorem is the 88th theorem in a list of the ``\u003ca href=\"http://www.cs.ru.nl/~freek/100/\"\u003eTop 100 Mathematical Theorems\u003c/a\u003e''.","date":"June 27","id":333,"permalink":"/entries/derangements/","shortname":"Derangements","title":"Derangements Formula","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" Binary multirelations associate elements of a set with its subsets; hence they are binary relations from a set to its power set. Applications include alternating automata, models and logics for games, program semantics with dual demonic and angelic nondeterministic choices and concurrent dynamic logics. This proof document supports an arXiv article that formalises the basic algebra of multirelations and proposes axiom systems for them, ranging from weak bi-monoids to weak bi-quantales.","date":"June 11","id":334,"permalink":"/entries/multirelations/","shortname":"Multirelations","title":"Binary Multirelations","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" \u003cp\u003e Among the various mathematical tools introduced in his outstanding work on Communicating Sequential Processes, Hoare has defined \"interleaves\" as the predicate satisfied by any three lists such that the first list may be split into sublists alternately extracted from the other two ones, whatever is the criterion for extracting an item from either one list or the other in each step. \u003c/p\u003e\u003cp\u003e This paper enriches Hoare's definition by identifying such criterion with the truth value of a predicate taking as inputs the head and the tail of the first list. This enhanced \"interleaves\" predicate turns out to permit the proof of equalities between lists without the need of an induction. Some rules that allow to infer \"interleaves\" statements without induction, particularly applying to the addition or removal of a prefix to the input lists, are also proven. Finally, a stronger version of the predicate, named \"Interleaves\", is shown to fulfil further rules applying to the addition or removal of a suffix to the input lists. \u003c/p\u003e","date":"June 11","id":335,"permalink":"/entries/list_interleaving/","shortname":"List_Interleaving","title":"Reasoning about Lists via List Interleaving","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" \u003cp\u003e The classical definition of noninterference security for a deterministic state machine with outputs requires to consider the outputs produced by machine actions after any trace, i.e. any indefinitely long sequence of actions, of the machine. In order to render the verification of the security of such a machine more straightforward, there is a need of some sufficient condition for security such that just individual actions, rather than unbounded sequences of actions, have to be considered. \u003c/p\u003e\u003cp\u003e By extending previous results applying to transitive noninterference policies, Rushby has proven an unwinding theorem that provides a sufficient condition of this kind in the general case of a possibly intransitive policy. This condition has to be satisfied by a generic function mapping security domains into equivalence relations over machine states. \u003c/p\u003e\u003cp\u003e An analogous problem arises for CSP noninterference security, whose definition requires to consider any possible future, i.e. any indefinitely long sequence of subsequent events and any indefinitely large set of refused events associated to that sequence, for each process trace. \u003c/p\u003e\u003cp\u003e This paper provides a sufficient condition for CSP noninterference security, which indeed requires to just consider individual accepted and refused events and applies to the general case of a possibly intransitive policy. This condition follows Rushby's one for classical noninterference security, and has to be satisfied by a generic function mapping security domains into equivalence relations over process traces; hence its name, Generic Unwinding Theorem. Variants of this theorem applying to deterministic processes and trace set processes are also proven. Finally, the sufficient condition for security expressed by the theorem is shown not to be a necessary condition as well, viz. there exists a secure process such that no domain-relation map satisfying the condition exists. \u003c/p\u003e","date":"June 11","id":336,"permalink":"/entries/noninterference_generic_unwinding/","shortname":"Noninterference_Generic_Unwinding","title":"The Generic Unwinding Theorem for CSP Noninterference Security","topicLinks":["computer-science/security","computer-science/concurrency/process-calculi"],"topics":["Computer science/Security","Computer science/Concurrency/Process calculi"]},{"abstract":" \u003cp\u003e The definition of noninterference security for Communicating Sequential Processes requires to consider any possible future, i.e. any indefinitely long sequence of subsequent events and any indefinitely large set of refused events associated to that sequence, for each process trace. In order to render the verification of the security of a process more straightforward, there is a need of some sufficient condition for security such that just individual accepted and refused events, rather than unbounded sequences and sets of events, have to be considered. \u003c/p\u003e\u003cp\u003e Of course, if such a sufficient condition were necessary as well, it would be even more valuable, since it would permit to prove not only that a process is secure by verifying that the condition holds, but also that a process is not secure by verifying that the condition fails to hold. \u003c/p\u003e\u003cp\u003e This paper provides a necessary and sufficient condition for CSP noninterference security, which indeed requires to just consider individual accepted and refused events and applies to the general case of a possibly intransitive policy. This condition follows Rushby's output consistency for deterministic state machines with outputs, and has to be satisfied by a specific function mapping security domains into equivalence relations over process traces. The definition of this function makes use of an intransitive purge function following Rushby's one; hence the name given to the condition, Ipurge Unwinding Theorem. \u003c/p\u003e\u003cp\u003e Furthermore, in accordance with Hoare's formal definition of deterministic processes, it is shown that a process is deterministic just in case it is a trace set process, i.e. it may be identified by means of a trace set alone, matching the set of its traces, in place of a failures-divergences pair. Then, variants of the Ipurge Unwinding Theorem are proven for deterministic processes and trace set processes. \u003c/p\u003e","date":"June 11","id":337,"permalink":"/entries/noninterference_ipurge_unwinding/","shortname":"Noninterference_Ipurge_Unwinding","title":"The Ipurge Unwinding Theorem for CSP Noninterference Security","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" This article formalizes the amortized analysis of dynamic tables parameterized with their minimal and maximal load factors and the expansion and contraction factors. \u003cP\u003e A full description is found in a \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs\"\u003ecompanion paper\u003c/a\u003e.","date":"June 7","id":338,"permalink":"/entries/dynamic_tables/","shortname":"Dynamic_Tables","title":"Parameterized Dynamic Tables","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We formalize new decision procedures for WS1S, M2L(Str), and Presburger Arithmetics. Formulas of these logics denote regular languages. Unlike traditional decision procedures, we do \u003cem\u003enot\u003c/em\u003e translate formulas into automata (nor into regular expressions), at least not explicitly. Instead we devise notions of derivatives (inspired by Brzozowski derivatives for regular expressions) that operate on formulas directly and compute a syntactic bisimulation using these derivatives. The treatment of Boolean connectives and quantifiers is uniform for all mentioned logics and is abstracted into a locale. This locale is then instantiated by different atomic formulas and their derivatives (which may differ even for the same logic under different encodings of interpretations as formal words). \u003cp\u003e The WS1S instance is described in the draft paper \u003ca href=\"https://people.inf.ethz.ch/trayteld/papers/csl15-ws1s_derivatives/index.html\"\u003eA Coalgebraic Decision Procedure for WS1S\u003c/a\u003e by the author.","date":"May 28","id":339,"permalink":"/entries/formula_derivatives/","shortname":"Formula_Derivatives","title":"Derivatives of Logical Formulas","topicLinks":["computer-science/automata-and-formal-languages","logic/general-logic/decidability-of-theories"],"topics":["Computer science/Automata and formal languages","Logic/General logic/Decidability of theories"]},{"abstract":" Numerous models of probabilistic systems are studied in the literature. Coalgebra has been used to classify them into system types and compare their expressiveness.  We formalize the resulting hierarchy of probabilistic system types by modeling the semantics of the different systems as codatatypes. This approach yields simple and concise proofs, as bisimilarity coincides with equality for codatatypes. \u003cp\u003e This work is described in detail in the ITP 2015 publication by the authors.","date":"May 27","id":340,"permalink":"/entries/probabilistic_system_zoo/","shortname":"Probabilistic_System_Zoo","title":"A Zoo of Probabilistic Systems","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" A VCG auction (named after their inventors Vickrey, Clarke, and Groves) is a generalization of the single-good, second price Vickrey auction to the case of a combinatorial auction (multiple goods, from which any participant can bid on each possible combination). We formalize in this entry VCG auctions, including tie-breaking and prove that the functions for the allocation and the price determination are well-defined. Furthermore we show that the allocation function allocates goods only to participants, only goods in the auction are allocated, and no good is allocated twice. We also show that the price function is non-negative. These properties also hold for the automatically extracted Scala code.","date":"April 30","id":341,"permalink":"/entries/vickrey_clarke_groves/","shortname":"Vickrey_Clarke_Groves","title":"VCG - Combinatorial Vickrey-Clarke-Groves Auctions","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":" The theory of residuated lattices, first proposed by Ward and Dilworth, is formalised in Isabelle/HOL. This includes concepts of residuated functions; their adjoints and conjugates. It also contains necessary and sufficient conditions for the existence of these operations in an arbitrary lattice. The mathematical components for residuated lattices are linked to the AFP entry for relation algebra. In particular, we prove Jonsson and Tsinakis conditions for a residuated boolean algebra to form a relation algebra.","date":"April 15","id":342,"permalink":"/entries/residuated_lattices/","shortname":"Residuated_Lattices","title":"Residuated Lattices","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" ConcurrentIMP extends the small imperative language IMP with control non-determinism and constructs for synchronous message passing.","date":"April 13","id":343,"permalink":"/entries/concurrentimp/","shortname":"ConcurrentIMP","title":"Concurrent IMP","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":" \u003cp\u003e We use ConcurrentIMP to model Schism, a state-of-the-art real-time garbage collection scheme for weak memory, and show that it is safe on x86-TSO.\u003c/p\u003e \u003cp\u003e This development accompanies the PLDI 2015 paper of the same name. \u003c/p\u003e","date":"April 13","id":344,"permalink":"/entries/concurrentgc/","shortname":"ConcurrentGC","title":"Relaxing Safely: Verified On-the-Fly Garbage Collection for x86-TSO","topicLinks":["computer-science/algorithms/concurrent"],"topics":["Computer science/Algorithms/Concurrent"]},{"abstract":" This article formalizes the ``trie'' data structure invented by Fredkin [CACM 1960]. It also provides a specialization where the entries in the trie are lists.","date":"March 30","id":345,"permalink":"/entries/trie/","shortname":"Trie","title":"Trie","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" Algorithms for solving the consensus problem are fundamental to distributed computing. Despite their brevity, their ability to operate in concurrent, asynchronous and failure-prone environments comes at the cost of complex and subtle behaviors. Accordingly, understanding how they work and proving their correctness is a non-trivial endeavor where abstraction is immensely helpful. Moreover, research on consensus has yielded a large number of algorithms, many of which appear to share common algorithmic ideas. A natural question is whether and how these similarities can be distilled and described in a precise, unified way. In this work, we combine stepwise refinement and lockstep models to provide an abstract and unified view of a sizeable family of consensus algorithms. Our models provide insights into the design choices underlying the different algorithms, and classify them based on those choices.","date":"March 18","id":346,"permalink":"/entries/consensus_refined/","shortname":"Consensus_Refined","title":"Consensus Refined","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":" \u003cp\u003eWe provide a framework for registering automatic methods to derive class instances of datatypes, as it is possible using Haskell's ``deriving Ord, Show, ...'' feature.\u003c/p\u003e \u003cp\u003eWe further implemented such automatic methods to derive comparators, linear orders, parametrizable equality functions, and hash-functions which are required in the Isabelle Collection Framework and the Container Framework. Moreover, for the tactic of Blanchette to show that a datatype is countable, we implemented a wrapper so that this tactic becomes accessible in our framework. All of the generators are based on the infrastructure that is provided by the BNF-based datatype package.\u003c/p\u003e \u003cp\u003eOur formalization was performed as part of the \u003ca href=\"http://cl-informatik.uibk.ac.at/software/ceta\"\u003eIsaFoR/CeTA\u003c/a\u003e project. With our new tactics we could remove several tedious proofs for (conditional) linear orders, and conditional equality operators within IsaFoR and the Container Framework.\u003c/p\u003e","date":"March 11","id":347,"permalink":"/entries/deriving/","shortname":"Deriving","title":"Deriving class instances for datatypes","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We formalize the Call Arity analysis, as implemented in GHC, and prove both functional correctness and, more interestingly, safety (i.e. the transformation does not increase allocation). \u003cp\u003e We use syntax and the denotational semantics from the entry \"Launchbury\", where we formalized Launchbury's natural semantics for lazy evaluation. \u003cp\u003e The functional correctness of Call Arity is proved with regard to that denotational semantics. The operational properties are shown with regard to a small-step semantics akin to Sestoft's mark 1 machine, which we prove to be equivalent to Launchbury's semantics. \u003cp\u003e We use Christian Urban's Nominal2 package to define our terms and make use of Brian Huffman's HOLCF package for the domain-theoretical aspects of the development.","date":"February 20","id":348,"permalink":"/entries/call_arity/","shortname":"Call_Arity","title":"The Safety of Call Arity","topicLinks":["computer-science/programming-languages/transformations"],"topics":["Computer science/Programming languages/Transformations"]},{"abstract":"We formalize an algorithm to compute the Echelon Form of a matrix. We have proved its existence over Bézout domains and made it executable over Euclidean domains, such as the integer ring and the univariate polynomials over a field. This allows us to compute determinants, inverses and characteristic polynomials of matrices. The work is based on the HOL-Multivariate Analysis library, and on both the Gauss-Jordan and Cayley-Hamilton AFP entries. As a by-product, some algebraic structures have been implemented (principal ideal domains, Bézout domains...). The algorithm has been refined to immutable arrays and code can be generated to functional languages as well.","date":"February 12","id":349,"permalink":"/entries/echelon_form/","shortname":"Echelon_Form","title":"Echelon Form","topicLinks":["computer-science/algorithms/mathematical","mathematics/algebra"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Algebra"]},{"abstract":"QR decomposition is an algorithm to decompose a real matrix A into the product of two other matrices Q and R, where Q is orthogonal and R is invertible and upper triangular. The algorithm is useful for the least squares problem; i.e., the computation of the best approximation of an unsolvable system of linear equations. As a side-product, the Gram-Schmidt process has also been formalized. A refinement using immutable arrays is presented as well. The development relies, among others, on the AFP entry \"Implementing field extensions of the form Q[sqrt(b)]\" by René Thiemann, which allows execution of the algorithm using symbolic computations. Verified code can be generated and executed using floats as well.","date":"February 12","id":350,"permalink":"/entries/qr_decomposition/","shortname":"QR_Decomposition","title":"QR Decomposition","topicLinks":["computer-science/algorithms/mathematical","mathematics/algebra"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Algebra"]},{"abstract":"Finite Automata, both deterministic and non-deterministic, for regular languages. The Myhill-Nerode Theorem. Closure under intersection, concatenation, etc. Regular expressions define regular languages. Closure under reversal; the powerset construction mapping NFAs to DFAs. Left and right languages; minimal DFAs. Brzozowski's minimization algorithm. Uniqueness up to isomorphism of minimal DFAs.","date":"February 5","id":351,"permalink":"/entries/finite_automata_hf/","shortname":"Finite_Automata_HF","title":"Finite Automata in Hereditarily Finite Set Theory","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" The UpDown scheme is a recursive scheme used to compute the stiffness matrix on a special form of sparse grids. Usually, when discretizing a Euclidean space of dimension d we need O(n^d) points, for n points along each dimension. Sparse grids are a hierarchical representation where the number of points is reduced to O(n * log(n)^d). One disadvantage of such sparse grids is that the algorithm now operate recursively in the dimensions and levels of the sparse grid. \u003cp\u003e The UpDown scheme allows us to compute the stiffness matrix on such a sparse grid. The stiffness matrix represents the influence of each representation function on the L^2 scalar product. For a detailed description see Dirk Pflüger's PhD thesis. This formalization was developed as an interdisciplinary project (IDP) at the Technische Universität München.","date":"January 28","id":352,"permalink":"/entries/updown_scheme/","shortname":"UpDown_Scheme","title":"Verification of the UpDown Scheme","topicLinks":["computer-science/algorithms/mathematical"],"topics":["Computer science/Algorithms/Mathematical"]},{"abstract":" We present the Unified Policy Framework (UPF), a generic framework for modelling security (access-control) policies. UPF emphasizes the view that a policy is a policy decision function that grants or denies access to resources, permissions, etc. In other words, instead of modelling the relations of permitted or prohibited requests directly, we model the concrete function that implements the policy decision point in a system.  In more detail, UPF is based on the following four principles: 1) Functional representation of policies, 2) No conflicts are possible, 3) Three-valued decision type (allow, deny, undefined), 4) Output type not containing the decision only.","date":"November 28","id":353,"permalink":"/entries/upf/","shortname":"UPF","title":"The Unified Policy Framework (UPF)","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003e The Ad hoc On-demand Distance Vector (AODV) routing protocol allows the nodes in a Mobile Ad hoc Network (MANET) or a Wireless Mesh Network (WMN) to know where to forward data packets. Such a protocol is ‘loop free’ if it never leads to routing decisions that forward packets in circles. \u003cp\u003e This development mechanises an existing pen-and-paper proof of loop freedom of AODV. The protocol is modelled in the Algebra of Wireless Networks (AWN), which is the subject of an earlier paper and AFP mechanization. The proof relies on a novel compositional approach for lifting invariants to networks of nodes. \u003c/p\u003e\u003cp\u003e We exploit the mechanization to analyse several variants of AODV and show that Isabelle/HOL can re-establish most proof obligations automatically and identify exactly the steps that are no longer valid. \u003c/p\u003e","date":"October 23","id":354,"permalink":"/entries/aodv/","shortname":"AODV","title":"Loop freedom of the (untimed) AODV routing protocol","topicLinks":["computer-science/concurrency/process-calculi"],"topics":["Computer science/Concurrency/Process calculi"]},{"abstract":" We implemented a command that can be used to easily generate elements of a restricted type \u003ctt\u003e{x :: 'a. P x}\u003c/tt\u003e, provided the definition is of the form \u003ctt\u003ef ys = (if check ys then Some(generate ys :: 'a) else None)\u003c/tt\u003e where \u003ctt\u003eys\u003c/tt\u003e is a list of variables \u003ctt\u003ey1 ... yn\u003c/tt\u003e and \u003ctt\u003echeck ys ==\u003e P(generate ys)\u003c/tt\u003e can be proved. \u003cp\u003e In principle, such a definition is also directly possible using the \u003ctt\u003elift_definition\u003c/tt\u003e command. However, then this definition will not be suitable for code-generation. To this end, we automated a more complex construction of Joachim Breitner which is amenable for code-generation, and where the test \u003ctt\u003echeck ys\u003c/tt\u003e will only be performed once.  In the automation, one auxiliary type is created, and Isabelle's lifting- and transfer-package is invoked several times.","date":"October 13","id":355,"permalink":"/entries/lifting_definition_option/","shortname":"Lifting_Definition_Option","title":"Lifting Definition Option","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"Stream Fusion is a system for removing intermediate list data structures from functional programs, in particular Haskell. This entry adapts stream fusion to Isabelle/HOL and its code generator. We define stream types for finite and possibly infinite lists and stream versions for most of the fusible list functions in the theories List and Coinductive_List, and prove them correct with respect to the conversion functions between lists and streams. The Stream Fusion transformation itself is implemented as a simproc in the preprocessor of the code generator. [Brian Huffman's \u003ca href=\"http://isa-afp.org/entries/Stream-Fusion.html\"\u003eAFP entry\u003c/a\u003e formalises stream fusion in HOLCF for the domain of lazy lists to prove the GHC compiler rewrite rules correct. In contrast, this work enables Isabelle's code generator to perform stream fusion itself. To that end, it covers both finite and coinductive lists from the HOL library and the Coinductive entry. The fusible list functions require specification and proof principles different from Huffman's.]","date":"October 10","id":356,"permalink":"/entries/stream_fusion_code/","shortname":"Stream_Fusion_Code","title":"Stream Fusion in HOL with Code Generation","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" \u003ca href=\"https://doi.org/10.1007/978-3-642-36742-7_35\"\u003eBhat et al. [TACAS 2013]\u003c/a\u003e developed an inductive compiler that computes density functions for probability spaces described by programs in a probabilistic functional language. In this work, we implement such a compiler for a modified version of this language within the theorem prover Isabelle and give a formal proof of its soundness w.r.t. the semantics of the source and target language.  Together with Isabelle's code generation for inductive predicates, this yields a fully verified, executable density compiler. The proof is done in two steps: First, an abstract compiler working with abstract functions modelled directly in the theorem prover's logic is defined and proved sound.  Then, this compiler is refined to a concrete version that returns a target-language expression. \u003cp\u003e An article with the same title and authors is published in the proceedings of ESOP 2015. A detailed presentation of this work can be found in the first author's master's thesis.","date":"October 9","id":357,"permalink":"/entries/density_compiler/","shortname":"Density_Compiler","title":"A Verified Compiler for Probability Density Functions","topicLinks":["mathematics/probability-theory","computer-science/programming-languages/compiling"],"topics":["Mathematics/Probability theory","Computer science/Programming languages/Compiling"]},{"abstract":" We present a formalization of refinement calculus for reactive systems. Refinement calculus is based on monotonic predicate transformers (monotonic functions from sets of post-states to sets of pre-states), and it is a powerful formalism for reasoning about imperative programs. We model reactive systems as monotonic property transformers that transform sets of output infinite sequences into sets of input infinite sequences. Within this semantics we can model refinement of reactive systems, (unbounded) angelic and demonic nondeterminism, sequential composition, and other semantic properties. We can model systems that may fail for some inputs, and we can model compatibility of systems. We can specify systems that have liveness properties using linear temporal logic, and we can refine system specifications into systems based on symbolic transitions systems, suitable for implementations.","date":"October 8","id":358,"permalink":"/entries/refinementreactive/","shortname":"RefinementReactive","title":"Formalization of Refinement Calculus for Reactive Systems","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"This entry provides several monads intended for the development of stand-alone certifiers via code generation from Isabelle/HOL. More specifically, there are three flavors of error monads (the sum type, for the case where all monadic functions are total; an instance of the former, the so called check monad, yielding either success without any further information or an error message; as well as a variant of the sum type that accommodates partial functions by providing an explicit bottom element) and a parser monad built on top. All of this monads are heavily used in the IsaFoR/CeTA project which thus provides many examples of their usage.","date":"October 3","id":359,"permalink":"/entries/certification_monads/","shortname":"Certification_Monads","title":"Certification Monads","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" This entry provides an XML library for Isabelle/HOL. This includes parsing and pretty printing of XML trees as well as combinators for transforming XML trees into arbitrary user-defined data. The main contribution of this entry is an interface (fit for code generation) that allows for communication between verified programs formalized in Isabelle/HOL and the outside world via XML. This library was developed as part of the IsaFoR/CeTA project to which we refer for examples of its usage.","date":"October 3","id":360,"permalink":"/entries/xml/","shortname":"XML","title":"XML","topicLinks":["computer-science/functional-programming","computer-science/data-structures"],"topics":["Computer science/Functional programming","Computer science/Data structures"]},{"abstract":"The insertion sort algorithm of Cormen et al. (Introduction to Algorithms) is expressed in Imperative HOL and proved to be correct and terminating. For this purpose we also provide a theory about imperative loop constructs with accompanying induction/invariant rules for proving partial and total correctness. Furthermore, the formalized algorithm is fit for code generation.","date":"September 25","id":361,"permalink":"/entries/imperative_insertion_sort/","shortname":"Imperative_Insertion_Sort","title":"Imperative Insertion Sort","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":"We have formalized the Sturm-Tarski theorem (also referred as the Tarski theorem), which generalizes Sturm's theorem. Sturm's theorem is usually used as a way to count distinct real roots, while the Sturm-Tarksi theorem forms the basis for Tarski's classic quantifier elimination for real closed field.","date":"September 19","id":362,"permalink":"/entries/sturm_tarski/","shortname":"Sturm_Tarski","title":"The Sturm-Tarski Theorem","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" This document contains a proof of the Cayley-Hamilton theorem based on the development of matrices in HOL/Multivariate Analysis.","date":"September 15","id":363,"permalink":"/entries/cayley_hamilton/","shortname":"Cayley_Hamilton","title":"The Cayley-Hamilton Theorem","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"This submission contains theories that lead to a formalization of the proof of the Jordan-Hölder theorem about composition series of finite groups. The theories formalize the notions of isomorphism classes of groups, simple groups, normal series, composition series, maximal normal subgroups. Furthermore, they provide proofs of the second isomorphism theorem for groups, the characterization theorem for maximal normal subgroups as well as many useful lemmas about normal subgroups and factor groups. The proof is inspired by course notes of Stuart Rankin.","date":"September 9","id":364,"permalink":"/entries/jordan_hoelder/","shortname":"Jordan_Hoelder","title":"The Jordan-Hölder Theorem","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" This entry verifies priority queues based on Braun trees. Insertion and deletion take logarithmic time and preserve the balanced nature of Braun trees. Two implementations of deletion are provided.","date":"September 4","id":365,"permalink":"/entries/priority_queue_braun/","shortname":"Priority_Queue_Braun","title":"Priority Queues Based on Braun Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"The Gauss-Jordan algorithm states that any matrix over a field can be transformed by means of elementary row operations to a matrix in reduced row echelon form. The formalization is based on the Rank Nullity Theorem entry of the AFP and on the HOL-Multivariate-Analysis session of Isabelle, where matrices are represented as functions over finite types. We have set up the code generator to make this representation executable. In order to improve the performance, a refinement to immutable arrays has been carried out. We have formalized some of the applications of the Gauss-Jordan algorithm. Thanks to this development, the following facts can be computed over matrices whose elements belong to a field: Ranks, Determinants, Inverses, Bases and dimensions and Solutions of systems of linear equations. Code can be exported to SML and Haskell.","date":"September 3","id":366,"permalink":"/entries/gauss_jordan/","shortname":"Gauss_Jordan","title":"Gauss-Jordan Algorithm and Its Applications","topicLinks":["computer-science/algorithms/mathematical"],"topics":["Computer science/Algorithms/Mathematical"]},{"abstract":"This development proves upper and lower bounds for several familiar real-valued functions. For sin, cos, exp and sqrt, it defines and verifies infinite families of upper and lower bounds, mostly based on Taylor series expansions. For arctan, ln and exp, it verifies a finite collection of upper and lower bounds, originally obtained from the functions' continued fraction expansions using the computer algebra system Maple. A common theme in these proofs is to take the difference between a function and its approximation, which should be zero at one point, and then consider the sign of the derivative. The immediate purpose of this development is to verify axioms used by MetiTarski, an automatic theorem prover for real-valued special functions. Crucial to MetiTarski's operation is the provision of upper and lower bounds for each function of interest.","date":"August 29","id":367,"permalink":"/entries/special_function_bounds/","shortname":"Special_Function_Bounds","title":"Real-Valued Special Functions: Upper and Lower Bounds","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"This formalisation of basic linear algebra is based completely on locales, building off HOL-Algebra. It includes basic definitions: linear combinations, span, linear independence; linear transformations; interpretation of function spaces as vector spaces; the direct sum of vector spaces, sum of subspaces; the replacement theorem; existence of bases in finite-dimensional; vector spaces, definition of dimension; the rank-nullity theorem. Some concepts are actually defined and proved for modules as they also apply there. Infinite-dimensional vector spaces are supported, but dimension is only supported for finite-dimensional vector spaces. The proofs are standard; the proofs of the replacement theorem and rank-nullity theorem roughly follow the presentation in Linear Algebra by Friedberg, Insel, and Spence. The rank-nullity theorem generalises the existing development in the Archive of Formal Proof (originally using type classes, now using a mix of type classes and locales).","date":"August 29","id":368,"permalink":"/entries/vectorspace/","shortname":"VectorSpace","title":"Vector Spaces","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" Skew heaps are an amazingly simple and lightweight implementation of priority queues. They were invented by Sleator and Tarjan [SIAM 1986] and have logarithmic amortized complexity. This entry provides executable and verified functional skew heaps. \u003cp\u003e The amortized complexity of skew heaps is analyzed in the AFP entry \u003ca href=\"http://isa-afp.org/entries/Amortized_Complexity.html\"\u003eAmortized Complexity\u003c/a\u003e.","date":"August 13","id":369,"permalink":"/entries/skew_heap/","shortname":"Skew_Heap","title":"Skew Heap","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" Splay trees are self-adjusting binary search trees which were invented by Sleator and Tarjan [JACM 1985]. This entry provides executable and verified functional splay trees as well as the related splay heaps (due to Okasaki). \u003cp\u003e The amortized complexity of splay trees and heaps is analyzed in the AFP entry \u003ca href=\"http://isa-afp.org/entries/Amortized_Complexity.html\"\u003eAmortized Complexity\u003c/a\u003e.","date":"August 12","id":370,"permalink":"/entries/splay_tree/","shortname":"Splay_Tree","title":"Splay Tree","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We implemented a type class for \"to-string\" functions, similar to Haskell's Show class. Moreover, we provide instantiations for Isabelle/HOL's standard types like bool, prod, sum, nats, ints, and rats. It is further possible, to automatically derive show functions for arbitrary user defined datatypes similar to Haskell's \"deriving Show\".","date":"July 29","id":371,"permalink":"/entries/show/","shortname":"Show","title":"Haskell's Show Class in Isabelle/HOL","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":" \u003cp\u003eIntransitive noninterference has been a widely studied topic in the last few decades. Several well-established methodologies apply interactive theorem proving to formulate a noninterference theorem over abstract academic models. In joint work with several industrial and academic partners throughout Europe, we are helping in the certification process of PikeOS, an industrial separation kernel developed at SYSGO. In this process, established theories could not be applied. We present a new generic model of separation kernels and a new theory of intransitive noninterference. The model is rich in detail, making it suitable for formal verification of realistic and industrial systems such as PikeOS. Using a refinement-based theorem proving approach, we ensure that proofs remain manageable.\u003c/p\u003e \u003cp\u003e This document corresponds to the deliverable D31.1 of the EURO-MILS Project \u003ca href=\"http://www.euromils.eu\"\u003ehttp://www.euromils.eu\u003c/a\u003e.\u003c/p\u003e","date":"July 18","id":372,"permalink":"/entries/cisc-kernel/","shortname":"CISC-Kernel","title":"Formal Specification of a Generic Separation Kernel","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003epGCL is both a programming language and a specification language that incorporates both probabilistic and nondeterministic choice, in a unified manner. Program verification is by refinement or annotation (or both), using either Hoare triples, or weakest-precondition entailment, in the style of GCL.\u003c/p\u003e \u003cp\u003e This package provides both a shallow embedding of the language primitives, and an annotation and refinement framework. The generated document includes a brief tutorial.\u003c/p\u003e","date":"July 13","id":373,"permalink":"/entries/pgcl/","shortname":"pGCL","title":"pGCL for Isabelle","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":" A framework for the analysis of the amortized complexity of functional data structures is formalized in Isabelle/HOL and applied to a number of standard examples and to the folowing non-trivial ones: skew heaps, splay trees, splay heaps and pairing heaps. \u003cp\u003e A preliminary version of this work (without pairing heaps) is described in a \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/itp15.html\"\u003epaper\u003c/a\u003e published in the proceedings of the conference on Interactive Theorem Proving ITP 2015. An extended version of this publication is available \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/jfp16.html\"\u003ehere\u003c/a\u003e.","date":"July 7","id":374,"permalink":"/entries/amortized_complexity/","shortname":"Amortized_Complexity","title":"Amortized Complexity Verified","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We present a unified theory for verifying network security policies. A security policy is represented as directed graph. To check high-level security goals, security invariants over the policy are expressed. We cover monotonic security invariants, i.e. prohibiting more does not harm security. We provide the following contributions for the security invariant theory. \u003cul\u003e \u003cli\u003eSecure auto-completion of scenario-specific knowledge, which eases usability.\u003c/li\u003e \u003cli\u003eSecurity violations can be repaired by tightening the policy iff the security invariants hold for the deny-all policy.\u003c/li\u003e \u003cli\u003eAn algorithm to compute a security policy.\u003c/li\u003e \u003cli\u003eA formalization of stateful connection semantics in network security mechanisms.\u003c/li\u003e \u003cli\u003eAn algorithm to compute a secure stateful implementation of a policy.\u003c/li\u003e \u003cli\u003eAn executable implementation of all the theory.\u003c/li\u003e \u003cli\u003eExamples, ranging from an aircraft cabin data network to the analysis of a large real-world firewall.\u003c/li\u003e \u003cli\u003eMore examples: A fully automated translation of high-level security goals to both firewall and SDN configurations (see Examples/Distributed_WebApp.thy).\u003c/li\u003e \u003c/ul\u003e For a detailed description, see \u003cul\u003e \u003cli\u003eC. Diekmann, A. Korsten, and G. Carle. \u003ca href=\"http://www.net.in.tum.de/fileadmin/bibtex/publications/papers/diekmann2015mansdnnfv.pdf\"\u003eDemonstrating topoS: Theorem-prover-based synthesis of secure network configurations.\u003c/a\u003e In 2nd International Workshop on Management of SDN and NFV Systems, manSDN/NFV, Barcelona, Spain, November 2015.\u003c/li\u003e \u003cli\u003eC. Diekmann, S.-A. Posselt, H. Niedermayer, H. Kinkelin, O. Hanka, and G. Carle. \u003ca href=\"http://www.net.in.tum.de/pub/diekmann/forte14.pdf\"\u003eVerifying Security Policies using Host Attributes.\u003c/a\u003e In FORTE, 34th IFIP International Conference on Formal Techniques for Distributed Objects, Components and Systems, Berlin, Germany, June 2014.\u003c/li\u003e \u003cli\u003eC. Diekmann, L. Hupel, and G. Carle. Directed Security Policies: \u003ca href=\"http://rvg.web.cse.unsw.edu.au/eptcs/paper.cgi?ESSS2014.3\"\u003eA Stateful Network Implementation.\u003c/a\u003e In J. Pang and Y. Liu, editors, Engineering Safety and Security Systems, volume 150 of Electronic Proceedings in Theoretical Computer Science, pages 20-34, Singapore, May 2014. Open Publishing Association.\u003c/li\u003e \u003c/ul\u003e","date":"July 4","id":375,"permalink":"/entries/network_security_policy_verification/","shortname":"Network_Security_Policy_Verification","title":"Network Security Policy Verification","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"Pop-refinement is an approach to stepwise refinement, carried out inside an interactive theorem prover by constructing a monotonically decreasing sequence of predicates over deeply embedded target programs. The sequence starts with a predicate that characterizes the possible implementations, and ends with a predicate that characterizes a unique program in explicit syntactic form. Pop-refinement enables more requirements (e.g. program-level and non-functional) to be captured in the initial specification and preserved through refinement. Security requirements expressed as hyperproperties (i.e. predicates over sets of traces) are always preserved by pop-refinement, unlike the popular notion of refinement as trace set inclusion. Two simple examples in Isabelle/HOL are presented, featuring program-level requirements, non-functional requirements, and hyperproperties.","date":"July 3","id":376,"permalink":"/entries/pop_refinement/","shortname":"Pop_Refinement","title":"Pop-Refinement","topicLinks":["computer-science/programming-languages/misc"],"topics":["Computer science/Programming languages/Misc"]},{"abstract":" Monadic second-order logic on finite words (MSO) is a decidable yet expressive logic into which many decision problems can be encoded. Since MSO formulas correspond to regular languages, equivalence of MSO formulas can be reduced to the equivalence of some regular structures (e.g. automata). We verify an executable decision procedure for MSO formulas that is not based on automata but on regular expressions. \u003cp\u003e Decision procedures for regular expression equivalence have been formalized before, usually based on Brzozowski derivatives. Yet, for a straightforward embedding of MSO formulas into regular expressions an extension of regular expressions with a projection operation is required. We prove total correctness and completeness of an equivalence checker for regular expressions extended in that way. We also define a language-preserving translation of formulas into regular expressions with respect to two different semantics of MSO. \u003cp\u003e The formalization is described in this \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/icfp13.html\"\u003eICFP 2013 functional pearl\u003c/a\u003e.","date":"June 12","id":377,"permalink":"/entries/mso_regex_equivalence/","shortname":"MSO_Regex_Equivalence","title":"Decision Procedures for MSO on Words Based on Derivatives of Regular Expressions","topicLinks":["computer-science/automata-and-formal-languages","logic/general-logic/decidability-of-theories"],"topics":["Computer science/Automata and formal languages","Logic/General logic/Decidability of theories"]},{"abstract":" This entry provides executable checkers for the following properties of boolean expressions: satisfiability, tautology and equivalence. Internally, the checkers operate on binary decision trees and are reasonably efficient (for purely functional algorithms).","date":"June 8","id":378,"permalink":"/entries/boolean_expression_checkers/","shortname":"Boolean_Expression_Checkers","title":"Boolean Expression Checkers","topicLinks":["computer-science/algorithms","logic/general-logic/mechanization-of-proofs"],"topics":["Computer science/Algorithms","Logic/General logic/Mechanization of proofs"]},{"abstract":" We present an LTL model checker whose code has been completely verified using the Isabelle theorem prover. The checker consists of over 4000 lines of ML code. The code is produced using the Isabelle Refinement Framework, which allows us to split its correctness proof into (1) the proof of an abstract version of the checker, consisting of a few hundred lines of ``formalized pseudocode'', and (2) a verified refinement step in which mathematical sets and other abstract structures are replaced by implementations of efficient structures like red-black trees and functional arrays. This leads to a checker that, while still slower than unverified checkers, can already be used as a trusted reference implementation against which advanced implementations can be tested. \u003cp\u003e An early version of this model checker is described in the \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/cav13.html\"\u003eCAV 2013 paper\u003c/a\u003e with the same title.","date":"May 28","id":379,"permalink":"/entries/cava_ltl_modelchecker/","shortname":"CAVA_LTL_Modelchecker","title":"A Fully Verified Executable LTL Model Checker","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" We formalize linear-time temporal logic (LTL) and the algorithm by Gerth et al. to convert LTL formulas to generalized Büchi automata. We also formalize some syntactic rewrite rules that can be applied to optimize the LTL formula before conversion. Moreover, we integrate the Stuttering Equivalence AFP-Entry by Stefan Merz, adapting the lemma that next-free LTL formula cannot distinguish between stuttering equivalent runs to our setting. \u003cp\u003e We use the Isabelle Refinement and Collection framework, as well as the Autoref tool, to obtain a refined version of our algorithm, from which efficiently executable code can be extracted.","date":"May 28","id":380,"permalink":"/entries/ltl_to_gba/","shortname":"LTL_to_GBA","title":"Converting Linear-Time Temporal Logic to Generalized Büchi Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" We present an executable formalization of the language Promela, the description language for models of the model checker SPIN. This formalization is part of the work for a completely verified model checker (CAVA), but also serves as a useful (and executable!) description of the semantics of the language itself, something that is currently missing. The formalization uses three steps: It takes an abstract syntax tree generated from an SML parser, removes syntactic sugar and enriches it with type information. This further gets translated into a transition system, on which the semantic engine (read: successor function) operates.","date":"May 28","id":381,"permalink":"/entries/promela/","shortname":"Promela","title":"Promela Formalization","topicLinks":["computer-science/system-description-languages"],"topics":["Computer science/System description languages"]},{"abstract":" We report on the graph and automata library that is used in the fully verified LTL model checker CAVA. As most components of CAVA use some type of graphs or automata, a common automata library simplifies assembly of the components and reduces redundancy. \u003cp\u003e The CAVA Automata Library provides a hierarchy of graph and automata classes, together with some standard algorithms. Its object oriented design allows for sharing of algorithms, theorems, and implementations between its classes, and also simplifies extensions of the library. Moreover, it is integrated into the Automatic Refinement Framework, supporting automatic refinement of the abstract automata types to efficient data structures. \u003cp\u003e Note that the CAVA Automata Library is work in progress. Currently, it is very specifically tailored towards the requirements of the CAVA model checker. Nevertheless, the formalization techniques presented here allow an extension of the library to a wider scope. Moreover, they are not limited to graph libraries, but apply to class hierarchies in general. \u003cp\u003e The CAVA Automata Library is described in the paper: Peter Lammich, The CAVA Automata Library, Isabelle Workshop 2014.","date":"May 28","id":382,"permalink":"/entries/cava_automata/","shortname":"CAVA_Automata","title":"The CAVA Automata Library","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" We present an Isabelle/HOL formalization of Gabow's algorithm for finding the strongly connected components of a directed graph. Using data refinement techniques, we extract efficient code that performs comparable to a reference implementation in Java. Our style of formalization allows for re-using large parts of the proofs when defining variants of the algorithm. We demonstrate this by verifying an algorithm for the emptiness check of generalized Büchi automata, re-using most of the existing proofs.","date":"May 28","id":383,"permalink":"/entries/gabow_scc/","shortname":"Gabow_SCC","title":"Verified Efficient Implementation of Gabow's Strongly Connected Components Algorithm","topicLinks":["computer-science/algorithms/graph","mathematics/graph-theory"],"topics":["Computer science/Algorithms/Graph","Mathematics/Graph theory"]},{"abstract":" \u003cp\u003e An extension of classical noninterference security for deterministic state machines, as introduced by Goguen and Meseguer and elegantly formalized by Rushby, to nondeterministic systems should satisfy two fundamental requirements: it should be based on a mathematically precise theory of nondeterminism, and should be equivalent to (or at least not weaker than) the classical notion in the degenerate deterministic case. \u003c/p\u003e \u003cp\u003e This paper proposes a definition of noninterference security applying to Hoare's Communicating Sequential Processes (CSP) in the general case of a possibly intransitive noninterference policy, and proves the equivalence of this security property to classical noninterference security for processes representing deterministic state machines. \u003c/p\u003e \u003cp\u003e Furthermore, McCullough's generalized noninterference security is shown to be weaker than both the proposed notion of CSP noninterference security for a generic process, and classical noninterference security for processes representing deterministic state machines. This renders CSP noninterference security preferable as an extension of classical noninterference security to nondeterministic systems. \u003c/p\u003e","date":"May 23","id":384,"permalink":"/entries/noninterference_csp/","shortname":"Noninterference_CSP","title":"Noninterference Security in Communicating Sequential Processes","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"This formulation of the Roy-Floyd-Warshall algorithm for the transitive closure bypasses matrices and arrays, but uses a more direct mathematical model with adjacency functions for immediate predecessors and successors. This can be implemented efficiently in functional programming languages and is particularly adequate for sparse relations.","date":"May 23","id":385,"permalink":"/entries/roy_floyd_warshall/","shortname":"Roy_Floyd_Warshall","title":"Transitive closure according to Roy-Floyd-Warshall","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":" Regular algebras axiomatise the equational theory of regular expressions as induced by regular language identity. We use Isabelle/HOL for a detailed systematic study of regular algebras given by Boffa, Conway, Kozen and Salomaa. We investigate the relationships between these classes, formalise a soundness proof for the smallest class (Salomaa's) and obtain completeness of the largest one (Boffa's) relative to a deep result by Krob. In addition we provide a large collection of regular identities in the general setting of Boffa's axiom. Our regular algebra hierarchy is orthogonal to the Kleene algebra hierarchy in the Archive of Formal Proofs; we have not aimed at an integration for pragmatic reasons.","date":"May 21","id":386,"permalink":"/entries/regular_algebras/","shortname":"Regular_Algebras","title":"Regular Algebras","topicLinks":["computer-science/automata-and-formal-languages","mathematics/algebra"],"topics":["Computer science/Automata and formal languages","Mathematics/Algebra"]},{"abstract":"This set of theories presents a formalisation in Isabelle/HOL of data dependencies between components. The approach allows to analyse system structure oriented towards efficient checking of system: it aims at elaborating for a concrete system, which parts of the system are necessary to check a given property.","date":"April 28","id":387,"permalink":"/entries/componentdependencies/","shortname":"ComponentDependencies","title":"Formalisation and Analysis of Component Dependencies","topicLinks":["computer-science/system-description-languages"],"topics":["Computer science/System description languages"]},{"abstract":"Research in information-flow security aims at developing methods to identify undesired information leaks within programs from private (high) sources to public (low) sinks. For a concurrent system, it is desirable to have compositional analysis methods that allow for analyzing each thread independently and that nevertheless guarantee that the parallel composition of successfully analyzed threads satisfies a global security guarantee. However, such a compositional analysis should not be overly pessimistic about what an environment might do with shared resources. Otherwise, the analysis will reject many intuitively secure programs. \u003cp\u003e The paper \"Assumptions and Guarantees for Compositional Noninterference\" by Mantel et. al. presents one solution for this problem: an approach for compositionally reasoning about non-interference in concurrent programs via rely-guarantee-style reasoning.  We present an Isabelle/HOL formalization of the concepts and proofs of this approach.","date":"April 23","id":388,"permalink":"/entries/sifum_type_systems/","shortname":"SIFUM_Type_Systems","title":"A Formalization of Assumptions and Guarantees for Compositional Noninterference","topicLinks":["computer-science/security","computer-science/programming-languages/type-systems"],"topics":["Computer science/Security","Computer science/Programming languages/Type systems"]},{"abstract":"Research in information-flow security aims at developing methods to identify undesired information leaks within programs from private sources to public sinks. Noninterference captures this intuition by requiring that no information whatsoever flows from private sources to public sinks. However, in practice this definition is often too strict: Depending on the intuitive desired security policy, the controlled declassification of certain private information (WHAT) at certain points in the program (WHERE) might not result in an undesired information leak. \u003cp\u003e We present an Isabelle/HOL formalization of such a security property for controlled declassification, namely WHAT\u0026WHERE-security from \"Scheduler-Independent Declassification\" by Lux, Mantel, and Perner. The formalization includes compositionality proofs for and a soundness proof for a security type system that checks for programs in a simple while language with dynamic thread creation. \u003cp\u003e Our formalization of the security type system is abstract in the language for expressions and in the semantic side conditions for expressions. It can easily be instantiated with different syntactic approximations for these side conditions. The soundness proof of such an instantiation boils down to showing that these syntactic approximations imply the semantic side conditions. \u003cp\u003e This Isabelle/HOL formalization uses theories from the entry Strong Security.","date":"April 23","id":389,"permalink":"/entries/whatandwhere_security/","shortname":"WHATandWHERE_Security","title":"A Formalization of Declassification with WHAT-and-WHERE-Security","topicLinks":["computer-science/security","computer-science/programming-languages/type-systems"],"topics":["Computer science/Security","Computer science/Programming languages/Type systems"]},{"abstract":"Research in information-flow security aims at developing methods to identify undesired information leaks within programs from private sources to public sinks. Noninterference captures this intuition. Strong security from Sabelfeld and Sands formalizes noninterference for concurrent systems. \u003cp\u003e We present an Isabelle/HOL formalization of strong security for arbitrary security lattices (Sabelfeld and Sands use a two-element security lattice in the original publication). The formalization includes compositionality proofs for strong security and a soundness proof for a security type system that checks strong security for programs in a simple while language with dynamic thread creation. \u003cp\u003e Our formalization of the security type system is abstract in the language for expressions and in the semantic side conditions for expressions. It can easily be instantiated with different syntactic approximations for these side conditions. The soundness proof of such an instantiation boils down to showing that these syntactic approximations imply the semantic side conditions.","date":"April 23","id":390,"permalink":"/entries/strong_security/","shortname":"Strong_Security","title":"A Formalization of Strong Security","topicLinks":["computer-science/security","computer-science/programming-languages/type-systems"],"topics":["Computer science/Security","Computer science/Programming languages/Type systems"]},{"abstract":"This is a formalization of bounded-deducibility security (BD security), a flexible notion of information-flow security applicable to arbitrary input-output automata. It generalizes Sutherland's classic notion of nondeducibility by factoring in declassification bounds and trigger, whereas nondeducibility states that, in a system, information cannot flow between specified sources and sinks, BD security indicates upper bounds for the flow and triggers under which these upper bounds are no longer guaranteed.","date":"April 22","id":391,"permalink":"/entries/bounded_deducibility_security/","shortname":"Bounded_Deducibility_Security","title":"Bounded-Deducibility Security","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"We formalize HyperCTL*, a temporal logic for expressing security properties. We first define a shallow embedding of HyperCTL*, within which we prove inductive and coinductive rules for the operators. Then we show that a HyperCTL* formula captures Goguen-Meseguer noninterference, a landmark information flow property. We also define a deep embedding and connect it to the shallow embedding by a denotational semantics, for which we prove sanity w.r.t. dependence on the free variables. Finally, we show that under some finiteness assumptions about the model, noninterference is given by a (finitary) syntactic formula.","date":"April 16","id":392,"permalink":"/entries/hyperctl/","shortname":"HyperCTL","title":"A shallow embedding of HyperCTL*","topicLinks":["computer-science/security","logic/general-logic/temporal-logic"],"topics":["Computer science/Security","Logic/General logic/Temporal logic"]},{"abstract":"A formalization of an abstract property of possibly infinite derivation trees (modeled by a codatatype),  representing the core of a proof (in Beth/Hintikka style) of the first-order logic completeness theorem, independent of the concrete syntax or inference rules. This work is described in detail in the IJCAR 2014 publication by the authors. The abstract proof can be instantiated for a wide range of Gentzen and tableau systems as well as various flavors of FOL---e.g., with or without predicates, equality, or sorts. Here, we give only a toy example instantiation with classical propositional logic. A more serious instance---many-sorted FOL with equality---is described elsewhere [Blanchette and Popescu, FroCoS 2013].","date":"April 16","id":393,"permalink":"/entries/abstract_completeness/","shortname":"Abstract_Completeness","title":"Abstract Completeness","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":"These theories introduce basic concepts and proofs about discrete summation: shifts, formal summation, falling factorials and stirling numbers. As proof of concept, a simple summation conversion is provided.","date":"April 13","id":394,"permalink":"/entries/discrete_summation/","shortname":"Discrete_Summation","title":"Discrete Summation","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" This document accompanies the article \"The Design and Implementation of a Verification Technique for GPU Kernels\" by Adam Betts, Nathan Chong, Alastair F. Donaldson, Jeroen Ketema, Shaz Qadeer, Paul Thomson and John Wickerson. It formalises all of the definitions provided in Sections 3 and 4 of the article.","date":"April 3","id":395,"permalink":"/entries/gpu_kernel_pl/","shortname":"GPU_Kernel_PL","title":"Syntax and semantics of a GPU kernel programming language","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"We formalize a probabilistic noninterference for a multi-threaded language with uniform scheduling, where probabilistic behaviour comes from both the scheduler and the individual threads. We define notions probabilistic noninterference in two variants: resumption-based and trace-based. For the resumption-based notions, we prove compositionality w.r.t. the language constructs and establish sound type-system-like syntactic criteria. This is a formalization of the mathematical development presented at CPP 2013 and CALCO 2013. It is the probabilistic variant of the Possibilistic Noninterference AFP entry.","date":"March 11","id":396,"permalink":"/entries/probabilistic_noninterference/","shortname":"Probabilistic_Noninterference","title":"Probabilistic Noninterference","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003e AWN is a process algebra developed for modelling and analysing protocols for Mobile Ad hoc Networks (MANETs) and Wireless Mesh Networks (WMNs). AWN models comprise five distinct layers: sequential processes, local parallel compositions, nodes, partial networks, and complete networks.\u003c/p\u003e \u003cp\u003e This development mechanises the original operational semantics of AWN and introduces a variant 'open' operational semantics that enables the compositional statement and proof of invariants across distinct network nodes. It supports labels (for weakening invariants) and (abstract) data state manipulations. A framework for compositional invariant proofs is developed, including a tactic (inv_cterms) for inductive invariant proofs of sequential processes, lifting rules for the open versions of the higher layers, and a rule for transferring lifted properties back to the standard semantics. A notion of 'control terms' reduces proof obligations to the subset of subterms that act directly (in contrast to operators for combining terms and joining processes).\u003c/p\u003e","date":"March 8","id":397,"permalink":"/entries/awn/","shortname":"AWN","title":"Mechanization of the Algebra for Wireless Networks (AWN)","topicLinks":["computer-science/concurrency/process-calculi"],"topics":["Computer science/Concurrency/Process calculi"]},{"abstract":"We provide a wrapper around the partial-function command that supports mutual recursion.","date":"February 18","id":398,"permalink":"/entries/partial_function_mr/","shortname":"Partial_Function_MR","title":"Mutually Recursive Partial Functions","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"Random graphs are graphs with a fixed number of vertices, where each edge is present with a fixed probability. We are interested in the probability that a random graph contains a certain pattern, for example a cycle or a clique. A very high edge probability gives rise to perhaps too many edges (which degrades performance for many algorithms), whereas a low edge probability might result in a disconnected graph. We prove a theorem about a threshold probability such that a higher edge probability will asymptotically almost surely produce a random graph with the desired subgraph.","date":"February 13","id":399,"permalink":"/entries/random_graph_subgraph_threshold/","shortname":"Random_Graph_Subgraph_Threshold","title":"Properties of Random Graphs -- Subgraph Containment","topicLinks":["mathematics/graph-theory","mathematics/probability-theory"],"topics":["Mathematics/Graph theory","Mathematics/Probability theory"]},{"abstract":" Stepwise program refinement techniques can be used to simplify program verification. Programs are better understood since their main properties are clearly stated, and verification of rather complex algorithms is reduced to proving simple statements connecting successive program specifications. Additionally, it is easy to analyze similar algorithms and to compare their properties within a single formalization. Usually, formal analysis is not done in educational setting due to complexity of verification and a lack of tools and procedures to make comparison easy. Verification of an algorithm should not only give correctness proof, but also better understanding of an algorithm. If the verification is based on small step program refinement, it can become simple enough to be demonstrated within the university-level computer science curriculum. In this paper we demonstrate this and give a formal analysis of two well known algorithms (Selection Sort and Heap Sort) using proof assistant Isabelle/HOL and program refinement techniques.","date":"February 11","id":400,"permalink":"/entries/selection_heap_sort/","shortname":"Selection_Heap_Sort","title":"Verification of Selection and Heap Sort Using Locales","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":" We give a formalization of affine forms as abstract representations of zonotopes. We provide affine operations as well as overapproximations of some non-affine operations like multiplication and division. Expressions involving those operations can automatically be turned into (executable) functions approximating the original expression in affine arithmetic.","date":"February 7","id":401,"permalink":"/entries/affine_arithmetic/","shortname":"Affine_Arithmetic","title":"Affine Arithmetic","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We apply data refinement to implement the real numbers, where we support all numbers in the field extension Q[sqrt(b)], i.e., all numbers of the form p + q * sqrt(b) for rational numbers p and q and some fixed natural number b. To this end, we also developed algorithms to precisely compute roots of a rational number, and to perform a factorization of natural numbers which eliminates duplicate prime factors. \u003cp\u003e Our results have been used to certify termination proofs which involve polynomial interpretations over the reals.","date":"February 6","id":402,"permalink":"/entries/real_impl/","shortname":"Real_Impl","title":"Implementing field extensions of the form Q[sqrt(b)]","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We formalize a unified framework for verified decision procedures for regular expression equivalence. Five recently published formalizations of such decision procedures (three based on derivatives, two on marked regular expressions) can be obtained as instances of the framework. We discover that the two approaches based on marked regular expressions, which were previously thought to be the same, are different, and one seems to produce uniformly smaller automata.  The common framework makes it possible to compare the performance of the different decision procedures in a meaningful way. \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/itp14.html\"\u003e The formalization is described in a paper of the same name presented at Interactive Theorem Proving 2014\u003c/a\u003e.","date":"January 30","id":403,"permalink":"/entries/regex_equivalence/","shortname":"Regex_Equivalence","title":"Unified Decision Procedures for Regular Expression Equivalence","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"These theories extend the existing proof of the first Sylow theorem (written by Florian Kammueller and L. C. Paulson) by what are often called the second, third and fourth Sylow theorems. These theorems state propositions about the number of Sylow p-subgroups of a group and the fact that they are conjugate to each other. The proofs make use of an implementation of group actions and their properties.","date":"January 28","id":404,"permalink":"/entries/secondary_sylow/","shortname":"Secondary_Sylow","title":"Secondary Sylow Theorems","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"Tarski's algebra of binary relations is formalised along the lines of the standard textbooks of Maddux and Schmidt and Ströhlein. This includes relation-algebraic concepts such as subidentities, vectors and a domain operation as well as various notions associated to functions. Relation algebras are also expanded by a reflexive transitive closure operation, and they are linked with Kleene algebras and models of binary relations and Boolean matrices.","date":"January 25","id":405,"permalink":"/entries/relation_algebra/","shortname":"Relation_Algebra","title":"Relation Algebra","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" We formalise Kleene algebra with tests (KAT) and demonic refinement algebra (DRA) in Isabelle/HOL. KAT is relevant for program verification and correctness proofs in the partial correctness setting. While DRA targets similar applications in the context of total correctness. Our formalisation contains the two most important models of these algebras: binary relations in the case of KAT and predicate transformers in the case of DRA. In addition, we derive the inference rules for Hoare logic in KAT and its relational model and present a simple formally verified program verification tool prototype based on the algebraic approach.","date":"January 23","id":406,"permalink":"/entries/kat_and_dra/","shortname":"KAT_and_DRA","title":"Kleene Algebra with Tests and Demonic Refinement Algebras","topicLinks":["computer-science/programming-languages/logics","computer-science/automata-and-formal-languages","mathematics/algebra"],"topics":["Computer science/Programming languages/Logics","Computer science/Automata and formal languages","Mathematics/Algebra"]},{"abstract":"The Unified Modeling Language (UML) is one of the few modeling languages that is widely used in industry. While UML is mostly known as diagrammatic modeling language (e.g., visualizing class models), it is complemented by a textual language, called Object Constraint Language (OCL). The current version of OCL is based on a four-valued logic that turns UML into a formal language. Any type comprises the elements \"invalid\" and \"null\" which are propagated as strict and non-strict, respectively. Unfortunately, the former semi-formal semantics of this specification language, captured in the \"Annex A\" of the OCL standard, leads to different interpretations of corner cases. We formalize the core of OCL: denotational definitions, a logical calculus and operational rules that allow for the execution of OCL expressions by a mixture of term rewriting and code compilation. Our formalization reveals several inconsistencies and contradictions in the current version of the OCL standard. Overall, this document is intended to provide the basis for a machine-checked text \"Annex A\" of the OCL standard targeting at tool implementors.","date":"January 16","id":407,"permalink":"/entries/featherweight_ocl/","shortname":"Featherweight_OCL","title":"Featherweight OCL: A Proposal for a Machine-Checked Formal Semantics for OCL 2.5","topicLinks":["computer-science/system-description-languages"],"topics":["Computer science/System description languages"]},{"abstract":"This paper presents an Isabelle/HOL set of theories which allows the specification of crypto-based components and the verification of their composition properties wrt. cryptographic aspects. We introduce a formalisation of the security property of data secrecy, the corresponding definitions and proofs. Please note that here we import the Isabelle/HOL theory ListExtras.thy, presented in the AFP entry FocusStreamsCaseStudies-AFP.","date":"January 11","id":408,"permalink":"/entries/cryptobasedcompositionalproperties/","shortname":"CryptoBasedCompositionalProperties","title":"Compositional Properties of Crypto-Based Components","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"Sturm's Theorem states that polynomial sequences with certain properties, so-called Sturm sequences, can be used to count the number of real roots of a real polynomial. This work contains a proof of Sturm's Theorem and code for constructing Sturm sequences efficiently. It also provides the “sturm” proof method, which can decide certain statements about the roots of real polynomials, such as “the polynomial P has exactly n roots in the interval I” or “P(x) \u003e Q(x) for all x \u0026#8712; \u0026#8477;”.","date":"January 11","id":409,"permalink":"/entries/sturm_sequences/","shortname":"Sturm_Sequences","title":"Sturm's Theorem","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" \u003cp\u003e Tail-recursive function definitions are sometimes more straightforward than alternatives, but proving theorems on them may be roundabout because of the peculiar form of the resulting recursion induction rules. \u003c/p\u003e\u003cp\u003e This paper describes a proof method that provides a general solution to this problem by means of suitable invariants over inductive sets, and illustrates the application of such method by examining two case studies. \u003c/p\u003e","date":"December 1","id":410,"permalink":"/entries/tail_recursive_functions/","shortname":"Tail_Recursive_Functions","title":"A General Method for the Proof of Theorems on Tail-recursive Functions","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"Gödel's two incompleteness theorems are formalised, following a careful  \u003ca href=\"http://journals.impan.gov.pl/dm/Inf/422-0-1.html\"\u003epresentation\u003c/a\u003e by Swierczkowski, in the theory of \u003ca href=\"HereditarilyFinite.html\"\u003ehereditarily finite sets\u003c/a\u003e. This represents the first ever machine-assisted proof of the second incompleteness theorem. Compared with traditional formalisations using Peano arithmetic (see e.g. Boolos), coding is simpler, with no need to formalise the notion of multiplication (let alone that of a prime number) in the formalised calculus upon which the theorem is based. However, other technical problems had to be solved in order to complete the argument.","date":"November 17","id":411,"permalink":"/entries/incompleteness/","shortname":"Incompleteness","title":"Gödel's Incompleteness Theorems","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":"The theory of hereditarily finite sets is formalised, following the \u003ca href=\"http://journals.impan.gov.pl/dm/Inf/422-0-1.html\"\u003edevelopment\u003c/a\u003e of Swierczkowski. An HF set is a finite collection of other HF sets; they enjoy an induction principle and satisfy all the axioms of ZF set theory apart from the axiom of infinity, which is negated. All constructions that are possible in ZF set theory (Cartesian products, disjoint sums, natural numbers, functions) without using infinite sets are possible here. The definition of addition for the HF sets follows Kirby. This development forms the foundation for the Isabelle proof of Gödel's incompleteness theorems, which has been \u003ca href=\"Incompleteness.html\"\u003eformalised separately\u003c/a\u003e.","date":"November 17","id":412,"permalink":"/entries/hereditarilyfinite/","shortname":"HereditarilyFinite","title":"The Hereditarily Finite Sets","topicLinks":["logic/set-theory"],"topics":["Logic/Set theory"]},{"abstract":"\u003cp\u003eWe define formal languages as a codataype of infinite trees branching over the alphabet. Each node in such a tree indicates whether the path to this node constitutes a word inside or outside of the language. This codatatype is isormorphic to the set of lists representation of languages, but caters for definitions by corecursion and proofs by coinduction.\u003c/p\u003e \u003cp\u003eRegular operations on languages are then defined by primitive corecursion. A difficulty arises here, since the standard definitions of concatenation and iteration from the coalgebraic literature are not primitively corecursive-they require guardedness up-to union/concatenation. Without support for up-to corecursion, these operation must be defined as a composition of primitive ones (and proved being equal to the standard definitions). As an exercise in coinduction we also prove the axioms of Kleene algebra for the defined regular operations.\u003c/p\u003e \u003cp\u003eFurthermore, a language for context-free grammars given by productions in Greibach normal form and an initial nonterminal is constructed by primitive corecursion, yielding an executable decision procedure for the word problem without further ado.\u003c/p\u003e","date":"November 15","id":413,"permalink":"/entries/coinductive_languages/","shortname":"Coinductive_Languages","title":"A Codatatype of Formal Languages","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"This set of theories presents an Isabelle/HOL formalisation of stream processing components introduced in Focus, a framework for formal specification and development of interactive systems. This is an extended and updated version of the formalisation, which was elaborated within the methodology \"Focus on Isabelle\". In addition, we also applied the formalisation on three case studies that cover different application areas: process control (Steam Boiler System), data transmission (FlexRay communication protocol), memory and processing components (Automotive-Gateway System).","date":"November 14","id":414,"permalink":"/entries/focusstreamscasestudies/","shortname":"FocusStreamsCaseStudies","title":"Stream Processing Components: Isabelle/HOL Formalisation and Case Studies","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"Dana Scott's version of Gödel's proof of God's existence is formalized in quantified modal logic KB (QML KB). QML KB is modeled as a fragment of classical higher-order logic (HOL); thus, the formalization is essentially a formalization in HOL.","date":"November 12","id":415,"permalink":"/entries/goedelgod/","shortname":"GoedelGod","title":"Gödel's God in Isabelle/HOL","topicLinks":["logic/philosophical-aspects"],"topics":["Logic/Philosophical aspects"]},{"abstract":"This theory contains a formalization of decreasing diagrams showing that any locally decreasing abstract rewrite system is confluent. We consider the valley (van Oostrom, TCS 1994) and the conversion version (van Oostrom, RTA 2008) and closely follow the original proofs. As an application we prove Newman's lemma.","date":"November 1","id":416,"permalink":"/entries/decreasing-diagrams/","shortname":"Decreasing-Diagrams","title":"Decreasing Diagrams","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":"We present the Autoref tool for Isabelle/HOL, which automatically refines algorithms specified over abstract concepts like maps and sets to algorithms over concrete implementations like red-black-trees, and produces a refinement theorem. It is based on ideas borrowed from relational parametricity due to Reynolds and Wadler. The tool allows for rapid prototyping of verified, executable algorithms. Moreover, it can be configured to fine-tune the result to the user~s needs. Our tool is able to automatically instantiate generic algorithms, which greatly simplifies the implementation of executable data structures. \u003cp\u003e This AFP-entry provides the basic tool, which is then used by the Refinement and Collection Framework to provide automatic data refinement for the nondeterminism monad and various collection datastructures.","date":"October 2","id":417,"permalink":"/entries/automatic_refinement/","shortname":"Automatic_Refinement","title":"Automatic Data Refinement","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"This entry makes machine words and machine arithmetic available for code generation from Isabelle/HOL.  It provides a common abstraction that hides the differences between the different target languages.  The code generator maps these operations to the APIs of the target languages.  Apart from that, we extend the available bit operations on types int and integer, and map them to the operations in the target languages.","date":"September 17","id":418,"permalink":"/entries/native_word/","shortname":"Native_Word","title":"Native Word","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This development provides a formal model of IEEE-754 floating-point arithmetic. This formalization, including formal specification of the standard and proofs of important properties of floating-point arithmetic, forms the foundation for verifying programs with floating-point computation. There is also a code generation setup for floats so that we can execute programs using this formalization in functional programming languages.","date":"July 27","id":419,"permalink":"/entries/ieee_floating_point/","shortname":"IEEE_Floating_Point","title":"A Formal Model of IEEE Floating Point Arithmetic","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"In 1927, Lehmer presented criterions for primality, based on the converse of Fermat's litte theorem. This work formalizes the second criterion from Lehmer's paper, a necessary and sufficient condition for primality. \u003cp\u003e As a side product we formalize some properties of Euler's phi-function, the notion of the order of an element of a group, and the cyclicity of the multiplicative group of a finite field.","date":"July 22","id":420,"permalink":"/entries/lehmer/","shortname":"Lehmer","title":"Lehmer's Theorem","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":"In 1975, Pratt introduced a proof system for certifying primes. He showed that a number \u003ci\u003ep\u003c/i\u003e is prime iff a primality certificate for \u003ci\u003ep\u003c/i\u003e exists. By showing a logarithmic upper bound on the length of the certificates in size of the prime number, he concluded that the decision problem for prime numbers is in NP. This work formalizes soundness and completeness of Pratt's proof system as well as an upper bound for the size of the certificate.","date":"July 22","id":421,"permalink":"/entries/pratt_certificate/","shortname":"Pratt_Certificate","title":"Pratt's Primality Certificates","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":"This development provides a formalization of undirected graphs and simple graphs, which are based on Benedikt Nordhoff and Peter Lammich's simple formalization of labelled directed graphs in the archive. Then, with our formalization of graphs, we show both necessary and sufficient conditions for Eulerian trails and circuits as well as the fact that the Königsberg Bridge Problem does not have a solution. In addition, we show the Friendship Theorem in simple graphs.","date":"July 19","id":422,"permalink":"/entries/koenigsberg_friendship/","shortname":"Koenigsberg_Friendship","title":"The Königsberg Bridge Problem and the Friendship Theorem","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" This is a formalization of the soundness and completeness properties for various efficient encodings of sorts in unsorted first-order logic used by Isabelle's Sledgehammer tool. \u003cp\u003e Essentially, the encodings proceed as follows: a many-sorted problem is decorated with (as few as possible) tags or guards that make the problem monotonic; then sorts can be soundly erased. \u003cp\u003e The development employs a formalization of many-sorted first-order logic in clausal form (clauses, structures and the basic properties of the satisfaction relation), which could be of interest as the starting point for other formalizations of first-order logic metatheory.","date":"June 27","id":423,"permalink":"/entries/sort_encodings/","shortname":"Sort_Encodings","title":"Sound and Complete Sort Encodings for First-Order Logic","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":"This theory is split into two sections. In the first section, we give a formal proof that a well-known axiomatic characterization of the single-source shortest path problem is correct. Namely, we prove that in a directed graph with a non-negative cost function on the edges the single-source shortest path function is the only function that satisfies a set of four axioms. In the second section, we give a formal proof of the correctness of an axiomatic characterization of the single-source shortest path problem for directed graphs with general cost functions. The axioms here are more involved because we have to account for potential negative cycles in the graph. The axioms are summarized in three Isabelle locales.","date":"May 22","id":424,"permalink":"/entries/shortestpath/","shortname":"ShortestPath","title":"An Axiomatic Characterization of the Single-Source Shortest Path Problem","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":"This development provides a formalization of directed graphs, supporting (labelled) multi-edges and infinite graphs. A polymorphic edge type allows edges to be treated as pairs of vertices, if multi-edges are not required. Formalized properties are i.a. walks (and related concepts), connectedness and subgraphs and basic properties of isomorphisms. \u003cp\u003e This formalization is used to prove characterizations of Euler Trails, Shortest Paths and Kuratowski subgraphs.","date":"April 28","id":425,"permalink":"/entries/graph_theory/","shortname":"Graph_Theory","title":"Graph Theory","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":" This development provides a framework for container types like sets and maps such that generated code implements these containers with different (efficient) data structures. Thanks to type classes and refinement during code generation, this light-weight approach can seamlessly replace Isabelle's default setup for code generation. Heuristics automatically pick one of the available data structures depending on the type of elements to be stored, but users can also choose on their own. The extensible design permits to add more implementations at any time. \u003cp\u003e To support arbitrary nesting of sets, we define a linear order on sets based on a linear order of the elements and provide efficient implementations. It even allows to compare complements with non-complements.","date":"April 15","id":426,"permalink":"/entries/containers/","shortname":"Containers","title":"Light-weight Containers","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" \u003cp\u003eDealing with binders, renaming of bound variables, capture-avoiding substitution, etc., is very often a major problem in formal proofs, especially in proofs by structural and rule induction. Nominal Isabelle is designed to make such proofs easy to formalise: it provides an infrastructure for declaring nominal datatypes (that is alpha-equivalence classes) and for defining functions over them by structural recursion. It also provides induction principles that have Barendregt’s variable convention already built in. \u003c/p\u003e\u003cp\u003e This entry can be used as a more advanced replacement for HOL/Nominal in the Isabelle distribution. \u003c/p\u003e","date":"February 21","id":427,"permalink":"/entries/nominal2/","shortname":"Nominal2","title":"Nominal 2","topicLinks":["tools"],"topics":["Tools"]},{"abstract":"In his seminal paper \"Natural Semantics for Lazy Evaluation\", John Launchbury proves his semantics correct with respect to a denotational semantics, and outlines an adequacy proof. We have formalized both semantics and machine-checked the correctness proof, clarifying some details. Furthermore, we provide a new and more direct adequacy proof that does not require intermediate operational semantics.","date":"January 31","id":428,"permalink":"/entries/launchbury/","shortname":"Launchbury","title":"The Correctness of Launchbury's Natural Semantics for Lazy Evaluation","topicLinks":["computer-science/programming-languages/lambda-calculi","computer-science/semantics"],"topics":["Computer science/Programming languages/Lambda calculi","Computer science/Semantics"]},{"abstract":"This document concerns the theory of ribbon proofs: a diagrammatic proof system, based on separation logic, for verifying program correctness. We include the syntax, proof rules, and soundness results for two alternative formalisations of ribbon proofs. \u003cp\u003e Compared to traditional proof outlines, ribbon proofs emphasise the structure of a proof, so are intelligible and pedagogical. Because they contain less redundancy than proof outlines, and allow each proof step to be checked locally, they may be more scalable. Where proof outlines are cumbersome to modify, ribbon proofs can be visually manoeuvred to yield proofs of variant programs.","date":"January 19","id":429,"permalink":"/entries/ribbon_proofs/","shortname":"Ribbon_Proofs","title":"Ribbon Proofs","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"In this contribution, we present some formalizations based on the HOL-Multivariate-Analysis session of Isabelle. Firstly, a generalization of several theorems of such library are presented. Secondly, some definitions and proofs involving Linear Algebra and the four fundamental subspaces of a matrix are shown. Finally, we present a proof of the result known in Linear Algebra as the ``Rank-Nullity Theorem'', which states that, given any linear map f from a finite dimensional vector space V to a vector space W, then the dimension of V is equal to the dimension of the kernel of f (which is a subspace of V) and the dimension of the range of f (which is a subspace of W). The proof presented here is based on the one given by Sheldon Axler in his book \u003ci\u003eLinear Algebra Done Right\u003c/i\u003e. As a corollary of the previous theorem, and taking advantage of the relationship between linear maps and matrices, we prove that, for every matrix A (which has associated a linear map between finite dimensional vector spaces), the sum of its null space and its column space (which is equal to the range of the linear map) is equal to the number of columns of A.","date":"January 16","id":430,"permalink":"/entries/rank_nullity_theorem/","shortname":"Rank_Nullity_Theorem","title":"Rank-Nullity Theorem in Linear Algebra","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":" These files contain a formalisation of variants of Kleene algebras and their most important models as axiomatic type classes in Isabelle/HOL. Kleene algebras are foundational structures in computing with applications ranging from automata and language theory to computational modeling, program construction and verification. \u003cp\u003e We start with formalising dioids, which are additively idempotent semirings, and expand them by axiomatisations of the Kleene star for finite iteration and an omega operation for infinite iteration. We show that powersets over a given monoid, (regular) languages, sets of paths in a graph, sets of computation traces, binary relations and formal power series form Kleene algebras, and consider further models based on lattices, max-plus semirings and min-plus semirings. We also demonstrate that dioids are closed under the formation of matrices (proofs for Kleene algebras remain to be completed). \u003cp\u003e On the one hand we have aimed at a reference formalisation of variants of Kleene algebras that covers a wide range of variants and the core theorems in a structured and modular way and provides readable proofs at text book level. On the other hand, we intend to use this algebraic hierarchy and its models as a generic algebraic middle-layer from which programming applications can quickly be explored, implemented and verified.","date":"January 15","id":431,"permalink":"/entries/kleene_algebra/","shortname":"Kleene_Algebra","title":"Kleene Algebra","topicLinks":["computer-science/programming-languages/logics","computer-science/automata-and-formal-languages","mathematics/algebra"],"topics":["Computer science/Programming languages/Logics","Computer science/Automata and formal languages","Mathematics/Algebra"]},{"abstract":" We implement the Babylonian method to compute n-th roots of numbers. We provide precise algorithms for naturals, integers and rationals, and offer an approximation algorithm for square roots over linear ordered fields. Moreover, there are precise algorithms to compute the floor and the ceiling of n-th roots.","date":"January 3","id":432,"permalink":"/entries/sqrt_babylonian/","shortname":"Sqrt_Babylonian","title":"Computing N-th Roots using the Babylonian Method","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":" We provide a framework for separation-logic based correctness proofs of Imperative HOL programs. Our framework comes with a set of proof methods to automate canonical tasks such as verification condition generation and frame inference. Moreover, we provide a set of examples that show the applicability of our framework. The examples include algorithms on lists, hash-tables, and union-find trees. We also provide abstract interfaces for lists, maps, and sets, that allow to develop generic imperative algorithms and use data-refinement techniques. \u003cbr\u003e As we target Imperative HOL, our programs can be translated to efficiently executable code in various target languages, including ML, OCaml, Haskell, and Scala.","date":"November 14","id":433,"permalink":"/entries/separation_logic_imperative_hol/","shortname":"Separation_Logic_Imperative_HOL","title":"A Separation Logic Framework for Imperative HOL","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":" A proof of the open induction schema based on J.-C. Raoult, Proving open properties by induction, \u003ci\u003eInformation Processing Letters\u003c/i\u003e 29, 1988, pp.19-23. \u003cp\u003eThis research was supported by the Austrian Science Fund (FWF): J3202.\u003c/p\u003e","date":"November 2","id":434,"permalink":"/entries/open_induction/","shortname":"Open_Induction","title":"Open Induction","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" Tarski's axioms of plane geometry are formalized and, using the standard real Cartesian model, shown to be consistent. A substantial theory of the projective plane is developed. Building on this theory, the Klein-Beltrami model of the hyperbolic plane is defined and shown to satisfy all of Tarski's axioms except his Euclidean axiom; thus Tarski's Euclidean axiom is shown to be independent of his other axioms of plane geometry. \u003cp\u003e An earlier version of this work was the subject of the author's \u003ca href=\"http://researcharchive.vuw.ac.nz/handle/10063/2315\"\u003eMSc thesis\u003c/a\u003e, which contains natural-language explanations of some of the more interesting proofs.","date":"October 30","id":435,"permalink":"/entries/tarskis_geometry/","shortname":"Tarskis_Geometry","title":"The independence of Tarski's Euclidean axiom","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":"A proof of Bondy's theorem following B. Bollabas, Combinatorics, 1986, Cambridge University Press.","date":"October 27","id":436,"permalink":"/entries/bondy/","shortname":"Bondy","title":"Bondy's Theorem","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":"We formalize a wide variety of Volpano/Smith-style  noninterference notions for a while language with parallel composition. We systematize and classify these notions according to compositionality w.r.t. the language constructs. Compositionality yields sound syntactic criteria (a.k.a. type systems) in a uniform way. \u003cp\u003e An \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/cpp12.html\"\u003earticle\u003c/a\u003e about these proofs is published in the proceedings of the conference Certified Programs and Proofs 2012.","date":"September 10","id":437,"permalink":"/entries/possibilistic_noninterference/","shortname":"Possibilistic_Noninterference","title":"Possibilistic Noninterference","topicLinks":["computer-science/security","computer-science/programming-languages/type-systems"],"topics":["Computer science/Security","Computer science/Programming languages/Type systems"]},{"abstract":" We provide a framework for registering automatic methods to derive class instances of datatypes, as it is possible using Haskell's ``deriving Ord, Show, ...'' feature. \u003cp\u003e We further implemented such automatic methods to derive (linear) orders or hash-functions which are required in the Isabelle Collection Framework. Moreover, for the tactic of Huffman and Krauss to show that a datatype is countable, we implemented a wrapper so that this tactic becomes accessible in our framework. \u003cp\u003e Our formalization was performed as part of the \u003ca href=\"http://cl-informatik.uibk.ac.at/software/ceta\"\u003eIsaFoR/CeTA\u003c/a\u003e project. With our new tactic we could completely remove tedious proofs for linear orders of two datatypes. \u003cp\u003e This development is aimed at datatypes generated by the \"old_datatype\" command.","date":"August 7","id":438,"permalink":"/entries/datatype_order_generator/","shortname":"Datatype_Order_Generator","title":"Generating linear orders for datatypes","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"Squaring the circle, doubling the cube and trisecting an angle, using a compass and straightedge alone, are classic unsolved problems first posed by the ancient Greeks. All three problems were proved to be impossible in the 19th century. The following document presents the proof of the impossibility of solving the latter two problems using Isabelle/HOL, following a proof by Carrega. The proof uses elementary methods: no Galois theory or field extensions. The set of points constructible using a compass and straightedge is defined inductively. Radical expressions, which involve only square roots and arithmetic of rational numbers, are defined, and we find that all constructive points have radical coordinates. Finally, doubling the cube and trisecting certain angles requires solving certain cubic equations that can be proved to have no rational roots. The Isabelle proofs require a great many detailed calculations.","date":"August 5","id":439,"permalink":"/entries/impossible_geometry/","shortname":"Impossible_Geometry","title":"Proving the Impossibility of Trisecting an Angle and Doubling the Cube","topicLinks":["mathematics/algebra","mathematics/geometry"],"topics":["Mathematics/Algebra","Mathematics/Geometry"]},{"abstract":" Distributed computing is inherently based on replication, promising increased tolerance to failures of individual computing nodes or communication channels. Realizing this promise, however, involves quite subtle algorithmic mechanisms, and requires precise statements about the kinds and numbers of faults that an algorithm tolerates (such as process crashes, communication faults or corrupted values).  The landmark theorem due to Fischer, Lynch, and Paterson shows that it is impossible to achieve Consensus among N asynchronously communicating nodes in the presence of even a single permanent failure. Existing solutions must rely on assumptions of \"partial synchrony\". \u003cp\u003e Indeed, there have been numerous misunderstandings on what exactly a given algorithm is supposed to realize in what kinds of environments. Moreover, the abundance of subtly different computational models complicates comparisons between different algorithms. Charron-Bost and Schiper introduced the Heard-Of model for representing algorithms and failure assumptions in a uniform framework, simplifying comparisons between algorithms. \u003cp\u003e In this contribution, we represent the Heard-Of model in Isabelle/HOL. We define two semantics of runs of algorithms with different unit of atomicity and relate these through a reduction theorem that allows us to verify algorithms in the coarse-grained semantics (where proofs are easier) and infer their correctness for the fine-grained one (which corresponds to actual executions). We instantiate the framework by verifying six Consensus algorithms that differ in the underlying algorithmic mechanisms and the kinds of faults they tolerate.","date":"July 27","id":440,"permalink":"/entries/heard_of/","shortname":"Heard_Of","title":"Verifying Fault-Tolerant Distributed Algorithms in the Heard-Of Model","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":"We apply Andy Pitts's methods of defining relations over domains to several classical results in the literature. We show that the Y combinator coincides with the domain-theoretic fixpoint operator, that parallel-or and the Plotkin existential are not definable in PCF, that the continuation semantics for PCF coincides with the direct semantics, and that our domain-theoretic semantics for PCF is adequate for reasoning about contextual equivalence in an operational semantics. Our version of PCF is untyped and has both strict and non-strict function abstractions. The development is carried out in HOLCF.","date":"July 1","id":441,"permalink":"/entries/pcf/","shortname":"PCF","title":"Logical Relations for PCF","topicLinks":["computer-science/programming-languages/lambda-calculi"],"topics":["Computer science/Programming languages/Lambda calculi"]},{"abstract":" These theories contain a formalization of first class type constructors and axiomatic constructor classes for HOLCF. This work is described in detail in the ICFP 2012 paper \u003ci\u003eFormal Verification of Monad Transformers\u003c/i\u003e by the author. The formalization is a revised and updated version of earlier joint work with Matthews and White. \u003cP\u003e Based on the hierarchy of type classes in Haskell, we define classes for functors, monads, monad-plus, etc. Each one includes all the standard laws as axioms. We also provide a new user command, tycondef, for defining new type constructors in HOLCF. Using tycondef, we instantiate the type class hierarchy with various monads and monad transformers.","date":"June 26","id":442,"permalink":"/entries/tycon/","shortname":"Tycon","title":"Type Constructor Classes and Monad Transformers","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"We formalise a large portion of CCS as described in Milner's book 'Communication and Concurrency' using the nominal datatype package in Isabelle. Our results include many of the standard theorems of bisimulation equivalence and congruence, for both weak and strong versions. One main goal of this formalisation is to keep the machine-checked proofs as close to their pen-and-paper counterpart as possible. \u003cp\u003e This entry is described in detail in \u003ca href=\"http://www.itu.dk/people/jebe/files/thesis.pdf\"\u003eBengtson's thesis\u003c/a\u003e.","date":"May 29","id":443,"permalink":"/entries/ccs/","shortname":"CCS","title":"CCS in nominal logic","topicLinks":["computer-science/concurrency/process-calculi"],"topics":["Computer science/Concurrency/Process calculi"]},{"abstract":"Psi-calculi are extensions of the pi-calculus, accommodating arbitrary nominal datatypes to represent not only data but also communication channels, assertions and conditions, giving it an expressive power beyond the applied pi-calculus and the concurrent constraint pi-calculus. \u003cp\u003e We have formalised psi-calculi in the interactive theorem prover Isabelle using its nominal datatype package. One distinctive feature is that the framework needs to treat binding sequences, as opposed to single binders, in an efficient way. While different methods for formalising single binder calculi have been proposed over the last decades, representations for such binding sequences are not very well explored. \u003cp\u003e The main effort in the formalisation is to keep the machine checked proofs as close to their pen-and-paper counterparts as possible. This includes treating all binding sequences as atomic elements, and creating custom induction and inversion rules that to remove the bulk of manual alpha-conversions. \u003cp\u003e This entry is described in detail in \u003ca href=\"http://www.itu.dk/people/jebe/files/thesis.pdf\"\u003eBengtson's thesis\u003c/a\u003e.","date":"May 29","id":444,"permalink":"/entries/psi_calculi/","shortname":"Psi_Calculi","title":"Psi-calculi in Isabelle","topicLinks":["computer-science/concurrency/process-calculi"],"topics":["Computer science/Concurrency/Process calculi"]},{"abstract":"We formalise the pi-calculus using the nominal datatype package, based on ideas from the nominal logic by Pitts et al., and demonstrate an implementation in Isabelle/HOL. The purpose is to derive powerful induction rules for the semantics in order to conduct machine checkable proofs, closely following the intuitive arguments found in manual proofs. In this way we have covered many of the standard theorems of bisimulation equivalence and congruence, both late and early, and both strong and weak in a uniform manner. We thus provide one of the most extensive formalisations of a the pi-calculus ever done inside a theorem prover. \u003cp\u003e A significant gain in our formulation is that agents are identified up to alpha-equivalence, thereby greatly reducing the arguments about bound names. This is a normal strategy for manual proofs about the pi-calculus, but that kind of hand waving has previously been difficult to incorporate smoothly in an interactive theorem prover. We show how the nominal logic formalism and its support in Isabelle accomplishes this and thus significantly reduces the tedium of conducting completely formal proofs. This improves on previous work using weak higher order abstract syntax since we do not need extra assumptions to filter out exotic terms and can keep all arguments within a familiar first-order logic. \u003cp\u003e This entry is described in detail in \u003ca href=\"http://www.itu.dk/people/jebe/files/thesis.pdf\"\u003eBengtson's thesis\u003c/a\u003e.","date":"May 29","id":445,"permalink":"/entries/pi_calculus/","shortname":"Pi_Calculus","title":"The pi-calculus in nominal logic","topicLinks":["computer-science/concurrency/process-calculi"],"topics":["Computer science/Concurrency/Process calculi"]},{"abstract":"The Circus specification language combines elements for complex data and behavior specifications, using an integration of Z and CSP with a refinement calculus. Its semantics is based on Hoare and He's Unifying Theories of Programming (UTP). Isabelle/Circus is a formalization of the UTP and the Circus language in Isabelle/HOL. It contains proof rules and tactic support that allows for proofs of refinement for Circus processes (involving both data and behavioral aspects). \u003cp\u003e The Isabelle/Circus environment supports a syntax for the semantic definitions which is close to textbook presentations of Circus. This article contains an extended version of corresponding VSTTE Paper together with the complete formal development of its underlying commented theories.","date":"May 27","id":446,"permalink":"/entries/circus/","shortname":"Circus","title":"Isabelle/Circus","topicLinks":["computer-science/concurrency/process-calculi","computer-science/system-description-languages"],"topics":["Computer science/Concurrency/Process calculi","Computer science/System description languages"]},{"abstract":"We present a generic type class implementation of separation algebra for Isabelle/HOL as well as lemmas and generic tactics which can be used directly for any instantiation of the type class. \u003cP\u003e The ex directory contains example instantiations that include structures such as a heap or virtual memory. \u003cP\u003e The abstract separation algebra is based upon \"Abstract Separation Logic\" by Calcagno et al. These theories are also the basis of the ITP 2012 rough diamond \"Mechanised Separation Algebra\" by the authors. \u003cP\u003e The aim of this work is to support and significantly reduce the effort for future separation logic developments in Isabelle/HOL by factoring out the part of separation logic that can be treated abstractly once and for all. This includes developing typical default rule sets for reasoning as well as automated tactic support for separation logic.","date":"May 11","id":447,"permalink":"/entries/separation_algebra/","shortname":"Separation_Algebra","title":"Separation Algebra","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"\u003cp\u003eTwo omega-sequences are stuttering equivalent if they differ only by finite repetitions of elements. Stuttering equivalence is a fundamental concept in the theory of concurrent and distributed systems. Notably, Lamport argues that refinement notions for such systems should be insensitive to finite stuttering. Peled and Wilke showed that all PLTL (propositional linear-time temporal logic) properties that are insensitive to stuttering equivalence can be expressed without the next-time operator. Stuttering equivalence is also important for certain verification techniques such as partial-order reduction for model checking.\u003c/p\u003e \u003cp\u003eWe formalize stuttering equivalence in Isabelle/HOL. Our development relies on the notion of stuttering sampling functions that may skip blocks of identical sequence elements. We also encode PLTL and prove the theorem due to Peled and Wilke.\u003c/p\u003e","date":"May 7","id":448,"permalink":"/entries/stuttering_equivalence/","shortname":"Stuttering_Equivalence","title":"Stuttering Equivalence","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"This document contains the full theory files accompanying article \u003ci\u003eInductive Study of Confidentiality --- for Everyone\u003c/i\u003e in \u003ci\u003eFormal Aspects of Computing\u003c/i\u003e. They aim at an illustrative and didactic presentation of the Inductive Method of protocol analysis, focusing on the treatment of one of the main goals of security protocols: confidentiality against a threat model. The treatment of confidentiality, which in fact forms a key aspect of all protocol analysis tools, has been found cryptic by many learners of the Inductive Method, hence the motivation for this work. The theory files in this document guide the reader step by step towards design and proof of significant confidentiality theorems. These are developed against two threat models, the standard Dolev-Yao and a more audacious one, the General Attacker, which turns out to be particularly useful also for teaching purposes.","date":"May 2","id":449,"permalink":"/entries/inductive_confidentiality/","shortname":"Inductive_Confidentiality","title":"Inductive Study of Confidentiality","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003eSession Ordinary-Differential-Equations formalizes ordinary differential equations (ODEs) and initial value problems. This work comprises proofs for local and global existence of unique solutions (Picard-Lindelöf theorem). Moreover, it contains a formalization of the (continuous or even differentiable) dependency of the flow on initial conditions as the \u003ci\u003eflow\u003c/i\u003e of ODEs.\u003c/p\u003e \u003cp\u003e Not in the generated document are the following sessions: \u003cul\u003e \u003cli\u003e HOL-ODE-Numerics: Rigorous numerical algorithms for computing enclosures of solutions based on Runge-Kutta methods and affine arithmetic. Reachability analysis with splitting and reduction at hyperplanes.\u003c/li\u003e \u003cli\u003e HOL-ODE-Examples: Applications of the numerical algorithms to concrete systems of ODEs.\u003c/li\u003e \u003cli\u003e Lorenz_C0, Lorenz_C1: Verified algorithms for checking C1-information according to Tucker's proof, computation of C0-information.\u003c/li\u003e \u003c/ul\u003e \u003c/p\u003e","date":"April 26","id":450,"permalink":"/entries/ordinary_differential_equations/","shortname":"Ordinary_Differential_Equations","title":"Ordinary Differential Equations","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"Based on Isabelle/HOL's type class for preorders, we introduce a type class for well-quasi-orders (wqo) which is characterized by the absence of \"bad\" sequences (our proofs are along the lines of the proof of Nash-Williams, from which we also borrow terminology). Our main results are instantiations for the product type, the list type, and a type of finite trees, which (almost) directly follow from our proofs of (1) Dickson's Lemma, (2) Higman's Lemma, and (3) Kruskal's Tree Theorem. More concretely: \u003cul\u003e \u003cli\u003eIf the sets A and B are wqo then their Cartesian product is wqo.\u003c/li\u003e \u003cli\u003eIf the set A is wqo then the set of finite lists over A is wqo.\u003c/li\u003e \u003cli\u003eIf the set A is wqo then the set of finite trees over A is wqo.\u003c/li\u003e \u003c/ul\u003e The research was funded by the Austrian Science Fund (FWF): J3202.","date":"April 13","id":451,"permalink":"/entries/well_quasi_orders/","shortname":"Well_Quasi_Orders","title":"Well-Quasi-Orders","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" We define the Abortable Linearizable Module automaton (ALM for short) and prove its key composition property using the IOA theory of HOLCF. The ALM is at the heart of the Speculative Linearizability framework. This framework simplifies devising correct speculative algorithms by enabling their decomposition into independent modules that can be analyzed and proved correct in isolation. It is particularly useful when working in a distributed environment, where the need to tolerate faults and asynchrony has made current monolithic protocols so intricate that it is no longer tractable to check their correctness. Our theory contains a typical example of a refinement proof in the I/O-automata framework of Lynch and Tuttle.","date":"March 1","id":452,"permalink":"/entries/abortable_linearizable_modules/","shortname":"Abortable_Linearizable_Modules","title":"Abortable Linearizable Modules","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":" \u003cp\u003e We provide a generic work-list algorithm to compute the (reflexive-)transitive closure of relations where only successors of newly detected states are generated. In contrast to our previous work, the relations do not have to be finite, but each element must only have finitely many (indirect) successors. Moreover, a subsumption relation can be used instead of pure equality. An executable variant of the algorithm is available where the generic operations are instantiated with list operations. \u003c/p\u003e\u003cp\u003e This formalization was performed as part of the IsaFoR/CeTA project, and it has been used to certify size-change termination proofs where large transitive closures have to be computed. \u003c/p\u003e","date":"February 29","id":453,"permalink":"/entries/transitive-closure-ii/","shortname":"Transitive-Closure-II","title":"Executable Transitive Closures","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":"This works presents a formalization of the Girth-Chromatic number theorem in graph theory, stating that graphs with arbitrarily large girth and chromatic number exist. The proof uses the theory of Random Graphs to prove the existence with probabilistic arguments.","date":"February 6","id":454,"permalink":"/entries/girth_chromatic/","shortname":"Girth_Chromatic","title":"A Probabilistic Proof of the Girth-Chromatic Number Theorem","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":"We implement and prove correct Dijkstra's algorithm for the single source shortest path problem, conceived in 1956 by E. Dijkstra. The algorithm is implemented using the data refinement framework for monadic, nondeterministic programs. An efficient implementation is derived using data structures from the Isabelle Collection Framework.","date":"January 30","id":455,"permalink":"/entries/dijkstra_shortest_path/","shortname":"Dijkstra_Shortest_Path","title":"Dijkstra's Shortest Path Algorithm","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":"We provide a framework for program and data refinement in Isabelle/HOL. The framework is based on a nondeterminism-monad with assertions, i.e., the monad carries a set of results or an assertion failure. Recursion is expressed by fixed points. For convenience, we also provide while and foreach combinators. \u003cp\u003e The framework provides tools to automatize canonical tasks, such as verification condition generation, finding appropriate data refinement relations, and refine an executable program to a form that is accepted by the Isabelle/HOL code generator. \u003cp\u003e This submission comes with a collection of examples and a user-guide, illustrating the usage of the framework.","date":"January 30","id":456,"permalink":"/entries/refine_monadic/","shortname":"Refine_Monadic","title":"Refinement for Monadic Programs","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"This is a formalization of Markov models in Isabelle/HOL. It builds on Isabelle's probability theory. The available models are currently Discrete-Time Markov Chains and a extensions of them with rewards. \u003cp\u003e As application of these models we formalize probabilistic model checking of pCTL formulas, analysis of IPv4 address allocation in ZeroConf and an analysis of the anonymity of the Crowds protocol. \u003ca href=\"http://arxiv.org/abs/1212.3870\"\u003eSee here for the corresponding paper.\u003c/a\u003e","date":"January 3","id":457,"permalink":"/entries/markov_models/","shortname":"Markov_Models","title":"Markov Models","topicLinks":["mathematics/probability-theory","computer-science/automata-and-formal-languages"],"topics":["Mathematics/Probability theory","Computer science/Automata and formal languages"]},{"abstract":"We mechanise the logic TLA* \u003ca href=\"http://www.springerlink.com/content/ax3qk557qkdyt7n6/\"\u003e[Merz 1999]\u003c/a\u003e, an extension of Lamport's  Temporal Logic of Actions (TLA) \u003ca href=\"http://dl.acm.org/citation.cfm?doid=177492.177726\"\u003e[Lamport 1994]\u003c/a\u003e for specifying and reasoning about concurrent and reactive systems. Aiming at a framework for mechanising]  the verification of TLA (or TLA*) specifications, this contribution reuses some elements from a previous axiomatic encoding of TLA in Isabelle/HOL by the second author [Merz 1998], which has been part of the Isabelle distribution. In contrast to that previous work, we give here a shallow, definitional embedding, with the following highlights: \u003cul\u003e \u003cli\u003ea theory of infinite sequences, including a formalisation of the concepts of stuttering invariance central to TLA and TLA*; \u003cli\u003ea definition of the semantics of TLA*, which extends TLA by a mutually-recursive definition of formulas and pre-formulas, generalising TLA action formulas; \u003cli\u003ea substantial set of derived proof rules, including the TLA* axioms and Lamport's proof rules for system verification; \u003cli\u003ea set of examples illustrating the usage of Isabelle/TLA* for reasoning about systems. \u003c/ul\u003e Note that this work is unrelated to the ongoing development of a proof system for the specification language TLA+, which includes an encoding of TLA+ as a new Isabelle object logic \u003ca href=\"http://www.springerlink.com/content/354026160p14j175/\"\u003e[Chaudhuri et al 2010]\u003c/a\u003e.","date":"November 19","id":458,"permalink":"/entries/tla/","shortname":"TLA","title":"A Definitional Encoding of TLA* in Isabelle/HOL","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"We provide a formalization of the mergesort algorithm as used in GHC's Data.List module, proving correctness and stability. Furthermore, experimental data suggests that generated (Haskell-)code for this algorithm is much faster than for previous algorithms available in the Isabelle distribution.","date":"November 9","id":459,"permalink":"/entries/efficient-mergesort/","shortname":"Efficient-Mergesort","title":"Efficient Mergesort","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":"Algebras of imperative programming languages have been successful in reasoning about programs. In general an algebra of programs is an algebraic structure with programs as elements and with program compositions (sequential composition, choice, skip) as algebra operations. Various versions of these algebras were introduced to model partial correctness, total correctness, refinement, demonic choice, and other aspects. We formalize here an algebra which can be used to model total correctness, refinement, demonic and angelic choice. The basic model of this algebra are monotonic Boolean transformers (monotonic functions from a Boolean algebra to itself).","date":"September 22","id":460,"permalink":"/entries/monobooltranalgebra/","shortname":"MonoBoolTranAlgebra","title":"Algebra of Monotonic Boolean Transformers","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"This formalization introduces and collects some algebraic structures based on lattices and complete lattices for use in other developments. The structures introduced are modular, and lattice ordered groups. In addition to the results proved for the new lattices, this formalization also introduces theorems about latices and complete lattices in general.","date":"September 22","id":461,"permalink":"/entries/latticeproperties/","shortname":"LatticeProperties","title":"Lattice Properties","topicLinks":["mathematics/order"],"topics":["Mathematics/Order"]},{"abstract":"Pseudo-hoops are algebraic structures introduced by B. Bosbach under the name of complementary semigroups. In this formalization we prove some properties of pseudo-hoops and we define the basic concepts of filter and normal filter. The lattice of normal filters is isomorphic with the lattice of congruences of a pseudo-hoop. We also study some important classes of pseudo-hoops. Bounded Wajsberg pseudo-hoops are equivalent to pseudo-Wajsberg algebras and bounded basic pseudo-hoops are equivalent to pseudo-BL algebras. Some examples of pseudo-hoops are given in the last section of the formalization.","date":"September 22","id":462,"permalink":"/entries/pseudohoops/","shortname":"PseudoHoops","title":"Pseudo Hoops","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"There are many proofs of the Myhill-Nerode theorem using automata. In this library we give a proof entirely based on regular expressions, since regularity of languages can be conveniently defined using regular expressions (it is more painful in HOL to define regularity in terms of automata).  We prove the first direction of the Myhill-Nerode theorem by solving equational systems that involve regular expressions.  For the second direction we give two proofs: one using tagging-functions and another using partial derivatives. We also establish various closure properties of regular languages. Most details of the theories are described in our ITP 2011 paper.","date":"August 26","id":463,"permalink":"/entries/myhill-nerode/","shortname":"Myhill-Nerode","title":"The Myhill-Nerode Theorem Based on Regular Expressions","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"This theory provides a compact formulation of Gauss-Jordan elimination for matrices represented as functions. Its distinctive feature is succinctness. It is not meant for large computations.","date":"August 19","id":464,"permalink":"/entries/gauss-jordan-elim-fun/","shortname":"Gauss-Jordan-Elim-Fun","title":"Gauss-Jordan Elimination for Matrices Represented as Functions","topicLinks":["computer-science/algorithms/mathematical","mathematics/algebra"],"topics":["Computer science/Algorithms/Mathematical","Mathematics/Algebra"]},{"abstract":" \u003cp\u003e A \u003cem\u003ematching\u003c/em\u003e in a graph \u003ci\u003eG\u003c/i\u003e is a subset \u003ci\u003eM\u003c/i\u003e of the edges of \u003ci\u003eG\u003c/i\u003e such that no two share an endpoint. A matching has maximum cardinality if its cardinality is at least as large as that of any other matching. An \u003cem\u003eodd-set cover\u003c/em\u003e \u003ci\u003eOSC\u003c/i\u003e of a graph \u003ci\u003eG\u003c/i\u003e is a labeling of the nodes of \u003ci\u003eG\u003c/i\u003e with integers such that every edge of \u003ci\u003eG\u003c/i\u003e is either incident to a node labeled 1 or connects two nodes labeled with the same number \u003ci\u003ei \u0026ge; 2\u003c/i\u003e. \u003c/p\u003e\u003cp\u003e This article proves Edmonds theorem:\u003cbr\u003e Let \u003ci\u003eM\u003c/i\u003e be a matching in a graph \u003ci\u003eG\u003c/i\u003e and let \u003ci\u003eOSC\u003c/i\u003e be an odd-set cover of \u003ci\u003eG\u003c/i\u003e. For any \u003ci\u003ei \u0026ge; 0\u003c/i\u003e, let \u003cvar\u003en(i)\u003c/var\u003e be the number of nodes labeled \u003ci\u003ei\u003c/i\u003e. If \u003ci\u003e|M| = n(1) + \u0026sum;\u003csub\u003ei \u0026ge; 2\u003c/sub\u003e(n(i) div 2)\u003c/i\u003e, then \u003ci\u003eM\u003c/i\u003e is a maximum cardinality matching. \u003c/p\u003e","date":"July 21","id":465,"permalink":"/entries/max-card-matching/","shortname":"Max-Card-Matching","title":"Maximum Cardinality Matching","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":"Knowledge-based programs (KBPs) are a formalism for directly relating agents' knowledge and behaviour. Here we present a general scheme for compiling KBPs to executable automata with a proof of correctness in Isabelle/HOL. We develop the algorithm top-down, using Isabelle's locale mechanism to structure these proofs, and show that two classic examples can be synthesised using Isabelle's code generator.","date":"May 17","id":466,"permalink":"/entries/kbps/","shortname":"KBPs","title":"Knowledge-based programs","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"Some acute-angled triangles are special, e.g. right-angled or isoscele triangles. Some are not of this kind, but, without measuring angles, look as if they were. In that sense, there is exactly one general triangle. This well-known fact is proven here formally.","date":"April 1","id":467,"permalink":"/entries/general-triangle/","shortname":"General-Triangle","title":"The General Triangle Is Unique","topicLinks":["mathematics/geometry"],"topics":["Mathematics/Geometry"]},{"abstract":"We provide a generic work-list algorithm to compute the transitive closure of finite relations where only successors of newly detected states are generated. This algorithm is then instantiated for lists over arbitrary carriers and red black trees (which are faster but require a linear order on the carrier), respectively.  Our formalization was performed as part of the IsaFoR/CeTA project where reflexive transitive closures of large tree automata have to be computed.","date":"March 14","id":468,"permalink":"/entries/transitive-closure/","shortname":"Transitive-Closure","title":"Executable Transitive Closures of Finite Relations","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":"We formalize the AutoFocus Semantics (a time-synchronous subset of the Focus formalism) as stream processing functions on finite and infinite message streams represented as finite/infinite lists. The formalization comprises both the conventional single-clocking semantics (uniform global clock for all components and communications channels) and its extension to multi-clocking semantics (internal execution clocking of a component may be a multiple of the external communication clocking). The semantics is defined by generic stream processing functions making it suitable for simulation/code generation in Isabelle/HOL. Furthermore, a number of AutoFocus semantics properties are formalized using definitions from the IntervalLogic theories.","date":"February 23","id":469,"permalink":"/entries/autofocus-stream/","shortname":"AutoFocus-Stream","title":"AutoFocus Stream Processing for Single-Clocking and Multi-Clocking Semantics","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"We introduce a theory of infinite lists in HOL formalized as functions over naturals (folder ListInf, theories ListInf and ListInf_Prefix). It also provides additional results for finite lists (theory ListInf/List2), natural numbers (folder CommonArith, esp. division/modulo, naturals with infinity), sets (folder CommonSet, esp. cutting/truncating sets, traversing sets of naturals).","date":"February 23","id":470,"permalink":"/entries/list-infinite/","shortname":"List-Infinite","title":"Infinite Lists","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"We introduce a theory of temporal logic operators using sets of natural numbers as time domain, formalized in a shallow embedding manner. The theory comprises special natural intervals (theory IL_Interval: open and closed intervals, continuous and modulo intervals, interval traversing results), operators for shifting intervals to left/right on the number axis as well as expanding/contracting intervals by constant factors (theory IL_IntervalOperators.thy), and ultimately definitions and results for unary and binary temporal operators on arbitrary natural sets (theory IL_TemporalOperators).","date":"February 23","id":471,"permalink":"/entries/nat-interval-logic/","shortname":"Nat-Interval-Logic","title":"Interval Temporal Logic on Natural Numbers","topicLinks":["logic/general-logic/temporal-logic"],"topics":["Logic/General logic/Temporal logic"]},{"abstract":"A fully-formalized and extensible minimal imperative fragment of Java.","date":"February 7","id":472,"permalink":"/entries/lightweightjava/","shortname":"LightweightJava","title":"Lightweight Java","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"This work presents a verification of an implementation in SPARK/ADA of the cryptographic hash-function RIPEMD-160. A functional specification of RIPEMD-160 is given in Isabelle/HOL. Proofs for the verification conditions generated by the static-analysis toolset of SPARK certify the functional correctness of the implementation.","date":"January 10","id":473,"permalink":"/entries/ripemd-160-spark/","shortname":"RIPEMD-160-SPARK","title":"RIPEMD-160","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":"We define the notions of lower and upper semicontinuity for functions from a metric space to the extended real line. We prove that a function is both lower and upper semicontinuous if and only if it is continuous. We also give several equivalent characterizations of lower semicontinuity. In particular, we prove that a function is lower semicontinuous if and only if its epigraph is a closed set. Also, we introduce the notion of the lower semicontinuous hull of an arbitrary function and prove its basic properties.","date":"January 8","id":474,"permalink":"/entries/lower_semicontinuous/","shortname":"Lower_Semicontinuous","title":"Lower Semicontinuous Functions","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"Two proofs of Hall's Marriage Theorem: one due to Halmos and Vaughan, one due to Rado.","date":"December 17","id":475,"permalink":"/entries/marriage/","shortname":"Marriage","title":"Hall's Marriage Theorem","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":" In his dissertation, Olin Shivers introduces a concept of control flow graphs for functional languages, provides an algorithm to statically derive a safe approximation of the control flow graph and proves this algorithm correct. In this research project, Shivers' algorithms and proofs are formalized in the HOLCF extension of HOL.","date":"November 16","id":476,"permalink":"/entries/shivers-cfa/","shortname":"Shivers-CFA","title":"Shivers' Control Flow Analysis","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":" We implement and prove correct binomial heaps and skew binomial heaps. Both are data-structures for priority queues. While binomial heaps have logarithmic \u003cem\u003efindMin\u003c/em\u003e, \u003cem\u003edeleteMin\u003c/em\u003e, \u003cem\u003einsert\u003c/em\u003e, and \u003cem\u003emeld\u003c/em\u003e operations, skew binomial heaps have constant time \u003cem\u003efindMin\u003c/em\u003e, \u003cem\u003einsert\u003c/em\u003e, and \u003cem\u003emeld\u003c/em\u003e operations, and only the \u003cem\u003edeleteMin\u003c/em\u003e-operation is logarithmic. This is achieved by using \u003cem\u003eskew links\u003c/em\u003e to avoid cascading linking on \u003cem\u003einsert\u003c/em\u003e-operations, and \u003cem\u003edata-structural bootstrapping\u003c/em\u003e to get constant-time \u003cem\u003efindMin\u003c/em\u003e and \u003cem\u003emeld\u003c/em\u003e operations.  Our implementation follows the paper by Brodal and Okasaki.","date":"October 28","id":477,"permalink":"/entries/binomial-heaps/","shortname":"Binomial-Heaps","title":"Binomial Heaps and Skew Binomial Heaps","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We implement and prove correct 2-3 finger trees. Finger trees are a general purpose data structure, that can be used to efficiently implement other data structures, such as priority queues. Intuitively, a finger tree is an annotated sequence, where the annotations are elements of a monoid. Apart from operations to access the ends of the sequence, the main operation is to split the sequence at the point where a \u003cem\u003emonotone predicate\u003c/em\u003e over the sum of the left part of the sequence becomes true for the first time. The implementation follows the paper of Hinze and Paterson. The code generator can be used to get efficient, verified code.","date":"October 28","id":478,"permalink":"/entries/finger-trees/","shortname":"Finger-Trees","title":"Finger Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"Priority queues are an important data structure and efficient implementations of them are crucial. We implement a functional variant of binomial queues in Isabelle/HOL and show its functional correctness. A verification against an abstract reference specification of priority queues has also been attempted, but could not be achieved to the full extent.","date":"October 28","id":479,"permalink":"/entries/binomial-queues/","shortname":"Binomial-Queues","title":"Functional Binomial Queues","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"Handling variable binding is one of the main difficulties in formal proofs. In this context, Moggi's computational metalanguage serves as an interesting case study. It features monadic types and a commuting conversion rule that rearranges the binding structure. Lindley and Stark have given an elegant proof of strong normalization for this calculus. The key construction in their proof is a notion of relational TT-lifting, using stacks of elimination contexts to obtain a Girard-Tait style logical relation. I give a formalization of their proof in Isabelle/HOL-Nominal with a particular emphasis on the treatment of bound variables.","date":"August 29","id":480,"permalink":"/entries/lam-ml-normalization/","shortname":"Lam-ml-Normalization","title":"Strong Normalization of Moggis's Computational Metalanguage","topicLinks":["computer-science/programming-languages/lambda-calculi"],"topics":["Computer science/Programming languages/Lambda calculi"]},{"abstract":" We define multivariate polynomials over arbitrary (ordered) semirings in combination with (executable) operations like addition, multiplication, and substitution. We also define (weak) monotonicity of polynomials and comparison of polynomials where we provide standard estimations like absolute positiveness or the more recent approach of Neurauter, Zankl, and Middeldorp. Moreover, it is proven that strongly normalizing (monotone) orders can be lifted to strongly normalizing (monotone) orders over polynomials. Our formalization was performed as part of the \u003ca href=\"http://cl-informatik.uibk.ac.at/software/ceta\"\u003eIsaFoR/CeTA-system\u003c/a\u003e which contains several termination techniques. The provided theories have been essential to  formalize polynomial interpretations. \u003cp\u003e This formalization also contains an abstract representation as coefficient functions with finite support and a type of power-products. If this type is ordered by a linear (term) ordering, various additional notions, such as leading power-product, leading coefficient etc., are introduced as well. Furthermore, a lot of generic properties of, and functions on, multivariate polynomials are formalized, including the substitution and evaluation homomorphisms, embeddings of polynomial rings into larger rings (i.e. with one additional indeterminate), homogenization and dehomogenization of polynomials, and the canonical isomorphism between R[X,Y] and R[X][Y].","date":"August 10","id":481,"permalink":"/entries/polynomials/","shortname":"Polynomials","title":"Executable Multivariate Polynomials","topicLinks":["mathematics/analysis","mathematics/algebra","computer-science/algorithms/mathematical"],"topics":["Mathematics/Analysis","Mathematics/Algebra","Computer science/Algorithms/Mathematical"]},{"abstract":"We formalize in Isabelle/HOL the abtract syntax and a synchronous step semantics for the specification language Statecharts. The formalization is based on Hierarchical Automata which allow a structural decomposition of Statecharts into Sequential Automata. To support the composition of Statecharts, we introduce calculating operators to construct a Hierarchical Automaton in a stepwise manner. Furthermore, we present a complete semantics of Statecharts including a theory of data spaces, which enables the modelling of racing effects. We also adapt CTL for Statecharts to build a bridge for future combinations with model checking. However the main motivation of this work is to provide a sound and complete basis for reasoning on Statecharts. As a central meta theorem we prove that the well-formedness of a Statechart is preserved by the semantics.","date":"August 8","id":482,"permalink":"/entries/statecharts/","shortname":"Statecharts","title":"Formalizing Statecharts using Hierarchical Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":" Free Groups are, in a sense, the most generic kind of group. They are defined over a set of generators with no additional relations in between them. They play an important role in the definition of group presentations and in other fields. This theory provides the definition of Free Group as the set of fully canceled words in the generators. The universal property is proven, as well as some isomorphisms results about Free Groups.","date":"June 24","id":483,"permalink":"/entries/free-groups/","shortname":"Free-Groups","title":"Free Groups","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"This article presents a development of Category Theory in Isabelle/HOL. A Category is defined using records and locales. Functors and Natural Transformations are also defined. The main result that has been formalized is that the Yoneda functor is a full and faithful embedding. We also formalize the completeness of many sorted monadic equational logic. Extensive use is made of the HOLZF theory in both cases. For an informal description see \u003ca href=\"http://www.srcf.ucam.org/~apk32/Isabelle/Category/Cat.pdf\"\u003ehere [pdf]\u003c/a\u003e.","date":"June 20","id":484,"permalink":"/entries/category2/","shortname":"Category2","title":"Category Theory","topicLinks":["mathematics/category-theory"],"topics":["Mathematics/Category theory"]},{"abstract":" We provide the operations of matrix addition, multiplication, transposition, and matrix comparisons as executable functions over ordered semirings. Moreover, it is proven that strongly normalizing (monotone) orders can be lifted to strongly normalizing (monotone) orders over matrices. We further show that the standard semirings over the naturals, integers, and rationals, as well as the arctic semirings satisfy the axioms that are required by our matrix theory. Our formalization is part of the \u003ca href=\"http://cl-informatik.uibk.ac.at/software/ceta\"\u003eCeTA\u003c/a\u003e system which contains several termination techniques. The provided theories have been essential to formalize matrix-interpretations and arctic interpretations.","date":"June 17","id":485,"permalink":"/entries/matrix/","shortname":"Matrix","title":"Executable Matrix Operations on Matrices of Arbitrary Dimensions","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":" We present an Isabelle formalization of abstract rewriting (see, e.g., the book by Baader and Nipkow). First, we define standard relations like \u003ci\u003ejoinability\u003c/i\u003e, \u003ci\u003emeetability\u003c/i\u003e, \u003ci\u003econversion\u003c/i\u003e, etc. Then, we formalize important properties of abstract rewrite systems, e.g., confluence and strong normalization. Our main concern is on strong normalization, since this formalization is the basis of \u003ca href=\"http://cl-informatik.uibk.ac.at/software/ceta\"\u003eCeTA\u003c/a\u003e (which is mainly about strong normalization of term rewrite systems). Hence lemmas involving strong normalization constitute by far the biggest part of this theory. One of those is Newman's lemma.","date":"June 14","id":486,"permalink":"/entries/abstract-rewriting/","shortname":"Abstract-Rewriting","title":"Abstract Rewriting","topicLinks":["logic/rewriting"],"topics":["Logic/Rewriting"]},{"abstract":"The invariant based programming is a technique of constructing correct programs by first identifying the basic situations (pre- and post-conditions and invariants) that can occur during the execution of the program, and then defining the transitions and proving that they preserve the invariants. Data refinement is a technique of building correct programs working on concrete datatypes as refinements of more abstract programs. In the theories presented here we formalize the predicate transformer semantics for invariant based programs and their data refinement.","date":"May 28","id":487,"permalink":"/entries/datarefinementibp/","shortname":"DataRefinementIBP","title":"Semantics and Data Refinement of Invariant Based Programs","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"The verification of the Deutsch-Schorr-Waite graph marking algorithm is used as a benchmark in many formalizations of pointer programs. The main purpose of this mechanization is to show how data refinement of invariant based programs can be used in verifying practical algorithms. The verification starts with an abstract algorithm working on a graph given by a relation \u003ci\u003enext\u003c/i\u003e on nodes. Gradually the abstract program is refined into Deutsch-Schorr-Waite graph marking algorithm where only one bit per graph node of additional memory is used for marking.","date":"May 28","id":488,"permalink":"/entries/graphmarkingibp/","shortname":"GraphMarkingIBP","title":"Verification of the Deutsch-Schorr-Waite Graph Marking Algorithm using Data Refinement","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":"This document gives a formalization of the proof of the Robbins conjecture, following A. Mann, \u003ci\u003eA Complete Proof of the Robbins Conjecture\u003c/i\u003e, 2003.","date":"May 22","id":489,"permalink":"/entries/robbins-conjecture/","shortname":"Robbins-Conjecture","title":"A Complete Proof of the Robbins Conjecture","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"This is a library of constructions on regular expressions and languages. It provides the operations of concatenation, Kleene star and derivative on languages. Regular expressions and their meaning are defined. An executable equivalence checker for regular expressions is verified; it does not need automata but works directly on regular expressions. \u003ci\u003eBy mapping regular expressions to binary relations, an automatic and complete proof method for (in)equalities of binary relations over union, concatenation and (reflexive) transitive closure is obtained.\u003c/i\u003e \u003cP\u003e Extended regular expressions with complement and intersection are also defined and an equivalence checker is provided.","date":"May 12","id":490,"permalink":"/entries/regular-sets/","shortname":"Regular-Sets","title":"Regular Sets and Expressions","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"We present a Theory of Objects based on the original functional sigma-calculus by Abadi and Cardelli but with an additional parameter to methods. We prove confluence of the operational semantics following the outline of Nipkow's proof of confluence for the lambda-calculus reusing his theory Commutation, a generic diamond lemma reduction. We furthermore formalize a simple type system for our sigma-calculus including a proof of type safety. The entire development uses the concept of Locally Nameless representation for binders. We reuse an earlier proof of confluence for a simpler sigma-calculus based on de Bruijn indices and lists to represent objects.","date":"April 30","id":491,"permalink":"/entries/locally-nameless-sigma/","shortname":"Locally-Nameless-Sigma","title":"Locally Nameless Sigma Calculus","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"This theory defines a type constructor representing the free Boolean algebra over a set of generators. Values of type (α)\u003ci\u003eformula\u003c/i\u003e represent propositional formulas with uninterpreted variables from type α, ordered by implication. In addition to all the standard Boolean algebra operations, the library also provides a function for building homomorphisms to any other Boolean algebra type.","date":"March 29","id":492,"permalink":"/entries/free-boolean-algebra/","shortname":"Free-Boolean-Algebra","title":"Free Boolean Algebra","topicLinks":["logic/general-logic/classical-propositional-logic"],"topics":["Logic/General logic/Classical propositional logic"]},{"abstract":" \u003cp\u003e In this contribution, we show how correctness proofs for \u003ca href=\"Slicing.html\"\u003eintra-\u003c/a\u003e and \u003ca href=\"HRB-Slicing.html\"\u003einterprocedural slicing\u003c/a\u003e can be used to prove that slicing is able to guarantee information flow noninterference. Moreover, we also illustrate how to lift the control flow graphs of the respective frameworks such that they fulfil the additional assumptions needed in the noninterference proofs. A detailed description of the intraprocedural proof and its interplay with the slicing framework can be found in the PLAS'09 paper by Wasserrab et al. \u003c/p\u003e \u003cp\u003e This entry contains the part for intra-procedural slicing. See entry \u003ca href=\"InformationFlowSlicing_Inter.html\"\u003eInformationFlowSlicing_Inter\u003c/a\u003e for the inter-procedural part. \u003c/p\u003e","date":"March 23","id":493,"permalink":"/entries/informationflowslicing/","shortname":"InformationFlowSlicing","title":"Information Flow Noninterference via Slicing","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":" \u003cp\u003e In this contribution, we show how correctness proofs for \u003ca href=\"Slicing.html\"\u003eintra-\u003c/a\u003e and \u003ca href=\"HRB-Slicing.html\"\u003einterprocedural slicing\u003c/a\u003e can be used to prove that slicing is able to guarantee information flow noninterference. Moreover, we also illustrate how to lift the control flow graphs of the respective frameworks such that they fulfil the additional assumptions needed in the noninterference proofs. A detailed description of the intraprocedural proof and its interplay with the slicing framework can be found in the PLAS'09 paper by Wasserrab et al. \u003c/p\u003e \u003cp\u003e This entry contains the part for inter-procedural slicing. See entry \u003ca href=\"InformationFlowSlicing.html\"\u003eInformationFlowSlicing\u003c/a\u003e for the intra-procedural part. \u003c/p\u003e","date":"March 23","id":494,"permalink":"/entries/informationflowslicing_inter/","shortname":"InformationFlowSlicing_Inter","title":"Inter-Procedural Information Flow Noninterference via Slicing","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"This theory provides functions for finding the index of an element in a list, by predicate and by value.","date":"February 20","id":495,"permalink":"/entries/list-index/","shortname":"List-Index","title":"List Index","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This article collects formalisations of general-purpose coinductive data types and sets. Currently, it contains coinductive natural numbers, coinductive lists, i.e. lazy lists or streams, infinite streams, coinductive terminated lists, coinductive resumptions, a library of operations on coinductive lists, and a version of König's lemma as an application for coinductive lists.\u003cbr\u003eThe initial theory was contributed by Paulson and Wenzel. Extensions and other coinductive formalisations of general interest are welcome.","date":"February 12","id":496,"permalink":"/entries/coinductive/","shortname":"Coinductive","title":"Coinductive","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"This contribution contains a fast SAT solver for Isabelle written in Standard ML. By loading the theory \u003ctt\u003eDPT_SAT_Solver\u003c/tt\u003e, the SAT solver installs itself (under the name ``dptsat'') and certain Isabelle tools like Refute will start using it automatically. This is a port of the DPT (Decision Procedure Toolkit) SAT Solver written in OCaml.","date":"December 9","id":497,"permalink":"/entries/dpt-sat-solver/","shortname":"DPT-SAT-Solver","title":"A Fast SAT Solver for Isabelle in Standard ML","topicLinks":["tools"],"topics":["Tools"]},{"abstract":"This work presents a formalization of a library for automata on bit strings. It forms the basis of a reflection-based decision procedure for Presburger arithmetic, which is efficiently executable thanks to Isabelle's code generator. With this work, we therefore provide a mechanized proof of a well-known connection between logic and automata theory. The formalization is also described in a publication [TPHOLs 2009].","date":"December 3","id":498,"permalink":"/entries/presburger-automata/","shortname":"Presburger-Automata","title":"Formalizing the Logic-Automaton Connection","topicLinks":["computer-science/automata-and-formal-languages","logic/general-logic/decidability-of-theories"],"topics":["Computer science/Automata and formal languages","Logic/General logic/Decidability of theories"]},{"abstract":"This development provides an efficient, extensible, machine checked collections framework. The library adopts the concepts of interface, implementation and generic algorithm from object-oriented programming and implements them in Isabelle/HOL. The framework features the use of data refinement techniques to refine an abstract specification (using high-level concepts like sets) to a more concrete implementation (using collection datastructures, like red-black-trees). The code-generator of Isabelle/HOL can be used to generate efficient code.","date":"November 25","id":499,"permalink":"/entries/collections/","shortname":"Collections","title":"Collections Framework","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This work presents a machine-checked tree automata library for Standard-ML, OCaml and Haskell. The algorithms are efficient by using appropriate data structures like RB-trees. The available algorithms for non-deterministic automata include membership query, reduction, intersection, union, and emptiness check with computation of a witness for non-emptiness. The executable algorithms are derived from less-concrete, non-executable algorithms using data-refinement techniques. The concrete data structures are from the Isabelle Collections Framework. Moreover, this work contains a formalization of the class of tree-regular languages and its closure properties under set operations.","date":"November 25","id":500,"permalink":"/entries/tree-automata/","shortname":"Tree-Automata","title":"Tree Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"These theories present the mechanised proof of the Perfect Number Theorem.","date":"November 22","id":501,"permalink":"/entries/perfect-number-thm/","shortname":"Perfect-Number-Thm","title":"Perfect Number Theorem","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":"After verifying \u003ca href=\"Slicing.html\"\u003edynamic and static interprocedural slicing\u003c/a\u003e, we present a modular framework for static interprocedural slicing. To this end, we formalized the standard two-phase slicer from Horwitz, Reps and Binkley (see their TOPLAS 12(1) 1990 paper) together with summary edges as presented by Reps et al. (see FSE 1994). The framework is again modular in the programming language by using an abstract CFG, defined via structural and well-formedness properties. Using a weak simulation between the original and sliced graph, we were able to prove the correctness of static interprocedural slicing. We also instantiate our framework with a simple While language with procedures. This shows that the chosen abstractions are indeed valid.","date":"November 13","id":502,"permalink":"/entries/hrb-slicing/","shortname":"HRB-Slicing","title":"Backing up Slicing: Verifying the Interprocedural Two-Phase Horwitz-Reps-Binkley Slicer","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":"Gill and Hutton formalise the worker/wrapper transformation, building on the work of Launchbury and Peyton-Jones who developed it as a way of changing the type at which a recursive function operates. This development establishes the soundness of the technique and several examples of its use.","date":"October 30","id":503,"permalink":"/entries/workerwrapper/","shortname":"WorkerWrapper","title":"The Worker/Wrapper Transformation","topicLinks":["computer-science/programming-languages/transformations"],"topics":["Computer science/Programming languages/Transformations"]},{"abstract":"We develop a basic theory of ordinals and cardinals in Isabelle/HOL, up to the point where some cardinality facts relevant for the ``working mathematician\" become available. Unlike in set theory, here we do not have at hand canonical notions of ordinal and cardinal. Therefore, here an ordinal is merely a well-order relation and a cardinal is an ordinal minim w.r.t. order embedding on its field.","date":"September 1","id":504,"permalink":"/entries/ordinals_and_cardinals/","shortname":"Ordinals_and_Cardinals","title":"Ordinals and Cardinals","topicLinks":["logic/set-theory"],"topics":["Logic/Set theory"]},{"abstract":"The invertibility of the rules of a sequent calculus is important for guiding proof search and can be used in some formalised proofs of Cut admissibility. We present sufficient conditions for when a rule is invertible with respect to a calculus. We illustrate the conditions with examples. It must be noted we give purely syntactic criteria; no guarantees are given as to the suitability of the rules.","date":"August 28","id":505,"permalink":"/entries/sequentinvertibility/","shortname":"SequentInvertibility","title":"Invertibility in Sequent Calculi","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":"We formalize the usual proof that the group generated by the function k -\u003e k + 1 on the integers gives rise to a cofinitary group.","date":"August 4","id":506,"permalink":"/entries/cofgroups/","shortname":"CofGroups","title":"An Example of a Cofinitary Group in Isabelle/HOL","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"FinFuns are total functions that are constant except for a finite set of points, i.e. a generalisation of finite maps. They are formalised as a new type in Isabelle/HOL such that the code generator can handle equality tests and quantification on FinFuns. On the code output level, FinFuns are explicitly represented by constant functions and pointwise updates, similarly to associative lists. Inside the logic, they behave like ordinary functions with extensionality. Via the update/constant pattern, a recursion combinator and an induction rule for FinFuns allow for defining and reasoning about operators on FinFun that are also executable.","date":"May 6","id":507,"permalink":"/entries/finfun/","shortname":"FinFun","title":"Code Generation for Functions as Data","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"Stream Fusion is a system for removing intermediate list structures from Haskell programs; it consists of a Haskell library along with several compiler rewrite rules. (The library is available \u003ca href=\"http://hackage.haskell.org/package/stream-fusion\"\u003eonline\u003c/a\u003e.)\u003cbr\u003e\u003cbr\u003eThese theories contain a formalization of much of the Stream Fusion library in HOLCF. Lazy list and stream types are defined, along with coercions between the two types, as well as an equivalence relation for streams that generate the same list. List and stream versions of map, filter, foldr, enumFromTo, append, zipWith, and concatMap are defined, and the stream versions are shown to respect stream equivalence.","date":"April 29","id":508,"permalink":"/entries/stream-fusion/","shortname":"Stream-Fusion","title":"Stream Fusion","topicLinks":["computer-science/functional-programming"],"topics":["Computer science/Functional programming"]},{"abstract":"This document contains the Isabelle/HOL sources underlying the paper \u003ci\u003eA bytecode logic for JML and types\u003c/i\u003e by Beringer and Hofmann, updated to Isabelle 2008. We present a program logic for a subset of sequential Java bytecode that is suitable for representing both, features found in high-level specification language JML as well as interpretations of high-level type systems. To this end, we introduce a fine-grained collection of assertions, including strong invariants, local annotations and VDM-reminiscent partial-correctness specifications. Thanks to a goal-oriented structure and interpretation of judgements, verification may proceed without recourse to an additional control flow analysis. The suitability for interpreting intensional type systems is illustrated by the proof-carrying-code style encoding of a type system for a first-order functional language which guarantees a constant upper bound on the number of objects allocated throughout an execution, be the execution terminating or non-terminating. Like the published paper, the formal development is restricted to a comparatively small subset of the JVML, lacking (among other features) exceptions, arrays, virtual methods, and static fields. This shortcoming has been overcome meanwhile, as our paper has formed the basis of the Mobius base logic, a program logic for the full sequential fragment of the JVML. Indeed, the present formalisation formed the basis of a subsequent formalisation of the Mobius base logic in the proof assistant Coq, which includes a proof of soundness with respect to the Bicolano operational semantics by Pichardie.","date":"December 12","id":509,"permalink":"/entries/bytecodelogicjmltypes/","shortname":"BytecodeLogicJmlTypes","title":"A Bytecode Logic for JML and Types","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":"We present interpretations of type systems for secure information flow in Hoare logic, complementing previous encodings in relational program logics. We first treat the imperative language IMP, extended by a simple procedure call mechanism. For this language we consider base-line non-interference in the style of Volpano et al. and the flow-sensitive type system by Hunt and Sands. In both cases, we show how typing derivations may be used to automatically generate proofs in the program logic that certify the absence of illicit flows. We then add instructions for object creation and manipulation, and derive appropriate proof rules for base-line non-interference. As a consequence of our work, standard verification technology may be used for verifying that a concrete program satisfies the non-interference property.\u003cbr\u003e\u003cbr\u003eThe present proof development represents an update of the formalisation underlying our paper [CSF 2007] and is intended to resolve any ambiguities that may be present in the paper.","date":"November 10","id":510,"permalink":"/entries/sifpl/","shortname":"SIFPL","title":"Secure information flow and program logics","topicLinks":["computer-science/programming-languages/logics","computer-science/security"],"topics":["Computer science/Programming languages/Logics","Computer science/Security"]},{"abstract":"Drawing on Sen's landmark work \"Collective Choice and Social Welfare\" (1970), this development proves Arrow's General Possibility Theorem, Sen's Liberal Paradox and May's Theorem in a general setting. The goal was to make precise the classical statements and proofs of these results, and to provide a foundation for more recent results such as the Gibbard-Satterthwaite and Duggan-Schwartz theorems.","date":"November 9","id":511,"permalink":"/entries/sensocialchoice/","shortname":"SenSocialChoice","title":"Some classical results in Social Choice Theory","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":"Tilings are defined inductively. It is shown that one form of mutilated chess board cannot be tiled with dominoes, while another one can be tiled with L-shaped tiles. Please add further fun examples of this kind!","date":"November 7","id":512,"permalink":"/entries/funwithtilings/","shortname":"FunWithTilings","title":"Fun With Tilings","topicLinks":["mathematics/misc"],"topics":["Mathematics/Misc"]},{"abstract":"Huffman's algorithm is a procedure for constructing a binary tree with minimum weighted path length. This report presents a formal proof of the correctness of Huffman's algorithm written using Isabelle/HOL. Our proof closely follows the sketches found in standard algorithms textbooks, uncovering a few snags in the process. Another distinguishing feature of our formalization is the use of custom induction rules to help Isabelle's automatic tactics, leading to very short proofs for most of the lemmas.","date":"October 15","id":513,"permalink":"/entries/huffman/","shortname":"Huffman","title":"The Textbook Proof of Huffman's Algorithm","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"Slicing is a widely-used technique with applications in e.g. compiler technology and software security. Thus verification of algorithms in these areas is often based on the correctness of slicing, which should ideally be proven independent of concrete programming languages and with the help of well-known verifying techniques such as proof assistants. As a first step in this direction, this contribution presents a framework for dynamic and static intraprocedural slicing based on control flow and program dependence graphs. Abstracting from concrete syntax we base the framework on a graph representation of the program fulfilling certain structural and well-formedness properties.\u003cbr\u003e\u003cbr\u003eThe formalization consists of the basic framework (in subdirectory Basic/), the correctness proof for dynamic slicing (in subdirectory Dynamic/), the correctness proof for static intraprocedural slicing (in subdirectory StaticIntra/) and instantiations of the framework with a simple While language (in subdirectory While/) and the sophisticated object-oriented bytecode language of Jinja (in subdirectory JinjaVM/). For more information on the framework, see the TPHOLS 2008 paper by Wasserrab and Lochbihler and the PLAS 2009 paper by Wasserrab et al.","date":"September 16","id":514,"permalink":"/entries/slicing/","shortname":"Slicing","title":"Towards Certified Slicing","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":"The Volpano/Smith/Irvine security type systems requires that variables are annotated as high (secret) or low (public), and provides typing rules which guarantee that secret values cannot leak to public output ports. This property of a program is called confidentiality. For a simple while-language without threads, our proof shows that typeability in the Volpano/Smith system guarantees noninterference. Noninterference means that if two initial states for program execution are low-equivalent, then the final states are low-equivalent as well. This indeed implies that secret values cannot leak to public ports. The proof defines an abstract syntax and operational semantics for programs, formalizes noninterference, and then proceeds by rule induction on the operational semantics. The mathematically most intricate part is the treatment of implicit flows. Note that the Volpano/Smith system is not flow-sensitive and thus quite unprecise, resulting in false alarms. However, due to the correctness property, all potential breaks of confidentiality are discovered.","date":"September 2","id":515,"permalink":"/entries/volpanosmith/","shortname":"VolpanoSmith","title":"A Correctness Proof for the Volpano/Smith Security Typing System","topicLinks":["computer-science/programming-languages/type-systems","computer-science/security"],"topics":["Computer science/Programming languages/Type systems","Computer science/Security"]},{"abstract":"This article formalizes two proofs of Arrow's impossibility theorem due to Geanakoplos and derives the Gibbard-Satterthwaite theorem as a corollary. One formalization is based on utility functions, the other one on strict partial orders.\u003cbr\u003e\u003cbr\u003eAn article about these proofs is found \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/arrow.html\"\u003ehere\u003c/a\u003e.","date":"September 1","id":516,"permalink":"/entries/arrowimpossibilitygs/","shortname":"ArrowImpossibilityGS","title":"Arrow and Gibbard-Satterthwaite","topicLinks":["mathematics/games-and-economics"],"topics":["Mathematics/Games and economics"]},{"abstract":"This is a collection of cute puzzles of the form ``Show that if a function satisfies the following constraints, it must be ...'' Please add further examples to this collection!","date":"August 26","id":517,"permalink":"/entries/funwithfunctions/","shortname":"FunWithFunctions","title":"Fun With Functions","topicLinks":["mathematics/misc"],"topics":["Mathematics/Misc"]},{"abstract":"This document contains formal correctness proofs of modern SAT solvers. Following (Krstic et al, 2007) and (Nieuwenhuis et al., 2006), solvers are described using state-transition systems. Several different SAT solver descriptions are given and their partial correctness and termination is proved. These include: \u003cul\u003e \u003cli\u003e a solver based on classical DPLL procedure (using only a backtrack-search with unit propagation),\u003c/li\u003e \u003cli\u003e a very general solver with backjumping and learning (similar to the description given in (Nieuwenhuis et al., 2006)), and\u003c/li\u003e \u003cli\u003e a solver with a specific conflict analysis algorithm (similar to the description given in (Krstic et al., 2007)).\u003c/li\u003e \u003c/ul\u003e Within the SAT solver correctness proofs, a large number of lemmas about propositional logic and CNF formulae are proved. This theory is self-contained and could be used for further exploring of properties of CNF based SAT algorithms.","date":"July 23","id":518,"permalink":"/entries/satsolververification/","shortname":"SATSolverVerification","title":"Formal Verification of Modern SAT Solvers","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":"This document presents the formalization of introductory material from  recursion theory --- definitions and basic properties of primitive recursive  functions, Cantor pairing function and computably enumerable sets  (including a proof of existence of a one-complete computably enumerable set  and a proof of the Rice's theorem).","date":"April 5","id":519,"permalink":"/entries/recursion-theory-i/","shortname":"Recursion-Theory-I","title":"Recursion Theory I","topicLinks":["logic/computability"],"topics":["Logic/Computability"]},{"abstract":"We present the theory of Simpl, a sequential imperative programming language. We introduce its syntax, its semantics (big and small-step operational semantics) and Hoare logics for both partial as well as total correctness. We prove soundness and completeness of the Hoare logic. We integrate and automate the Hoare logic in Isabelle/HOL to obtain a practically usable verification environment for imperative programs. Simpl is independent of a concrete programming language but expressive enough to cover all common language features: mutually recursive procedures, abrupt termination and exceptions, runtime faults, local and global variables, pointers and heap, expressions with side effects, pointers to procedures, partial application and closures, dynamic method invocation and also unbounded nondeterminism.","date":"February 29","id":520,"permalink":"/entries/simpl/","shortname":"Simpl","title":"A Sequential Imperative Programming Language Syntax, Semantics, Hoare Logics and Verification Environment","topicLinks":["computer-science/programming-languages/language-definitions","computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Language definitions","Computer science/Programming languages/Logics"]},{"abstract":"We present the verification of the normalisation of a binary decision diagram (BDD). The normalisation follows the original algorithm presented by Bryant in 1986 and transforms an ordered BDD in a reduced, ordered and shared BDD. The verification is based on Hoare logics.","date":"February 29","id":521,"permalink":"/entries/bdd/","shortname":"BDD","title":"BDD Normalisation","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This article formalizes normalization by evaluation as implemented in Isabelle. Lambda calculus plus term rewriting is compiled into a functional program with pattern matching. It is proved that the result of a successful evaluation is a) correct, i.e. equivalent to the input, and b) in normal form.","date":"February 18","id":522,"permalink":"/entries/normbyeval/","shortname":"NormByEval","title":"Normalization by Evaluation","topicLinks":["computer-science/programming-languages/compiling"],"topics":["Computer science/Programming languages/Compiling"]},{"abstract":"This article formalizes quantifier elimination procedures for dense linear orders, linear real arithmetic and Presburger arithmetic. In each case both a DNF-based non-elementary algorithm and one or more (doubly) exponential NNF-based algorithms are formalized, including the well-known algorithms by Ferrante and Rackoff and by Cooper. The NNF-based algorithms for dense linear orders are new but based on Ferrante and Rackoff and on an algorithm by Loos and Weisspfenning which simulates infenitesimals. All algorithms are directly executable. In particular, they yield reflective quantifier elimination procedures for HOL itself. The formalization makes heavy use of locales and is therefore highly modular.","date":"January 11","id":523,"permalink":"/entries/linearquantifierelim/","shortname":"LinearQuantifierElim","title":"Quantifier Elimination for Linear Arithmetic","topicLinks":["logic/general-logic/decidability-of-theories"],"topics":["Logic/General logic/Decidability of theories"]},{"abstract":"In this work we formally verify the soundness and precision of a static program analysis that detects conflicts (e. g. data races) in programs with procedures, thread creation and monitors with the Isabelle theorem prover. As common in static program analysis, our program model abstracts guarded branching by nondeterministic branching, but completely interprets the call-/return behavior of procedures, synchronization by monitors, and thread creation. The analysis is based on the observation that all conflicts already occur in a class of particularly restricted schedules. These restricted schedules are suited to constraint-system-based program analysis. The formalization is based upon a flowgraph-based program model with an operational semantics as reference point.","date":"December 14","id":524,"permalink":"/entries/program-conflict-analysis/","shortname":"Program-Conflict-Analysis","title":"Formalization of Conflict Analysis of Programs with Procedures, Thread Creation, and Monitors","topicLinks":["computer-science/programming-languages/static-analysis"],"topics":["Computer science/Programming languages/Static analysis"]},{"abstract":"We extend the Jinja source code semantics by Klein and Nipkow with Java-style arrays and threads. Concurrency is captured in a generic framework semantics for adding concurrency through interleaving to a sequential semantics, which features dynamic thread creation, inter-thread communication via shared memory, lock synchronisation and joins. Also, threads can suspend themselves and be notified by others. We instantiate the framework with the adapted versions of both Jinja source and byte code and show type safety for the multithreaded case. Equally, the compiler from source to byte code is extended, for which we prove weak bisimilarity between the source code small step semantics and the defensive Jinja virtual machine. On top of this, we formalise the JMM and show the DRF guarantee and consistency. For description of the different parts, see Lochbihler's papers at FOOL 2008, ESOP 2010, ITP 2011, and ESOP 2012.","date":"December 3","id":525,"permalink":"/entries/jinjathreads/","shortname":"JinjaThreads","title":"Jinja with Threads","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"This article is an Isabelle formalisation of a paper with the same title. In a similar way as Knuth's 0-1-principle for sorting algorithms, that paper develops a 0-1-2-principle for parallel prefix computations.","date":"November 6","id":526,"permalink":"/entries/muchadoabouttwo/","shortname":"MuchAdoAboutTwo","title":"Much Ado About Two","topicLinks":["computer-science/algorithms"],"topics":["Computer science/Algorithms"]},{"abstract":"This document presents the mechanised proofs of\u003cul\u003e\u003cli\u003eFermat's Last Theorem for exponents 3 and 4 and\u003c/li\u003e\u003cli\u003ethe parametrisation of Pythagorean Triples.\u003c/li\u003e\u003c/ul\u003e","date":"August 12","id":527,"permalink":"/entries/fermat3_4/","shortname":"Fermat3_4","title":"Fermat's Last Theorem for Exponents 3 and 4 and the Parametrisation of Pythagorean Triples","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":"This document presents the mechanised proofs of the following results:\u003cul\u003e\u003cli\u003eany prime number of the form 4m+1 can be written as the sum of two squares;\u003c/li\u003e\u003cli\u003eany natural number can be written as the sum of four squares\u003c/li\u003e\u003c/ul\u003e","date":"August 12","id":528,"permalink":"/entries/sumsquares/","shortname":"SumSquares","title":"Sums of Two and Four Squares","topicLinks":["mathematics/number-theory"],"topics":["Mathematics/Number theory"]},{"abstract":"Convergence with respect to a valuation is discussed as convergence of a Cauchy sequence. Cauchy sequences of polynomials are defined. They are used to formalize Hensel's lemma.","date":"August 8","id":529,"permalink":"/entries/valuation/","shortname":"Valuation","title":"Fundamental Properties of Valuation Theory and Hensel's Lemma","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"We present a formalization of parts of Melvin Fitting's book \"First-Order Logic and Automated Theorem Proving\". The formalization covers the syntax of first-order logic, its semantics, the model existence theorem, a natural deduction proof calculus together with a proof of correctness and completeness, as well as the Löwenheim-Skolem theorem.","date":"August 2","id":530,"permalink":"/entries/fol-fitting/","shortname":"FOL-Fitting","title":"First-Order Logic According to Fitting","topicLinks":["logic/general-logic/classical-first-order-logic"],"topics":["Logic/General logic/Classical first-order logic"]},{"abstract":"We present a solution to the POPLmark challenge designed by Aydemir et al., which has as a goal the formalization of the meta-theory of System F\u003csub\u003e\u0026lt;:\u003c/sub\u003e. The formalization is carried out in the theorem prover Isabelle/HOL using an encoding based on de Bruijn indices. We start with a relatively simple formalization covering only the basic features of System F\u003csub\u003e\u0026lt;:\u003c/sub\u003e, and explain how it can be extended to also cover records and more advanced binding constructs.","date":"August 2","id":531,"permalink":"/entries/poplmark-debruijn/","shortname":"POPLmark-deBruijn","title":"POPLmark Challenge Via de Bruijn Indices","topicLinks":["computer-science/programming-languages/lambda-calculi"],"topics":["Computer science/Programming languages/Lambda calculi"]},{"abstract":"Two models of an electronic hotel key card system are contrasted: a state based and a trace based one. Both are defined, verified, and proved equivalent in the theorem prover Isabelle/HOL. It is shown that if a guest follows a certain safety policy regarding her key cards, she can be sure that nobody but her can enter her room.","date":"September 9","id":532,"permalink":"/entries/hotelkeycards/","shortname":"HotelKeyCards","title":"Hotel Key Card System","topicLinks":["computer-science/security"],"topics":["Computer science/Security"]},{"abstract":"These therories describe Hoare logics for a number of imperative language constructs, from while-loops to mutually recursive procedures. Both partial and total correctness are treated. In particular a proof system for total correctness of recursive procedures in the presence of unbounded nondeterminism is presented.","date":"August 8","id":533,"permalink":"/entries/abstract-hoare-logics/","shortname":"Abstract-Hoare-Logics","title":"Abstract Hoare Logics","topicLinks":["computer-science/programming-languages/logics"],"topics":["Computer science/Programming languages/Logics"]},{"abstract":" These theories present the verified enumeration of \u003ci\u003etame\u003c/i\u003e plane graphs as defined by Thomas C. Hales in his proof of the Kepler Conjecture in his book \u003ci\u003eDense Sphere Packings. A Blueprint for Formal Proofs.\u003c/i\u003e [CUP 2012]. The values of the constants in the definition of tameness are identical to those in the \u003ca href=\"https://code.google.com/p/flyspeck/\"\u003eFlyspeck project\u003c/a\u003e. The \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/Flyspeck/\"\u003eIJCAR 2006 paper by Nipkow, Bauer and Schultz\u003c/a\u003e refers to the original version of Hales' proof, the \u003ca href=\"http://www21.in.tum.de/~nipkow/pubs/itp11.html\"\u003eITP 2011 paper by Nipkow\u003c/a\u003e refers to the Blueprint version of the proof.","date":"May 22","id":534,"permalink":"/entries/flyspeck-tame/","shortname":"Flyspeck-Tame","title":"Flyspeck I: Tame Graphs","topicLinks":["mathematics/graph-theory"],"topics":["Mathematics/Graph theory"]},{"abstract":"We present an operational semantics and type safety proof for multiple inheritance in C++. The semantics models the behavior of method calls, field accesses, and two forms of casts in C++ class hierarchies. For explanations see the OOPSLA 2006 paper by Wasserrab, Nipkow, Snelting and Tip.","date":"May 15","id":535,"permalink":"/entries/corec++/","shortname":"CoreC++","title":"CoreC++","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"We formalize the type system, small-step operational semantics, and type soundness proof for Featherweight Java, a simple object calculus, in Isabelle/HOL.","date":"March 31","id":536,"permalink":"/entries/featherweightjava/","shortname":"FeatherweightJava","title":"A Theory of Featherweight Java in Isabelle/HOL","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"F. B. Schneider (\"Understanding protocols for Byzantine clock synchronization\") generalizes a number of protocols for Byzantine fault-tolerant clock synchronization and presents a uniform proof for their correctness. In Schneider's schema, each processor maintains a local clock by periodically adjusting each value to one computed by a convergence function applied to the readings of all the clocks. Then, correctness of an algorithm, i.e. that the readings of two clocks at any time are within a fixed bound of each other, is based upon some conditions on the convergence function. To prove that a particular clock synchronization algorithm is correct it suffices to show that the convergence function used by the algorithm meets Schneider's conditions. Using the theorem prover Isabelle, we formalize the proofs that the convergence functions of two algorithms, namely, the Interactive Convergence Algorithm (ICA) of Lamport and Melliar-Smith and the Fault-tolerant Midpoint algorithm of Lundelius-Lynch, meet Schneider's conditions. Furthermore, we experiment on handling some parts of the proofs with fully automatic tools like ICS and CVC-lite. These theories are part of a joint work with Alwen Tiu and Leonor P. Nieto \u003ca href=\"http://users.rsise.anu.edu.au/~tiu/clocksync.pdf\"\u003e\"Verification of Clock Synchronization Algorithms: Experiments on a combination of deductive tools\"\u003c/a\u003e in proceedings of AVOCS 2005. In this work the correctness of Schneider schema was also verified using Isabelle (entry \u003ca href=\"GenClock.html\"\u003eGenClock\u003c/a\u003e in AFP).","date":"March 15","id":537,"permalink":"/entries/clocksynchinst/","shortname":"ClockSynchInst","title":"Instances of Schneider's generalized protocol of clock synchronization","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":"This document presents the mechanised proofs of two popular theorems attributed to Augustin Louis Cauchy - Cauchy's Mean Theorem and the Cauchy-Schwarz Inequality.","date":"March 14","id":538,"permalink":"/entries/cauchy/","shortname":"Cauchy","title":"Cauchy's Mean Theorem and the Cauchy-Schwarz Inequality","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"This development defines a well-ordered type of countable ordinals. It includes notions of continuous and normal functions, recursively defined functions over ordinals, least fixed-points, and derivatives. Much of ordinal arithmetic is formalized, including exponentials and logarithms. The development concludes with formalizations of Cantor Normal Form and Veblen hierarchies over normal functions.","date":"November 11","id":539,"permalink":"/entries/ordinal/","shortname":"Ordinal","title":"Countable Ordinals","topicLinks":["logic/set-theory"],"topics":["Logic/Set theory"]},{"abstract":"We formalise a functional implementation of the FFT algorithm over the complex numbers, and its inverse. Both are shown equivalent to the usual definitions of these operations through Vandermonde matrices. They are also shown to be inverse to each other, more precisely, that composition of the inverse and the transformation yield the identity up to a scalar.","date":"October 12","id":540,"permalink":"/entries/fft/","shortname":"FFT","title":"Fast Fourier Transform","topicLinks":["computer-science/algorithms/mathematical"],"topics":["Computer science/Algorithms/Mathematical"]},{"abstract":"We formalize the generalized Byzantine fault-tolerant clock synchronization protocol of Schneider. This protocol abstracts from particular algorithms or implementations for clock synchronization. This abstraction includes several assumptions on the behaviors of physical clocks and on general properties of concrete algorithms/implementations. Based on these assumptions the correctness of the protocol is proved by Schneider. His proof was later verified by Shankar using the theorem prover EHDM (precursor to PVS). Our formalization in Isabelle/HOL is based on Shankar's formalization.","date":"June 24","id":541,"permalink":"/entries/genclock/","shortname":"GenClock","title":"Formalization of a Generalized Protocol for Clock Synchronization","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":"Disk Paxos is an algorithm for building arbitrary fault-tolerant distributed systems. The specification of Disk Paxos has been proved correct informally and tested using the TLC model checker, but up to now, it has never been fully formally verified. In this work we have formally verified its correctness using the Isabelle theorem prover and the HOL logic system, showing that Isabelle is a practical tool for verifying properties of TLA+ specifications.","date":"June 22","id":542,"permalink":"/entries/diskpaxos/","shortname":"DiskPaxos","title":"Proving the Correctness of Disk Paxos","topicLinks":["computer-science/algorithms/distributed"],"topics":["Computer science/Algorithms/Distributed"]},{"abstract":"This document presents the formalization of an object-oriented data and store model in Isabelle/HOL. This model is being used in the Java Interactive Verification Environment, Jive.","date":"June 20","id":543,"permalink":"/entries/jivedatastoremodel/","shortname":"JiveDataStoreModel","title":"Jive Data and Store Model","topicLinks":["computer-science/programming-languages/misc"],"topics":["Computer science/Programming languages/Misc"]},{"abstract":"We introduce Jinja, a Java-like programming language with a formal semantics designed to exhibit core features of the Java language architecture. Jinja is a compromise between realism of the language and tractability and clarity of the formal semantics. The following aspects are formalised: a big and a small step operational semantics for Jinja and a proof of their equivalence; a type system and a definite initialisation analysis; a type safety proof of the small step semantics; a virtual machine (JVM), its operational semantics and its type system; a type safety proof for the JVM; a bytecode verifier, i.e. data flow analyser for the JVM; a correctness proof of the bytecode verifier w.r.t. the type system; a compiler and a proof that it preserves semantics and well-typedness. The emphasis of this work is not on particular language features but on providing a unified model of the source language, the virtual machine and the compiler. The whole development has been carried out in the theorem prover Isabelle/HOL.","date":"June 1","id":544,"permalink":"/entries/jinja/","shortname":"Jinja","title":"Jinja is not Java","topicLinks":["computer-science/programming-languages/language-definitions"],"topics":["Computer science/Programming languages/Language definitions"]},{"abstract":"Formal verification is getting more and more important in computer science. However the state of the art formal verification methods in cryptography are very rudimentary. These theories are one step to provide a tool box allowing the use of formal methods in every aspect of cryptography. Moreover we present a proof of concept for the feasibility of verification techniques to a standard signature algorithm.","date":"May 2","id":545,"permalink":"/entries/rsapss/","shortname":"RSAPSS","title":"SHA1, RSA, PSS and more","topicLinks":["computer-science/security/cryptography"],"topics":["Computer science/Security/Cryptography"]},{"abstract":"This development proves Yoneda's lemma and aims to be readable by humans. It only defines what is needed for the lemma: categories, functors and natural transformations. Limits, adjunctions and other important concepts are not included.","date":"April 21","id":546,"permalink":"/entries/category/","shortname":"Category","title":"Category Theory to Yoneda's Lemma","topicLinks":["mathematics/category-theory"],"topics":["Mathematics/Category theory"]},{"abstract":"These theories illustrates the verification of basic file operations (file creation, file read and file write) in the Isabelle theorem prover. We describe a file at two levels of abstraction: an abstract file represented as a resizable array, and a concrete file represented using data blocks.","date":"December 9","id":547,"permalink":"/entries/filerefinement/","shortname":"FileRefinement","title":"File Refinement","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"Lebesgue-style integration plays a major role in advanced probability. We formalize concepts of elementary measure theory, real-valued random variables as Borel-measurable functions, and a stepwise inductive definition of the integral itself. All proofs are carried out in human readable style using the Isar language.","date":"November 19","id":548,"permalink":"/entries/integration/","shortname":"Integration","title":"Integration theory and random variables","topicLinks":["mathematics/analysis"],"topics":["Mathematics/Analysis"]},{"abstract":"Soundness and completeness for a system of first order logic are formally proved, building on James Margetson's formalization of work by Wainer and Wallen. The completeness proofs naturally suggest an algorithm to derive proofs. This algorithm, which can be implemented tail recursively, is formalized in Isabelle/HOL. The algorithm can be executed via the rewriting tactics of Isabelle. Alternatively, the definitions can be exported to OCaml, yielding a directly executable program.","date":"September 28","id":549,"permalink":"/entries/verified-prover/","shortname":"Verified-Prover","title":"A Mechanically Verified, Efficient, Sound and Complete Theorem Prover For First Order Logic","topicLinks":["logic/general-logic/mechanization-of-proofs"],"topics":["Logic/General logic/Mechanization of proofs"]},{"abstract":"The completeness of first-order logic is proved, following the first five pages of Wainer and Wallen's chapter of the book \u003ci\u003eProof Theory\u003c/i\u003e by Aczel et al., CUP, 1992. Their presentation of formulas allows the proofs to use symmetry arguments. Margetson formalized this theorem by early 2000. The Isar conversion is thanks to Tom Ridge. A paper describing the formalization is available \u003ca href=\"Completeness-paper.pdf\"\u003e[pdf]\u003c/a\u003e.","date":"September 20","id":550,"permalink":"/entries/completeness/","shortname":"Completeness","title":"Completeness theorem","topicLinks":["logic/proof-theory"],"topics":["Logic/Proof theory"]},{"abstract":"This formalization of Ramsey's theorem (infinitary version) is taken from Boolos and Jeffrey, \u003ci\u003eComputability and Logic\u003c/i\u003e, 3rd edition, Chapter 26. It differs slightly from the text by assuming a slightly stronger hypothesis. In particular, the induction hypothesis is stronger, holding for any infinite subset of the naturals. This avoids the rather peculiar mapping argument between kj and aikj on p.263, which is unnecessary and slightly mars this really beautiful result.","date":"September 20","id":551,"permalink":"/entries/ramsey-infinite/","shortname":"Ramsey-Infinite","title":"Ramsey's theorem, infinitary version","topicLinks":["mathematics/combinatorics"],"topics":["Mathematics/Combinatorics"]},{"abstract":"An exception compilation scheme that dynamically creates and removes exception handler entries on the stack. A formalization of an article of the same name by \u003ca href=\"http://www.cs.nott.ac.uk/~gmh/\"\u003eHutton\u003c/a\u003e and Wright.","date":"July 9","id":552,"permalink":"/entries/compiling-exceptions-correctly/","shortname":"Compiling-Exceptions-Correctly","title":"Compiling Exceptions Correctly","topicLinks":["computer-science/programming-languages/compiling"],"topics":["Computer science/Programming languages/Compiling"]},{"abstract":"Depth-first search of a graph is formalized with recdef. It is shown that it visits all of the reachable nodes from a given list of nodes. Executable ML code of depth-first search is obtained using the code generation feature of Isabelle/HOL.","date":"June 24","id":553,"permalink":"/entries/depth-first-search/","shortname":"Depth-First-Search","title":"Depth First Search","topicLinks":["computer-science/algorithms/graph"],"topics":["Computer science/Algorithms/Graph"]},{"abstract":"The theory of groups, rings and modules is developed to a great depth. Group theory results include Zassenhaus's theorem and the Jordan-Hoelder theorem. The ring theory development includes ideals, quotient rings and the Chinese remainder theorem. The module development includes the Nakayama lemma, exact sequences and Tensor products.","date":"May 18","id":554,"permalink":"/entries/group-ring-module/","shortname":"Group-Ring-Module","title":"Groups, Rings and Modules","topicLinks":["mathematics/algebra"],"topics":["Mathematics/Algebra"]},{"abstract":"This theory contains some useful extensions to the LList (lazy list) theory by \u003ca href=\"http://www.cl.cam.ac.uk/~lp15/\"\u003eLarry Paulson\u003c/a\u003e, including finite, infinite, and positive llists over an alphabet, as well as the new constants take and drop and the prefix order of llists. Finally, the notions of safety and liveness in the sense of Alpern and Schneider (1985) are defined.","date":"April 26","id":555,"permalink":"/entries/lazy-lists-ii/","shortname":"Lazy-Lists-II","title":"Lazy Lists II","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This entry contains two theories. The first, \u003ctt\u003eTopology\u003c/tt\u003e, develops the basic notions of general topology. The second, which can be viewed as a demonstration of the first, is called \u003ctt\u003eLList_Topology\u003c/tt\u003e. It develops the topology of lazy lists.","date":"April 26","id":556,"permalink":"/entries/topology/","shortname":"Topology","title":"Topology","topicLinks":["mathematics/topology"],"topics":["Mathematics/Topology"]},{"abstract":"The correctness is shown of binary search tree operations (lookup, insert and remove) implementing a set. Two versions are given, for both structured and linear (tactic-style) proofs. An implementation of integer-indexed maps is also verified.","date":"April 5","id":557,"permalink":"/entries/binarysearchtree/","shortname":"BinarySearchTree","title":"Binary Search Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This theory defines deterministic and nondeterministic automata in a functional representation: the transition function/relation and the finality predicate are just functions. Hence the state space may be infinite. It is shown how to convert regular expressions into such automata. A scanner (generator) is implemented with the help of functional automata: the scanner chops the input up into longest recognized substrings. Finally we also show how to convert a certain subclass of functional automata (essentially the finite deterministic ones) into regular sets.","date":"March 30","id":558,"permalink":"/entries/functional-automata/","shortname":"Functional-Automata","title":"Functional Automata","topicLinks":["computer-science/automata-and-formal-languages"],"topics":["Computer science/Automata and formal languages"]},{"abstract":"Two formalizations of AVL trees with room for extensions. The first formalization is monolithic and shorter, the second one in two stages, longer and a bit simpler. The final implementation is the same. If you are interested in developing this further, please contact \u003ctt\u003egerwin.klein@nicta.com.au\u003c/tt\u003e.","date":"March 19","id":559,"permalink":"/entries/avl-trees/","shortname":"AVL-Trees","title":"AVL Trees","topicLinks":["computer-science/data-structures"],"topics":["Computer science/Data structures"]},{"abstract":"This theory defines the type inference rules and the type inference algorithm \u003ci\u003eW\u003c/i\u003e for MiniML (simply-typed lambda terms with \u003ctt\u003elet\u003c/tt\u003e) due to Milner. It proves the soundness and completeness of \u003ci\u003eW\u003c/i\u003e w.r.t. the rules.","date":"March 19","id":560,"permalink":"/entries/miniml/","shortname":"MiniML","title":"Mini ML","topicLinks":["computer-science/programming-languages/type-systems"],"topics":["Computer science/Programming languages/Type systems"]}]